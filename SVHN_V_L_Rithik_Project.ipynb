{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eN11wZ-D8dfj"
   },
   "source": [
    "# Objective:\n",
    "\n",
    "   In this project Neural Network based models are buit to recognize the digits in the images captured by Google Street view. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "s7Am4FEJ7m1I",
    "outputId": "f8824128-a8f7-4ead-f27d-9b9aa08b6dcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py # Hierarchical Data Format version 5 \n",
    "import numpy as np # For doing algebric/mathematical calculation/operations.\n",
    "import pandas as pd # For creating, analyzing/dataprocessing dataframes.\n",
    "import matplotlib.pyplot as plt # For visualization of data.\n",
    "import seaborn as sns           # For visualization of data.\n",
    "import math #To perform mathematical operations like exponential, power operations etc,..\n",
    "import tensorflow as tf #To build Neural Network Models.\n",
    "import keras #To build Neural Network Models.\n",
    "from keras.models import Sequential #This kind of Model is used because our layers have exactly one input and output tensor\n",
    "from keras.layers import Dense #To add layers in the Sequential Model.\n",
    "\n",
    "#To add activation layers:\n",
    "from keras.layers import Activation, LeakyReLU \n",
    "#To add Reglarization Layers:\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "from keras.layers import Flatten  # To Reshape the input\n",
    "\n",
    "#To do Optimization to updaate the parameters(Weight and bias):\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils.np_utils import to_categorical #To Perform One-Hot Encoding on the dependent variable to support Cross-Entropy cost function.\n",
    "from keras.regularizers import l2 #To perform Ridge Regularization\n",
    "\n",
    "#To perform Hyperparameter tuning:#### a. Reading the Data and structure of the file:#### a. Reading the Data and structure of the file:### Step 1: Importing necessary Libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(action =  \"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:. Reading the Data and structure of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZCZHwj_-gJI"
   },
   "outputs": [],
   "source": [
    "data = h5py.File('/content/gdrive/My Drive/AIML/Sri Rama Jayam/Intro to NN and DL/SVHN_single_grey1.h5') #Reading the data file from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EqipcoyQBjga",
    "outputId": "0bd60838-88d4-4adc-f69d-09e55286185e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key in data.keys()] # Understanding the contents that file have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yy6Qw1HQCUNZ"
   },
   "outputs": [],
   "source": [
    "#Extracting the Train, Validation and Testing dataSet from the file:\n",
    "X_train = data['X_train'][:]\n",
    "y_train = data['y_train'][:]\n",
    "X_val = data['X_val'][:]\n",
    "y_val = data['y_val'][:]\n",
    "X_test = data['X_test'][:]\n",
    "y_test = data['y_test'][:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on the above steps:\n",
    "1. The data files were read form the google drive.\n",
    "2. The contents in the files were understood and extracted.\n",
    "3. The extracted training, validation and testing will be used for creating model, improving and fianlizing the model and testing the model in the production respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Visualizing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "colab_type": "code",
    "id": "z0vNZE4eKv7Z",
    "outputId": "19424a92-1b9c-4f3b-c71f-92f092a55ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for the images are : [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5)) #Determining the output figure size.\n",
    "\n",
    "#Plotting the image:\n",
    "for x in range(10):\n",
    "  plt.subplot(1,10, x+1)\n",
    "  plt.imshow(X_train[x])\n",
    "  plt.axis('off')\n",
    "print( 'label for the images are : {}'. format(y_train[0:10]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "colab_type": "code",
    "id": "Y0NQH7_pVAYk",
    "outputId": "5a865061-2668-4f76-9fbe-eac06c12fd3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for the images are : [1 7 2 9 0 9 1 8 4 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9S6xlW5ae9Y35WGvt1zknTrzu+2ZVOqtMOlM2VWVK2MiWjCwjSjSQ3DJSdaCPBAgQDSwBDUQDRIMmfVoIJIRLMhKNsjBgoKpcWVXOyszKm/d9I+I892s95oPGmGvtHffejDi3JISUOkOKOOfE2bH3WnOuOeY//vGPMSXnzL3d273d273d273d2y+ymf+/L+De7u3e7u3e7u3e7u3/a7sHPPd2b/d2b/d2b/f2C2/3gOfe7u3e7u3e7u3efuHtHvDc273d273d273d2y+83QOee7u3e7u3e7u3e/uFt3vAc2/3dm/3dm/3dm+/8OZe9cu//df+0xxnjjCzxNowzIUwF7ZvC7HJJJfxtwZJ+vr2zUhuIuIT8qKiujX4W1h9FAHIVmjPhLAQwgxsD7YF02eSF5KHWMNwkhnOA7OHe773xmf00dEnS2MH3plf863mgu81H3FiWuZm4MyECblZYABihm+/+5m8bgD+0v/493PO+rKU9Ov4szEJERDJL/37WMmfkiHn49dnrE0Yk0jJEKOZ3hPAuYi1CSuZbnCEYIjBkloLApiMrRJIZvxfUq7h2MbrAfjTv/sfv/Yef+fPvpsriTQysDI9howt72HJ09glIJZPtmR8eechQ5st16nmOs25jgt+2j3m1O557G755eoZFQkjmTZbUjZEhDZ7YtZ3H7BcxwWXYcmH3Tm3oWEfPZuhpk+OIVpuuoZ97+kHR9+VRzPDT/+N/+iV9/i9f++/ysMJ9CeJNE/YrcFtDGc/SlSbhNtEbBuRrJOXjSApI0m/T7UlNJZhZQmN6DM41+cxeUgVIJAFJIFEpmf++OcsgIEwg1RlkoNUZ7LJYCH7BC4jNiEm63OThA9++z987Rz+jd/6L3K2QnYQy8RIBrcbLwT6pcXEjAkZ0x2ekezKc2ugXxrah4b2USZ9Z8dqueds1vJsvWTzxZLmc8fZDxP1bcTuE3FmyKY830PGdhHTJx2LDNkIV7/acPEbkb/1V/6Yf+eNf4iXRMzCOnsqEl4S33/v4zutxZSEGHVdZCAnIQ0GOov0QnVtcDvB7UACZKdzFKsyV3UmzDLZZbLPICBRIJQxi2CCQDqau1zmroxjNuWPy9O8A2QL2Ey2+u9Ifilk/Nm/+e+/9h7/5z/73lf6gBgSVhJ6x2oRIWbD83hCmzxDtqxTw5AcCcGQmduOuek5MXsaM+Al0MiAl4glMeSDe5+bjpQNPZbn4YQf7N/hj9Zv8nsfvkv6oqF5Zph/kbFdxnUZt0+YIWOGhIRMtkI2wv/6v7z6Wf1XfvU/yNIP0A9gDIiANdAP5JQgRsQ5cA6cJc8bsjNka5EYkXZA+gG6Xl/jHdkafS9ryN6WycjIEGEISNCvpPTVC7Ll9SKQEjkEiBGsRdS563UV+53P/pvXzuF/9+PfyCkb+myxkvlx+5Qfbp7yv/8/v8LsU8v888zys6BjlzLJGyRmJGb8dYu53ZHXW/J6TY762VJ5ZNYgTaMbjDE6PpUHI2D03lPjiI1jWDrC3DDMhNiU57g8y8NcCEvYvZHgcccbj2/4e+/9E75VPecNe8tfff9nr73HX/+3/sscK4i1sHszE84Ds/M933p4yZuzW95sbninuqQxA40MAPTZMmTHOjVl/wg8dmsWpmNuOhoZGLKlzZ4/bt/h99fv8sPrJ3zy6Tnm2lHdGOpL9TMmqp9LNYQGhtNMWCbyIjBbdTTVwKwasJJZtzXbXc1wXSODIFH46b/9737tPb4S8EjMSNCJ0g1CIKujkQEMgiiWIReHbpuI84G+8mSj/8dEdSDRQlgIwxLCLMNW/78ZdKLUibx8DX3UBZ6yYI42+oRuqikLw5HfGYABIebXzqm+frCH9xzByQiAjGDMCHbKr45AT04HbyeSSaCLCAU6CobK+4lucCkZsmT9fTIw/h71ujmDIJPry9G+5JFz5gCA5Cu+82vNSsJLwIhuPp6MLe/hAS+CF72XlDNGBItgMAxEdikSOTjkmNXhttlxHed8Gh4wl46F6ViZHitB31v202e1WXhudixMh5FElzxt8uxSRZccQ7bcDDPWQ81mqFn3NemOc5gtpHGDs1k3pnFssn47gp1x2MyQkG5Qh2dqaCyx0sUVZkKYl83UKXgZn0uJQNJN07ZgOzA9uDZPDifM1FHEGmIjJD+CH/0+e6PTmcpmfAfzu0BoLKGydKc6V5JGEJIxfcJWBslZ12ceN25BYtZxMDAshf3TTHi/5be/+0/41eYz3nA3/B+7b/O7D/4CPzx5yu5qjiSY7ZP+v5TJIgdQkDKmAMdsDckBLuFMJCKYLAwY2uxBBgx3e073+2paA2QFO2SBwSCDYFuDbcdx1/tMiWltSGbyUbpB6xhIKuMBmHFjiDIB1RG85hHsOMg2v/T8SSw+zsgEeEaAy+ESXj+PEjTIKB9qy7oyBfBMawwhIgxY1sy4jnN2sZ7Wi5fIkC3JGhrpaRjwRBbST+99bBWJWAbBSmKXKq66OWHtaa4NzUVm8UXA7pOC2i4gQ1RQERNpWRNn/rX3JyFCytNaAyDlCexM/+4sua6IJw3JGbCChIypHNJ6TEz6Glf8s1FwMjk/ETBZAZEIkjMkow9ESi9/vi3AywjF0xY/jb4u5cNn3NFimXhLojEDMzsoyLb6/ISZQZqyjzh9Jk3MSK5xlMcmRQWGMSLW6gLNmbzekHNGRJDVUsGPESRETOWxsxrJCyQ6zGBIu6PnWECiAQTbCkNn2ffqZ4fspoD2tfMYda3kOPpO3fuO14SRjCFNz66RRJXjNDaVBN13SFgSKRuG7Gizp82OLjlCMhAVpLwUTCZ0TjkEa9lmxGa8i9Q+0LiAk0TvLZ13DC7r6nnFLb4S8JAUoUosCN8WB1KipETGDrrYE0AS8ug8TJ5er45ESE50U5ll4jJhOzvt9aNPzKKAiiiEYHi+X1DZSG0Dc9dTG924x4kzkotzYAI5qTiLu1i/P1rEk7MtDtSMO2X59eiAv+y/jU6EsZkUDcamCRDl8T1RRsiU3TdFSwpCDjrhoAs4ieF4LU6DG49DTV45qV+2M7OfxmPIBisRiy66Rgy1OLyMkVC5VhJtDryIkYtUcxmX/KR/wrPhhIt+ybNuOYHRpet40qx5s7rhn599wEO75cz0PLIWj8WKsEsDsNcxL5FAzDIxTQBt8tzEOTdxxkW/1Hm8w06ikQjkOiF1JHe64CUqe2j3AbMPR/PF5MzToiYsPe1Dy/o9w7DKhHkiN1EHyGT9czwPUTC9oXlmkAh+l5m9iLhdxLaBbA1hbglzS3diCHMFUcOqMKNVAV6DYMLX3dFXrV95Nm9Zdm8J/bf3iNVruriomH3mWHyamV1EpDjvaXM2YNtEtkKsDOtfAv+dW/7O+3/Kb5/9n6yMgt333e/xm/Of8EdP3ua/lr9F/ycLwDN7MRyedwEZEhLTxO5kKyQvYCBlwy555kYjvor4EmvxOktXNVkKuHRHgHUwmE4wHbg9+G3G7fR1AfVLptfASe9XpuDpGMSQR991tEGkEQQpYI21FKCrDN94+Sbo+1B82WjTv90Z8MTp+xHseIk0EidgWEmizZZtdvxZ95QvhhMuhwV/tn7IbqjYDx5rEouqZ+U7ns5ueau+4f36BYvqc2K2RAxt8lNgOEhPmz3bVPPp8IBP9me82Cxw1476EubPE82nO0zbK2sSj0BDzoh3SP3q7QIgO6suJCsYGZ2ZpKSMjQh53hDPF3QPatbvOcJc9wWJUK0z9U1m+WGN2SvoyjNPWHjCzBIWpmyMmfqix7YBaYNeY1BAlYdhuh5xDmwBTiJIPyjYyfmrwOiOVok+11GERgbmpmdmB6gSqcrESmgfaCCQvAY+koEE9amlufFU1w3V8xopzNS4bnWs5gf3bgqiDpHcD8qCDQEvgvOW7O3Eto7stXtQYwfHcGKIc8d2VfOsP+HU7ic25nXmd4lYmFDbCqE3DINlSJaElGe258xqEHv8vttUT98vTDeBoTZ7+mxpU8VNmLMZana9R3qDGXQN2z6rT8zKrI9rN84SMg8sVi1vrNac1nseVDusZJ61Sy78gk8LM5xeEUS+BvCg0VzMU7SYR0bRoE5uJEi+Rg000Wyp0M0OYlNofp/IhfIcoy84RGlSPMi+9+pQx0vKUtiBilYGfI4vfeboYO/qaHNnj37gJc+VoWx2HIBOZro2HYcS7blEtBkxyt6MiHj8vzkrgEqiX3Mw5KCbp4QDiiWbMrblc6OmPWQQjV7TEQb7hms1ZcNQHKDPiUoSicTAQE0k5TG6zOxyZp0s/6x/i0+HB3zWn/Lj7WMu2gW3bcO2rQiDJSVDVQ+cL3e8s7pmaVtafwHumrn0eEnYLKxzYpc8bfakfHhYLAkvcaLjrWjEELPRCPYOO0m2ZbzK+I/DYoeM7RJmH9SRH5sI2Vv6s5r9Q8vuiWH/VoTVQLPomdX6egWsQkjK2sVoCMESO8uwqxT4txqN2C5ibzsATOexvSf5iuQEqQtrcMQYGSDfEbk++3VH+/bA03eu+I3HH2EkEbLlz9YP+dH5E4aTBvtPDa7N2D6VjVwjbUkwnFj2Dw3mlzf8C29/yN88+SEJeB6FLhvmJnFud/yl+hO++9bn/MHN++wvHfNnh9RfPo6wYVoP2egz7U0s6ZSM+RrW4nVm9jL5mHzMUgRdIyaIOsYB7KC+Z4w+TTh8hhlkAu7ZlJQXxbeEI5ZnAjzKFin4PKzfiR1M+plQ3IA7ij1ejwFesqE40JjNBEZiNi9tDADXcc7zcMLvr9/l4+0Zz7cLrp6tkJLayzaTqwx15Ox8y7tn12xWNed2QyURQ2KdZhO722fLNtVcxzlfDCc83y9ZbxvqG6G6zVS3ukakGzT1U3llT5ymUuLCE2Z3vFmRCeyM4FBgStOkVUP3oGb3xLF5D2KTSD5jBqF/IOx3BokN9VXA3/Z0jxrac0t3ZhiWyqrafSZWNc2lxceMtCgo6HoQgzirQGcoIME5TZ95B9Yg++5wvUam9NZdbEzTWzKVRGozUJsBKeyyMs4H0JyqMiyxPIteg/9sBRkKKyZCrjy58eTzpf5cAgzTBwhR52UEaF2PBIsMllQ5ZUNyBmcwIR8AfR5JLLkzYw6FsS5BjRlAgpCjEJMhZiEhUzprIT0ro/7SkFnI8JI0YmIrs2WdZlzEJZfDgpu+oes80gm2E53XXsFsGbHC7ED2maoJnMxaHs82PKo3PHA7vEScRJxJbLqaLlhCsD/nrl6X0koJExJ5OKKVStSI5Jeim8kBlA1CykZu+yOtRIVGuHUCn0ePP00McECrxYZ4lHIqm2CbPOvU4CXgJZKymZwrI712Rycr/RFSOwYS44VISeMdg43x92ak9bMqYaLm93PKL7MxozZIjqjwwhTIEeDRPHPRCIyXFUUj3F4mR/0S6LmjjbqabfZ4IgOGLme8JFpJNBKJWTFunw2XacbzeML/vf0WH+we8tnuhM+uTuj3nrx3mL3BDHpNXVPz6XnFrvc8qdcwp+iFBnxWvdB1ctzmmm2q6bMllRs0ctAejFFCzIbOqm5h3CBeaSV18ZJlOWhOuuHg4MZcflOT5xX9maM9V01L/XTH45MNT+ZrVr5jSJaQDbtQ0UeNboZo2Q9eaeK1w3YWt1MwIDEhbYd0AzI0SAZ76pCkGq1UQWoSeR5BIFpT2KjXW/Nrl/xLb3zEv3b+e/zF6jkxC122fHD2kH+w/D7/ePktug/PkCvd8E0qGoyYyEbol4bdG8Jff++n/J3zP+Q3m0/5IlZ8Es54Hk74K82HnJmelbvlbzz8ET95+pD28zO9LxR8TykcIxCzps9SYWRMxhWw48umXeVUaO87Ap7+4OCSE7JkJCsLZkJhcfpctCVKc0qhvs3ABFAmlkjG56L4rHyc0lLHasp6soOCJt2gj967vM6O+6Moo5hNYbW+RjbyKjtOK6zjTOn95JmbjkoUMG5TxYtwwmf9KT+6ecznlycMVzWLD13RPOoYacrUcd1ZQjJUJvD9+ZyF6bGS2KZq0vYou1NxE+c875dctTPi1uPXUG0Sdl82VVC9yKwiLirC3JFqQ6zNpB17peVxDOXAWpQ1N6aowqqme2BpHwn9mz22CXibGDpHSkLfG6q112A4wf6RY/eGsH+ciYuI21j8WsjGYiK4rYXNUfqxqcmzmlx5zMU1OSVkGMDONciGA7DLR9do7+BrvmSGRCWB2gTEJlIBO8YyZThGUkBkDPyF7Mq6T0nH3Rpy7QgnDe3jasqM1DcRuwvKHDvVAhES9noDMZFjRLxl0k8cPY/fAN989b76pHdnM6YEHCmaApzGlFWkMQNzM7AymshSDW16aS8ZMMSi3Vmnhquw4LKfs+lqhs7h+gJ2Wk3PTwqOkslIVoF9Uw88aPa82dzwpLrlsVtjSHgTMJK5ms3ZB08f/7yAZ99DzljAbROx0HMmCgwlLxmYNAPhxhIHofeO+tLSXEJ9rQsgNIXSX0RkHjFVRKLHduD2mTRS8B5CowyQtRlnEiKZmAy3Q1N0KJHndkWfHbtU05ihPHgHpmBxR+rOdF96KgqYkePUVqEjNSqUgzzE6MOdrRBzBpd1AR3TpMcAqThhQEHQEdAbnfWk1Sl/mV7pfNuKOvwxEv0GgGd0sBHDOjU//3Ulx3oRl3zYPeST9ozf/+Jtri8X2EvP7HPDbAdul/E7vbFsoH1o2N82XG0dfzh7C1Aq88zuaCRic+Y6NexSzZAdVjIWda4j0GlKCD0CoYi5M+BxG3Uig7ekpNGCpjiyUvNxFPaWKM6oc4kzT7cyDCsIJ4m3Ttc8ma95Um9wJqqYOlkMWfPwxdrg2QfPB4OlszPAMnth8BuH9Q66AZwl1pbuxNI+FNpHmfxuy4OTLU+XG5a+o4+ONt4tav773/2feMPe8NTuWRlhyImBxLn9nLceX/EvnvyE/+Tjf53Vjyxn21SYCdXghZVj/a5gf+2av/f4H/OWXdNl+G9f/A1+cPkmV7sZ//n3/3vmcslDm/nN+Y/5/Tfe4R/dzOj+0OG3CTMkddJdQkI6RO4xkzw4H3ngd0Ws/s03DgDbFb2TFOa0rDu/NrjNId3h2oTtMiko62k7wXX5yEFCrNTnpOoAdhBdr2LAjkxP+UqGVHQ/klQjZPvxa6a6CbreK8P+kWNYZEKl6a9RAH3n+5yiXkOfXRF6GrxEKglchiVfDCd80a344npFuGiYfWE5+Wmi2hQxeWMYlpbuVAhLy/6kok+OhelZGU0dt6Lp+jZVU3S9SxXbUBOTBmxxBv3KYLua2Diy0xTl7pFjWKreMvkjRux1VtJFEpOmxop2BpiAVPfA054ZurOMbQLGJJULJMHVAb8KbN8+IRtDcp79Y6E/VbCDGZlSFea2p3rtduGJtSHMDPuHhrDQvap58QC/zfidPjNuH7C7QB4apOuRrieHSCYVzcjr7V1/MQnA26Rpwtsww9gili8C71FDZnumQLc/HZlSqC/8JLzO2x3hvUdc/WrD5fcLWx2Eh7/vqdYW13rWbzuy1Xk4/+MKd9siuw5C0kBEhDRzDCtLdyIMq0yaJWZVpDZhYtLvYibovUh6Of1iJL+kEbNosLwSM2k/h5wYJNPmTJuFdaq4TnM+6B/zSfeAz7pTPrg55+pmAbcefyv4Nfgt+K2+d/K6trNA9mCrxLLpeNxseK++5Km/5qHdlDWjpMezZsUuVK/0qa8GPP0wbRLV7UCqhWFhibWKRDEaTbptxrUoqImG2GgeboygJorPQm4iroo4H1VEGDKuzYRJ4FXEpyYrQ2cTzka8SSpwKpayoUueW5jU8rbA23O7wdv4NXf0NfblZzyPUePh98cix2Owka3C0FRSULmkVTBjhJkPqbDE19AyMqXEXrqE8m+SRB3yoNVsttfoTsWx+RuDnqHkT1XsbSY9gS0PcF/YsxfDis/aUz7cPFCw86KiuRDmn6vj8NuE24biHA3ZOFKptPjs6oTaasTTyMCq5I23qZ6iWQU96Sufr+mtQGOERe4Ysp3o41fZqMk4zJdMEbuUtA4hHkSTTU22tjhIISwyeR5p3MDC9SxcR5ccm1Bx3c+57ZqJDp65AWsS3kZOl3suekvf13Sngt863KbGDKE8G0cplXni0dmGd1bXvLe4Ymn1M7p0N8Azl442ez6KljfY0ogKzncZVjLwnepzZm9u6J+dEqvCrpaNJ8wM3aPEX3/jY951tzSi6cofXL7Jx188gFvPR7/6kMd2zVnuWMjA03rN/KSlX51o1dcAEop+Z4jgD4mq5MC6RC1B06XjvIims+wd6chY51JplaBKEFW8r+tBDnocO1bQlZTJyJqWP8lLEZ6r+DyVaHtkZ8eKujSM7FE+pLrG4GYUhI9p0SGRvJmYrmyVsU6Ol4TPr7Nzu9ExywZPpJEZW6lIGAxpSnOFZGijJwxW9Us9CvT2hY3BEWuj7HAJlEypjBkrvibWG6ZA0UtkZgcW1cB6PtCdeUhCshY7WKJXoX37CIZlJi4j2IzZWdz2DpTBqI/JWdebKVSFMWTvyPVBomB7oV97JslFEnKlgtTdaaTfOUxvDqArCWYvuK3g9jqXYSbsHjtCA/2ZAqPhUcDOA74KXFw2uCtHfe1YfpxoLlDA453qZwBygmTId3SoxwLwHTUpGxKCyOEdRvFydofnbWQHZQ7DIMS5Q3qnaUrnSJUhNkI+6VX+MBiS90X7auhPFMRhYHtd08ws/lqr2EawFhtHqA2xFk2dV4nKhQJ47igYpLBQ5gDckK/uU1/2zWOhixGd/5hhnSou4pLn4YRPugd83J7xxe6Eq/WcuPa4jcHtxyA64XaxBB0GSWZa28ZGGhdY2J5Tu+XM7DgrwH5uOpa2ZeFKWu0Vi/HV3jZEcBEJFrvtMacesjqm0YFIUBFhfZMYFhaQ6d81VZWnyAkBU0d8FXAu0pe0g9snzFIHbwRHoFVTzkbqIloe6bQRZY6beMr1VMGVsuYWT3J7p4k9pK7GnzkAlGKSDkzWGA2OudFsRAWWo+6m6EgwWRfAkY4HjsgfU35IBfR85bpQ7U4UzDBSfirqGquB7mqWTIshZq2cGYFEY4YJJOrYKcNzE2dcdAsut3PMtae+FJoXmfnzgF8P2G2P7HtyrQ4sVmbKSa8vZ3zszqhsZGk7Hvk1Z3ZHzMKQtRoros7elM+OBXyNAs5R0zDqeF5nEsd5pABFitYjHXIOIZDbljwETF2BM0rVzyDMM37es/QdC9szN70CnqHm2XbJzXY2Vcet5i2rumPhe85nO7qV4zYYurMavzFUtx6z82DMgQl0kJvEeydXfHv5gvfqCxamK9H93diQdZqxTg3bVLOrnvGuu+apTfRJaCTxht3xnUcv+MHJilgp66FjkxkWQj7v+Ztnf8pjI7Q5s82Oz69WmGcV1Y3hs+GMdd0QbYeXxCO/4XyxY708xe8MfhMLMEja88FpuokiKnQuTizd8XN313QWaLo715lcR2wTSYMhZ1NYVKb0cfQKftQpHwAIKCAaZsKwEMICBbOWQ0uBUbfjpARlTOuLsrZMVBBkS+rMhCPWdky5jaXwVdFL3LHa7qE5aEfG6LQx1cTC9BmG5FSnGD1pMPhp/SdsGzCtAmoT7AFoFZ84BhK2MN56yQmyo5GeufGcuD3nzY7NouLqvAZjSZX6qVRBnGWGxwPVsud03mJN5sXFikD1+huUksrKWpkl48KxFrwj1pZsVDdlW8HduAIGVMyfgdoH7EnPsDUF8JQguLB9dq/i9eQp61don2Ti05Y3n17zvfPPeFxtOHU7/njzFj948SYvPj/B7Sr8tsylMwoUxutOdwyQQVO22RDLHhS/prhiZP+TYypMyKLPS0zCEITQWGzlVOjtHMkbYgW+CYjJBGNJ1k+6oDCHsMzEOrO9NSTvaJyUdakp5lgbYlXAeJUxPlK5OD1rd9a22lFnxKHasexpX2dGFOxYOWiFBoRtrriMS74YTiew83y7oN9U2K3Bb0XBzj7jtwrmx7U8VU8a8C5R28DM9pzYlhPTsir+ZmG0Qnhm+9fqlF4JePJiRprXxIVnOPXsz5XmRPKX0jz6etuCayE7UXpqk/GbRKoFM+jizEkIgyUEgyuVFTI6mE5UD2EgVKq4DtEWMOOwJpGyKsRXpmVlW5oikFKNilYmjBv7XSzV6QB2DKpNKLqaqZx1lNiMQK7M+XGqcGR3xCaMV+2CjCXt6Ugw9uUJGT9ADq/NUciDKYBHx8jtsyLhNh9EXXcU2flSLtjy1THxErVUnDSNmSURsqEPFtvqXFbrjF8PmN2A9EeRQs7YNlKvBcmGWDn2+xV/tKsIyfDm7Jan9S1L202C5EYCYx3PLkWSMZAgifa2GDgM7KvQ+jSEYy+VsaquAB5JJZEsQo6J3A+ktsMYQ6wt/crSPsrwuOP9x1f80uKCR37D3PR83D7gs+0Jz56fYF5URayaCY8snMLC9zyZrYnZEJOhP60YroVh7vBFs2D6qOXMBqRKfHv5gm83z3jDXXNi2hKB340a+M/+5F/VXhOt4/23L/itt/6Qv7v6AxYm49F2DN9ePucPTt+jXzn8Hi0lt8LNLxveenrNt6tngAp42+wZLhvmlwa31Qo5gEYETOSd6pL3Vlf83upN6qujCzECbgxOhGQNsc4sfGBpW85MP6VsptTWHTFPOg3YWaBpBoxJdJ1nEEd2TlkaN2p7mEAMjHOvaaxYw/6xMJxkwiKRZ/Ggh+u0vF01c4cgRyL4jcFtVMA7+jRltvKUztNUgWX/RJmEcJLIdYRgkP5ua/FR0YmknNGkSNkAxRWNw4yLYcGLfsFt10BnsXvdFKqrDrtukbYHs0RWXu/dgjHqc4bsSpohsDL7KQpXTd2eJ27Nudvw0G953DziT6qBm33Dfl+RBoNxGecD75+tadyAM4nrdkYeDH5zh3s8Kj0X75mqoZyKa1NlkZhxOymVcWyukwsAACAASURBVDLpWvoHuhYaF1jMO26XnqET4oNBfWFvaJ6pL5QEuzdFU4uLjH9ny199+2N+69E/5a81P+PMaPXpj5d/xD9YfJ/fqb/Ls5+8rQFRG8heq8nyWKkV49QT55vYKMr3X/JTUy8ni5Z2JzBFwpC8gpfYGJIzmJyhUiYHgRgNREidVVZ/yEXwnAmriD0ZWNuK7qGhvvJUN5olsZ2OS3LjZ2eszVRWg5G7+NLRUqWpzeg1bZt9xrlY2PtSnDAx819d4H3ODNlyMYKd7gGfbM94tl6yvW2wV9p3x99SRPMRf9vjrnfkyiGxwgzV1PbG2kRjB07dnjOz49R0rMqeeWb2XJuWZRHaOfPzweurGZ58ECaO1LH2MNGJHO8zOdFyzlGcFVWA5Dqlg7Ozh+xOEmIw5GhoWt3A3T4g0SqYKBqVMWIaQU4bHCKZtnJTHwovYdqsB7TUeWzSdfsKrcpLtzgb9R3FARbAMTYwkggmC7n0JEAO/nt6oI/ZHavNB8c/Irk0IHy5SaFInpoamiOGJ0ZDGIrCpVD5h3JadcCH5/ZuO8lCAkmE3gw0SVmdHlvSRz2NlMWQIBlDbQKVCXpdU/52ZLMMOTuN4KoSsVll6vwuUV8bkjd0ruKL0yWViSxcx9yWiq2JatebaLNXgGIOcxiLwPqupuk9na9s5fCsiUwiW7GluZnV8tRUaZPBsEqcrvZ8a3nJe/Ulc6PArEuWTVvDxuNvjTILlUwlj40dOHEdt65nVg10ZTPWZyghWch2LDcVxCZWtuXE7LWUU/oyFnebw+2uJjxvaF5YftY/5nfr7/Dd5hN+rXqBFaFNmQd+h1SRbJ025TNCmHu6p5H3Vlec2x0AXdYqIHdrcTtdg2OJtEWwZM7sljebG/6vhikFIbn04xkBjxFNa1ZQu0Az3pP+FuCbzaNL6lT9gDWZECzD0X8/sBmqt5FSgUZWJx9m0K+E9lEirSJuMeCrMDUyjJ3RNHHS6DcXyl9Mpps5YqO/V8ZVq8LEA9mQKkP7QPVY+yeJdBqoVx3OJdp9RdzdNTVZkUhEMo307I5Su6NmbZ8qdqFiN3itThtKZdK2RzZ7ctthmgrbNSX4EazNzF3Pud1wZjrm5T2Px3/cmBpRH+BNoEuWy2bB7byhDQ4jqptcVp1WxEbH1XaG7FSc/9o5HMvZUwZXxLTJaGqrAE8TtYISUSCXClCVpGmhhe+JM8N6NiNVFjuL2sIjCvVtwvaFLfEyFQJ4HzUdbToaUcZB77U0vc1yYOdhSgGJyDfgIMv1j+v2KwqF/NK3Y4XflCEYGQur9zzqAiVEcqWpvmyLyy8tMGyvTKNmF9S/VPVAdwa9VGRrdE2u9d5cWxjHgFZWfcPqrNGSk4mh0t5hGeeStogpeiBz1JvNItjC8nihVApmUlYSYhMqtn1F12rRi91LIUhUI+f2EbsbkPUOmgoL2GGme3DWfdKZRF0qwxpJrIwjkpknxQFL2xHHlNrPsdcCHoLmr/XnMoFBKyh0tnRQYnUEeJIyPW6vFGycHeX6opCShaFQk20pG461dokdq5ZG1sgkjaCDVcATPV2JRsfuwXOj+oZdqf/vs4WjXgCvMjtXykbQQU3J6OIylpzGazlEI5MAkgOKzu5lsOOc0ohuBDxWCFFLrMe+PGPHZWMS3h6Qdx8snXH0eII7ikILmzaW0H4TqwWiCcQkrE2PzQ6T00EwXABPEsNAoDHDJBY/rsIbNTsjsZRmB8AjKWNbRetKqRo2u4abpqObOe3uTJ4e2NHa5DU6zZouPe7PY0tTq7uYFAfBWFI8/UImSl2s0VJbo9FLaCAvAo+WW96fXfB+9VyvKWs6od1X2LXBr5ko/xh1QS1cz4nbc1LVXPo5l/4gVhxF0uLMxD4Ym1nalpXdc2ZafHnA76pvScngbwyLTzISPT86f8wPzt/lN+sL/T1waveYIpo0Q1KmdGGpn+z4zvIZ5yYAhm1pGOk3uuGMlLvqPAxtTqxMy5vVjVZV+sKmxPI8lGqRbIRkVSuw8D0L02ulRiFQoJTD3hH0GJfxPtL4gMAUMEzzeyzyP/oMSdo/J8yV2eFxx3LZcTprcSax7iq2+5oUqxJQCWmWkSZSL3rmTce6aRh8jdt6rQyLmdhL2aQM/dLQnQnt44w87Tg/2fJ4sSVn4XOzYnPHAMuL1fSHxLJBHLSHfdZU1iZUbIeKfe+1V9MArsvIriVvtuT9HrOYYfqICbpuRDK1iZyZllMTaURoc5h6ko0shCVPIMBIYjevOa923DTa9HOUDTgTWfcN665mdzNT4fjuDjeYEmMjv+ysAn6TtVvy2JOn9DxSIKcTmU0J7IwCNyOZL+oVQ+2pq0AQS7CZaq3VhyMDkao89WwKZXNdZ2FIEUPkOtXchBnbvsJ0GjROcoKXurhyaEb4GrOSGaYMp/qoyU99jTRCjsTxUsB5tEeFECMDVgCGNqnV/mzanyZPYwZo471VYC3QG48ZnOoWO5BdKoHxWFml6bZvEnhAITEKu5M8YJXhqUzAHTE8CnwOZhAMFo9QSZqKT9ro2fWe0DlMa3D7Q+NW22VMF5FdR95skKBryQwnLwFFV7IDjQQWRqiLKH9h9trJ2QyvlQi8GvA4qw2j9gNuV+FmhjCAUj0cSoHlwPhI1JtoLiP1RYe92hFn7tDsa+tU3xJEKbiINk8aS9THlJHVyo/GaclZ8NrEb+56nNEuo9tU4yUw55AXj6Oo4I72+PxWB7eAnj5ausGxb/3UHDCJ16lMet2TNqP0FkpVRqqEqwLeR+b1QO0CC99PgC1kwzCCHpS2rW2gsQON1R0nIexCxW3XsK4qrnqNSu1eDjqGUiZ814qCY7NkFtLTE/Fi8cQpuhxLDWNxGm30h34Go8wpqYPIzhDmjmHlGOb6LNhOaVVtS59xW2HfOtrgSNkULc9WUzklfbYrfUGG7CaAm4rWCAK2RAqvszGisV3RePUlrz2JJ5M6Nud02VeeVBlSJdgqsXA9p3bPQ7vR6wo1N92MsHPM1prmCHOdA1tFzmc7vjW74J3qEm+0QuCj04f0q4p+ZZjP64kBC7UQ60wz6/lW9YJvuSse28QHoeKj4SEfDef8xTvM3b/8nX/GP4z/HO2mob6Bm23FOjY0pWFkK4GV3eN8UN3AkOkeOLZvWn797Y/4leZzhgyDZJ7HBX/avkl1q2s12wO70OZIBE6k453qgnASiZUrlUuxpJMMMnYYNZBmkdN6z8rsdRrz4XlDuHvH7AQhWPrgcDaWbuWHYoEx2n1p3qNGtLES+hPonkT+wlsveDpbc15tuewXfJDOWW9m+BtNW9kOdk7Ip4mnp2u+9+Azfnj7hJ/lc7L1kx+yfdYy+KDViP0pxLdbfv39D3lrdsMTv+an+0dctTPW8W7tBT4Mm3HYuEmW53HBRVzyeTjl2XDC590JP7l5xOV6QXtTM39maF5k6qtA3u3JXafHIwwB20Vcm/Brx/624aPtGZ+GU1q7oZGo35dCAWDapPqsx7xchQVXYc560GNe+uTYB89+0M3pdjMj3lYsfupoLlWn+VrresZKSLwjhzj1mQFlVkzIExt63OpklDwYyTyuN3wyP+FyXjGre1rxBOeor9VX9ka1LRLB7CybL5b8b/0v8dPbh7y1uAHUn26Gmh8/e8Tw6YI3Po1Ut4OCkK5T0fIIetw3a6hkyVRfSkdLCQxHMC5RM8Bj7yhlSJmOnQnNgS2Ni4owKwU/komlualrE24fkZCxe5BBe+HMZy1hbtgDw+YgKLdtwhetm9tD11r6oMf9KNi9W/XyMFfWLcyE2CTMLLCoex5Uex64nYqExz5rX1reicyAHjO0jg23odHqqdaTW4vbq+jc7UuX+CFpZ+99R7jdYIaAEcG1CQn2JT2tkUQtEY8cmuUWGzW9x8VNX7ZXz/IYqdqMCWliOZSiO0LrhbbTdFeGAar1gL3cwtUt9tFSN8Odller4p4SLRbmQPXOE0LOogIpb7SpUG2hi0q5hmS5ifMJPcKhpHrI2vPE3vFc1MfzrQ5kSbXsQsXOqThvCIlBHMElchHljimtSdtTmg9Yl6gqpeNnfmDuVQRbmUjIZqq6GJ3/SdXS2IGl61mU3GPKwm2YUZmAyIJ1PSN4p5VrU6v8bw50bpKlzZY2O25TM/UCqSTSRk8lkTNzCN++6E94vlvQbmrqToGp7TLuppRAWqF9UtM+0KhXojI7khNjqwIzQN451vuGi25OysLCdDy2a+YS2GXHNh9EkBFTjqxIeKPM3XgGy+vMDIdz2SRJyXtT9Fj5EM3B1Gtj7PpdNz0P6h2ndouXqOd/YeiiUxayHBuRrYpb46C/Swgru+eR27Cpa/y8Jyw9w0KIM49E1X3k0kfeSNbmb9nhU88HwyP+ZP82H+wf3mkOv7f4lN+df5tsGurrRG7Lc08mZY04t6kmBjtV8Q1zQ/sIvrv8jDfc9eSY2uy5HuYaOZac/ygaBz07zUhmYTqtOhQmIeq0cRV/QAZ8pjKx0NhMZ7JNguU7Bpc5GmIUQgEPMRpyKAC2bBrHAlBJeUpTZKuiZ7MceG9xNenGxiq4GAz1TvAbdbTduTAkobaB92cv9Fy3s4oX87m2gegg9LreU5RSop1ZrFrenV3xRn3DyrT8TM4Zgp3m43X2PFbTOG+zZ5sr2uzZxIaLfskX+xOeX60YrmqqS8vis8z8WaB+sYe9FmJIVUHlISXcPlHdQH/l+Oj0jH90/is88mtWpuVFWE0FCuloPnapYh89+1ixDRV90gh8O1RsuprNvqa9anCXjsWVsPpQz1Zz29cHHzkmTSEfB2RfYk5iZRgWhn6lwvJUWIRUZZwt1bgWvE2YKjKrBnIWWqdp96nrv9V9SFqwF47hesGHL2Z8uHg4FY0gkC8rmgtDc9lht6URYdtrIcPUh8ccyudfY6pRK6mckp6f0igF9IxsTo6HQpNpjIRyBM64p2gT1FiaFKo4GMZWCpRg05Q01TDoETOjPGI6l6nsv6PQXqKZgg8vkcb0Uxf011l/cjjbMs0SdRWY+4GZ7af2CdOREoAp+20i0+VhKozYpZp9rNRnRjvhh6+w8KUppak84vWstfHIEEkHKYglkRAGErvU0+XAZfQ8Dyc860+mMxp/nr32aInJonZcHi92OlNobIZX6DsT9Ku97ZHbDfHqCrN7gt96/FZKx1KZwI3S4ubQt2CaQ/3GmURVvFwXXem07LgJM80Nmoa+CPVUe+FJcsgXv86eNutS3aAzsAkVt3ZGyqJtryUTWqepKyMvN0YULUXPJuN8pHKBRTWwrDqWvuPUt9QmMGRDSJZ9DBO9f17tWDkVXi9tOwk9r8KisAbCs2rJ4MvGOYrg7nhfx3Zd+t/0pRfHcZXWaKty/MSQHZ/vV1xv5rB2mFId5vYJU5pd4R3D/FQp/kcZ22tnbNsLfq+L2/Zgd4Z2r2f2RAwL6Xlse06NZZd61nlgl7QZIRkiVjdNSazMfjqb63U2aRz2WsZv22PRcqnUilGdWgkXslXnsmh6Tv1+6hm0I2tFWdKSX213DtHr19xb2uDYxYqF6Th3G9rasVq0XM3nDAujjGYfwUrpLzVuNCOjZflp94QfbZ/w4frBnebwO/XnNNVAB9TXCdOOTcDU+SZ0I0tRSlWRCiO788h3Z5/w2I7AXvuyXA8z7WqaMpjDOXVj5mhkA7EalR66nxYbS9QTiEtfKXudjg3J3LlSKwchRY1IYxZlGMcKpa5UTRW2BVOKCkqfENURJuaLjvdmlzzya7xEng0rva9gpmMp/C5jW0MfBW8jb/lrurlnGys+Xz3EdBZbmqEh6tOGpRCXgbNZyxv1DY/dunQGzwzRYtq7LcyLuJjEnjEbbddQzpS7DTWX7Zzhpqa6sMyeCYvPeuqLFnu5IfW9Vv9VXjshJy2xrm88/bVhdz3jBzdv8bDesvIt26Bp/WOGLSGsh5pQmmrqVJYKzuDYdZ5uW1E9dzTPhPmzxPLjDrsfMPs7bJZjibdhCphfOopDVO/ZnwjtuVYd5fKMpSZR20Qoxxc4k7A+MvcDMRmsG31hqSCiFHTshNkzTb3GxhJmdjoHL9YZvxHqa/CX7XR0BsPwskjZCGK+mXP9slZkBFgIWjVV/t32TKB8wibT0UsKeJI3Rbyd8UdBbT46Z2isKAyDpR0cw6DHKNiiS1NJSEKiOezJemvlKIhhSme+zoYV0+HH0kRm9cDC69FOY4dlbR+bOYb6Q460ObJN2vNtHRWAdMGpLmkEO3L4oxWXBuMdMpshdUWu/SSR0YrowzOkBREZGFinzLN4yufhlM/aUzZD/efvw4O1jCfUptpqTq9EUqCDPwl3k24g2SrSTHOPdY6cMrYbcNtIfWswvSW7TLKZ6M20gU/C04y22+6Efu95sVtMwuVdV7Guaq6qOV/4FYaMM5GV75jZgZnp6ZKWXZ66/Z0m9v3ZxUsO+crO8ZLYB69p2CzsbQKjoy8F5DGWopbJm9U9y7rnpG45q/ac+T1nfsfKalQWs+EmztS5YHi7vuLcbjmzOx672+l048/DKXPziJiFn1UP2LmXO1rrRUBG/pxprbGUUhmVdZqxiU1xujUvwpKPbh/QXjdUN5q393sVltP1WmqatIlXNmPn7Izda2m6pHRg/KIQSzty7fsTmIuwlJokLeucy0FyvpTkOoasvXh2UkM6HNL3Kqu2ScFM0ufTbzL1WrVh0g5IV5xbLq+jbJBN5ny244lf89BuWElgLYGEoR0cpld2y+0SWYxGX3vDpq25DQ0ro7RuIwNvn9xydbpiOKkZVlrdNjo3so7Bz7pHXIYlAL93+y4/u33A5e3iTvP2o+4NtvuaugO3j5jOsom6oXnRsv6P2nPSxuMV2xDmgpz3/LJ/wUoCQ1aJ05AtfbIanIimgw69mDRi86Mu4TidmbUUPYM2bSsdXp1XYbqX+FJ3VUu8s0YJQDpLDIbdzkEQ3K1ldissP8pUW+1BE+ZadhtqwUSdHxOy9mpZRh4tt5y6HSuzp5JISFY7r/ZGGcDI4TicJAxRe0+96a9ZnrV8/u0TPlo+IH7eUF0zVWyFBnCabpibvgDkgX30WlVzx9s8MYd2GVuqEugY7eo9Xti4GTpeYkfy2NumB9MPGGvAGWyvwZidBf7y2ce86a9Z2falM41GnVBE/dB46nrMhi45dqnisp/zrF7xzC+52p1iBocJBttr6wLvvhkgkH7QoxwqryADFRrvHxk272TS2y0Pzzfse0/XeiqXOFvsy9EyCsKdSzydrTFk1nXN+t2Tyfe4VnA7qK4zJz/roWjzhrmhXxmGpQIrv4bqJmN2HdJ22m5FRI+fKKOj4363+1MNf5qApCl6wzGllQWqTZ5AulZY6TNr96ZkOEzpHB7L9RQR9qwUu9h0dBSNauZMUKlAd1mxWesZVLYV6iuhutaybukTpj5iVg3a2sUMWuhzxwe1fSOSXQKfOTnb8WS54WG95YHbcWp35fTzQCOJRrQcPebMQOQywRdxySfDAy6GBdf9jG3vyfHl1jPRC8ZDqktPojjHAqnypLk2kszHgkD0+dUjijRN90l4wI+7p/zp9il/cvGEbvAvHQj+ZXu9aDnnKTUwqcydDmaSXDoiavVGmB8O3BtWHjdvMOVhN0OaWrq/NOaZgkoP4iRJYHoh7B3Xm9m05ofB0g+ObnBsfaUVTpLZFEalsUG1Mnfs3wKwLIBkpJm77NjbCm8jPiaMOSpbz+NGfvT9qOf5kk5hbPRVm2E6+sInLZE1eSxl1CqpsWInSuDWNOXhTAeGtQjgRuW/fp/v7GS96Am2FtETbWESBR9XS+1SpQcOlpzd2G8kNMKwcPgHJ3pejTW6OD1kn7VLqnBo1tbnqUEi6SCam04YllEvJGxTfaDdsyggKZVag7ycv/15ZtukBSFiFPDsMrbVM2hkCBACU58N4SsU+3ETxNHSyPCUxnRmSudKGdPE2dHmdVbtcHUgNpU2/ovmUN2INtHcRL3XLjmuu5m2XLhjivJ/+OwvEz6dc3KV6U8ccZF46Ld4MUS0o+n1MFNBYKt0eayhbgY8CS9MQstRlC2jCNlALaOO7GgMsinAXhsYSkjkog8aU4TZCM5r5UZVwHSiVIZ8M50kRBBU1G9ao13YW/D7NDX/M0GKz2E6umAMuvDaq6ORYTqmAaAbHNIZ1ZaV0l1NeQqhAPGq6FuezNc8ny/Yz6oitIXxPDLQIoqV2TOXbqpEeclHvMZWptfqFQSTNcjZporaBA3a3ICZBeLcMiykdEGukH6Gmc9LMz8hO6tsR0l1J6ei0gduy7nbcGZ2LIwCHlPY75FFXphFOQ/JTL2uhux44BYsnabi/6iraM2M5C2pslQ3hmpzh9PSnVNglop2zh1SoamyxMbQnUJ4GHjr8Q3fffAFz9slz/cL9r3HGx3olA3eRppKTyJf+I5F09M+0DYZo27P9IXdbQuIiYZYmaPWAuVPzGDHarH8sg/4knj5dRbzofrtKyXZMpIBTI30AMJMT7Y3RayNFJ3hyEJTiAOfsCapGzz2VVmLQvwGsrEH0XevYK65SXoeWh+Q6A4MSoaYtEnvLtXszN2IgNxExCWsT8zrnpkbWNielW2nvjeNRLxowGUwDAwMObH+f0l7k55LsjO/73emmO7wDjlUVpHVrGY3W2rJDdoyJAiGDQOCAQP21l/FH8Jb77T12jDghQEvemsYsAAbltwi1d1ks1ljDu90x4g4kxfPibg3i8XKW+wDJKqSlXzzxo2Ic57n//yH5NikRrzDQsMxOHw0JU+S+VxJFcQAodHFt8+hUnnmGiM+V3O0PPNzMWJIyRUuWsc7v+RhbDkOFX60xPCHcngK4VOBFCwFjprUSUqVAicptM6Etsg9FYxrQ71o0E0tpLWUOZeRyrMxSejKzHEy6aOMygbNsK9m806CyENjVLKJnXWPMWv6Yk74Q5YolE5KiU5X7LTHKnnwzHQgnRU7c8EzFWlpgoWlYwxZz+6bU74XWWNU+p1AzHP1hC68mvMQQSjPbjr/dXmxM/0dFZGEplKRSMaVaAd3djDEwjUyOqNsJrlMrBW+UwxXBvdigRplc/etSEKzK8TziVMxudOOMl7KZwjPeWhoJOOLNbsUY7L5a+TnT+O1SxAe009RB/JPd0iYPsHoxbZ9cln+1qhTFVLs/HPUaQOLBW0UPlKBiSeerhK12fUcdX7g2h2p6kBflU6tbLSTZUHOQqjz0bAPNUOU59fayyDmX//tK1ZfaNr7QH9jYDWUsY3BJ0+fDffDAtMrzBCJlZiYLZuRSiXpnMqljlnIqbqgHdlQ8mgkA2e6/ogqeW/MhoMKIYDLKEwQXWvjbDvwD1kqqnlT1KOaHYZFxVHUJ2NGu4yeHI4zRR4PqniOaJVn24qEcIJMr2cJLLmMGYK8r5WK0rHieVnv+E0zcqgSyZp5HDntW1YlFnqk0Z6KiNVR9qcLC9erc4+QBL0eWOiazgws7MDCDTTdyKG3+EExrDU6OJRvqJYLGcWIBT3ZGJEll0OkcpFrcxAXWnOgSnG2gJhdzcu7Pzk6y72WINMrI+jYrVux8zVf2it2dUtoHdVa47YX7K3WokIgUxDBVLIFjSY7TWg0fp1pb4784+s3/Mv1r/i7+gV/a1/w+fYaV+4fgNPC36l1EIpA0/PFtTxzZpD995SwnchKoTUz8p1VKYpC2aMKT0QAmrNndcr8upDD88GnXMnfaY4Jux1nx+JYl0IsiPxex9PYPSsRReAkWWA622aKRxJzvryR/789luiTUUQi1VPAbkfUEDlPXidDiFoiRVLN/kJBj64i2mRc4e4snTyfXeFVTuOxpkjRp+VzZp+reXKwDxVDsAUFFcuHZIsVQUkwCI0gXlM5IsrPYqDoyihQ5Vlx2CcnKHx2PMWOfazZ+1qKHa/Fw+73rIuiJbI1IoEsLWLsEpNJX6yNHL5BLPpTVRQNC8n10NNLaUvlnaaD4MzWvcxSU+FVyGisbGZDqQyjEsKaylApaheK2RasqoF1JdbSPhkWdphNiD60phyu+UarEwEtZdksc5ySmuVFm9JoU1025V6z3zZ4bzjUQtDqg+MYHYeqEKBzOegKdC0mYWY+5KUQUbwJK96FJfejdDwMJUurEIdN2fh/yGrOXIzh1J04Fbk2e3y2OBW4s0tW5pq/Wz0jZ8Vj1XFcO4ZnhuNW09+24gOUYf+xYnge0UtPKp2fkNaTJN+OCh1EWjmZRU4cj5iTcEVKEQBSbNTF+fmHWKCDqIdEFq9Ay4Gvj0Eg9WGEYSDnjLKFmJiSKH56uD923IdFMV381jNT0DRgjohICxmbfNbccavl9dEEbtyBtvIc6oQvNgwqKmIr78vV4sjP2teYolBrzcg2yIZwyfrRXyqqzYg5Rt78p4Yfv3rgH9dfsU0j9wk+D9f88quPaO/lWRnXhvEm8Sc373BKzAZ9lg3p61EMwNZDJhVUdqV7KqaoD7lun60UPIkZ0aGYGWZniZ2o0q7bnitzxKmELx5Kl/oLvX8f1dzV2qPCHWQ8aQ8R00eJtChLB5HET6MAshTXQ7DvZbDFLCRPM3t+iTeS3WvMQbMbKsZs+MQcuNY9P23f8sXymsd1S1i68hxP3MSTxL4i0pTndOZuXLBW2lCOXBIBnwd6feTW7Em1jCbHZPm68jx1Cw67llRpsqmxuzXqIOqiKQST0vyoJCTvfao55JoqRcZsqGBuoqZiflFsPCjihYl4e20ONNpzbQ6kG8VtfeCrxRVv1wv6Q0V/gddQbiqU16ihcO8mDh1aTCorRWwT183I83rHZ9VbIppjdHy1u8KoRKULYlgihayOvKh2tMbztz/5iPDWUT2qM05WmouKZDS+1YRWCLfTn6l2wqmjcmRrIEQ5d1K6mO85LVdQv1hQeiHwvl9k6JjFeHQMYokRz4qwXJotlUlWQ9uICaGTot2cEa7FhkQczt1O9tZGQ3PnN4c1dAAAIABJREFU0UOUJPUEevDS4CklwcUTsFCa8Puw4K1ZzaPrH7KsEo5ep0ex1TAHrvXAlVZ0yuGUUIn7HDlkZu7OU2jn4OUYNUoLXys1CT8ZTlYnixDbmjn7LlmJh4kVJHdyePbZcMiCXEqzLBMEpTLGxuI79Pv3ng9HS2gt/gT5BH+f/AVOhMJJmZOsAp2JjeR6uKYRaHOGwHmPkyLdiT57YAWenRvvXCriUDxwStV51fY0ViTdP+4eZ77MIVXUKvyOzf3vW1O2DQipdNoUQtaiWDjUqK3F7hR2L5kfphBiBbCQzz0uDSOQosjPt0PFO7egdX5GdFKZSzsdua6OdGakz477uJQcq1zxN8eP+NXuOZ9vbti/7ajuDfVDcTouPAaxAVDvkQG/b2kytYqCOBVIU6uMI5XRlvA2rvWRte55vV7TWc/XzZrNumGzbxj2FbF1szP2eBthGbAuMqb3oe7Zn8VmsLmYVfmiBJq6ysyI8JmmYqhRJQuI9zOBPrRUTOhcVAmA9hHlU3nuzhKRCzFxTkxO0v2EdBqBTuS+2kYObjJFKyM8q8DkMgILxVNFSHtzroyaZtQKpTOxAqrEuhr4kXvAqYDPItU/pIpDvKzgqe8DKmfCwuJ/2vPPnn/Op3ZDnzO/9s/4P7Z/hvptS30vm2OyhtQkSa8/W302PISOY++49pmsBQma3hePvOsJxZiNjPAyAq1PqpKSi5QqTWgUV25kaXocmX4aZ5XvQu71Zc+pKsaeKEr4K4WoLPldystYy2ghJ6hi1QBysKmD5d2h48vhhlRpVuZISEYQmBIoqr2aUVoVFGOws3/XSgWe2w039YGm8cQyulepEOGPmsdjy9uwmkfRM2p54aF5SOK/I/dC0Wc7c9i0SrTGc1vvywhA8XRTo4LGDJp2WcmGfVQn+/2cy5hEMY6Wr8dr+dlGIP8p0bpRfh5tbZMIPsby5U3jP7km6d4/a95R68DK9Syrax4WLdv+Mm8zYOZ/CuSiBOEpe79KiuPo+Lpf85vmBV+ON7wdl/TBykivUBVSEQ8YEmvbs7Y9q9s923GF6S31Q36viKWEcoZGiNHJgS1y+upegrCzmsjJ50jbDy/ONVDNvjCCQp1PHFRBb1QQZZn24h+kI4L+Znm2Vcrz+aejNPjxDHmeFJfZ6KIUFRm3uz+gjqOozYq3GEoKOoz4xslerUhJhD7+B9i1pCACjxj1TG6f4imk2I/vycJjzrMy6zEuuA9LNqFl7ysGb4lBgIuJV5Sd3N88Jw1IJahDaWLsNEEo4AcUwdLpuZXJQJ6LY2sT6QMRIR9Wac3FzkkKqIrjo/ZqVvEYnyXZu8pEK0ZgsdXkrkGN/kzWynu/JAhQz1/ElFUzTz8yTBEL2Wa0TTSV53m748r1XLsDP2tfc20OrMyRu7B8b37/ofXSbOfxSZ/dPEry0XAcHX5XUW001Vbhdplql2dOx/Qhs1b4QZyUfdCEQXhATya/1/gZG6kq8TM4dm5WZ6S8ZhsbHkLHXz19zBdPV2zvF1RvLM2dorkT6217jOgxSqqxOm32H1piAKVm0zEhpUKlFJ0ytEoO3VU60qkHNt1vubV7vqyv2YSWt6sl744L3rQr/GjIXmM7KXa0lmp9lgcX4qCEOwo0KqZ0AxVibAcT4iDEMzFhy6z08RR8eGHkAsi4RSkFk0FmOSDfs7lXSojn1s7eF9MociiBpjEL5N9o8VFKVcmmaTShlhdQmYQtNv4aTUR8a0QxNX0HglYqLcZouo6sqp5X5ommBGyKQqeiz5cVPOYYCCtHf2v4T37yd/xnq7/hhVZ8ExX/rv8x/+e7P2b5uaJ9iOhYfE6qxKtq897P2WfL1jeE/ozD46bRrpBFncr4MuaYb8Nk4FgQHlUQ21SJxcJCD6Xz5WxU8sPGyxPUD0WC7osU10+KMPnnJNyL6Ll4sTswO8121/JFL4e+dwaftZh/lj1Jx0kpKp12jHoueBZaSfSC29NVnqdiuKhD8ZY6KJ52DV+MtwUdPRDKz790pPWY9NxkHJLI0g9FRQlSeN5Wh7mQerha4XvHeFCEpdwzE9LM7ZjIrHqEeLR82V+LwMNVc0Bwrf3sSG9UZhub2cJDq0SnRxo1lqbDszI9VYmcubV7rt2Rd82Su+HDBPsJrReujJ4NB7M+yb5VgP5Y8fnuhn9ffcLbccmb44rBS/ClK2M/H8WTCWBleq7MgR9fPfHX+4b4aIplRMIcghQtJW5Emm3Zf9whUz167LutoDvf5uqcW1ZcuGI+oaBOnUJZ9RT6nEuxU3hMqoT4zoaLEXISoECVezl5CqlBGuaM/PxJcTmdldonbB/RT3vy/kA69qiuQ3UNualJVZFzF/oDUfilEyH+4n01yJ+MWjhAwFmjJ9ydyV0ZYMiBQ5Zk9LdhxUPouB879mPF6K041E8zdSVmvQnZl2NTip5c3s0ChAiHR1AhYG5M++QwKhdiu3z/jfFUNohX8vdsOx9WaVWO3FQMtzW+E5Jc9VS69yzIQ3sfcLtAf9tK/kaVGa/g+MxSPV/hPn83H4YwkZYyyejCISgV6ZiL86Yi6EyoBSHIOhEdqGWgWw5ctz1/vLjjj+p7flK95U/c3cyD2dvHH0Ra/sgcOWTDPkdMFAVNyopjcBx2NfbO0b5WVNtMtUvUDwFd+Ax2Z7BDSfRdCL8o2ywF2kRonp4vDeMiMSwDYWXYryr2pqbRnm9Czdf9FV8f1vz9V8/Q7yq6d5rV54n6MVI9eexWxi1ZKWJbgubqyw6Ux1TNMQZNIVoCuHIwBSKxvPSNSryyTzTK85F7Yp9q3rRr3ixW/MK94vHYchicvERBM/ZVMXQTN9jYaMaFZrxShOcjH91u+dn6LS/Mhk4HwBCIDJm5s3VZRgNGJRzxIrPB86XCCUEUK3vEMPN8lXgJnCXVUjBqD7t9zReHa361eMm1PjBi0CSet3u+urqmf2ZQQRM6xXgFVetZOzngE4khB7ZJs4s1Y7AnonPhNU1QpdWFxF6urdEj29RwSJcVPPtPWx5+phn/yZH/4Ud/yVoN/E1w/G+b/5j/5dc/Z/jFFT/6lS/kTYlZsG3gk+qhkCxlpSzjgzwKqToZiJWMOysSlUrzIzuhVvIcF/g/qzJGyWSrCI3iZb3j2uzFDn6ar8Ds/XKpUsuW/C8oiMpIkaGr08GpCrcqJlRf4P6UWWkAyz52/Bv7Ez6/vuHT5QObUUQPsU30zwx+odFBfEbCIrKsBZ1aq4FOGa71gbXtWVQjj1KLY46JNmZCa9mZBX+5/kf89Oo5P2ofuRsWwk+4sOD5+3Azo5h9dtzFJfdhyX1YzKopp0T11ldWQlRrK07fFPSyl71AAShFdVVRP2jGO8df3b3idbfitj6ISVsZD03+KVplNqGZ4wFqHRi0o9YVRmWSlhic6d0E6exvK5G6f3D5IMiOOYO8jCa3TuJAkgSAjqbmN8ML3myWEr0TNbo4zlc68DB2PA2CLm9Cy2fNHT9yD/zz27/naWj4autQ0ciY/+hJtbi+x9YwXCvCUmTq2mfMYYTHLdys52mFCkUd9R2Oy5esiev2Owj0PAKXZzY7S3aG0DnCQsu+M8qI1AxSwDMVKAH0oDgcauLRyti2oIyUmiA5RWgtdrVAa42yVj57ygIsOFv+fmafOK2Fc6hVuhjlUUdNtqKyPXixbOinxnBqaMjEHEg58zZlPg9rfjO+4Bf7j/nycM2b/ZL7xyXxaCQRfkJwz74ntOwj2QkgH1o1f/5U0uan/08oxU6fKxrG+fsX6xpJN8hZfe+t/EDBo2c1gCokXe1PBzpMsF0WuHnMxSRMSdBZC37tsE1FrvSMSGQ4ITpTVtRECA5AXciUlXgATLPIbjlw0x151ux57na8sBueFVfR6fUyZC4bZsn6dr07FQYpq/k6dciF85FnLoGKSWzCK41zCreTbvdb0535oZvgvCk/S/grml2oufcL7npJJ897i9tqqifxW6m2HnMYUT4KjO1M8WxQc8bRh5bPBg+n7BOVSDkXPkkCJMzTZxl5SPigJ2khYnd6pDWe2oQ5G8yPlnSw6J2headoHpMYk6kS/tqAaaMki1vZoPtseEwBnwNvY8s2tWffu9yJKWAUKIGwP2AjKrvQ7LBc4HQ1pTVbSSbORqOjdO1p4/hqt+bXyxfyLGnPmI2o/hYjw00FWRPbTFgmPlodeNlsSzDj5IEjhOycT52VSsJ10qMi9Ya3xyW/8c9ZlZHi3wyv+HK44d24vOjSxqWi/zjyLz77e17oAx7NNjb8h91H7O461m+VFH5I0eCXiqr2s1R8ej9mMnxS8zM8fe/SrcqoZSymnlOWk/JxVmyhSmea5Qev7XEmwQPzqPSHIjzan8bdsyJRPpwUPKSiUFJzFIH2Ed0HGpDRY6XZ3La8NaLY8smQkgJTTNTKKMivIC8jN92RP3J3JXnZzt+FVuX+RYpCDKqNoX5QvHtYYYqa6BjKC28vK3gmp9tYRoZTl9poL+Rhpd5zP2+7gV3niguvIjmDVkoO7HJQmyFhe/Gh2h4aOueLNYYkSHdmnL2+4CRUmKz4a+3ptCA8MWv2uWabGu7DkqfYiqrQdzz5C+IzYpzHn6QkRHQln1VH2UerjaipQu847kxB9TP2SiIlWuN5HS37oWLcV9wNHU9ty5gNz+2OZ+2Bbxae5MxMfchOF3PYqaEWAY0OGX305P0evWhPhY0PJwR4Mr77AUWPOTu4jUonbkz531OJ4dHOkBo7o8ST7YrtM+YY53d2UuGSFGk0goaoMimpNMqn8jOF76LHBW7r0LtKxlplz5savfMJSc5Q63BxUDGIh1qqBIXpvRVD3iR8N+HIgc8Jn+W8/abI0L8Yb/l8f8Pr3ZLNtiNuHLoX89BpeiXvuPxmEv1Ma/7cZR+YeJQpq4LGCzJpEN7pSQ0daOwZp+73rIt8eND6DDotHxzKB85lXphmmVwcpTILjcIvDU1TE52eN5vZeGlGuPLsbzMpfrLJUCWq5lS+XHdHbpsDL+sdz+12Dsqbzn1/2Z7z3hrPDtXpsJ0IaLkUYsJPypixWGCPoWz8CnuUiIJqo4iNmjPFZn+i4qMzKdu0SbMUeUyWHXA3LHjoWw6HWlCjnSBn1dZj9sXwKyYwFrSeH/xYXfaCjpPPRKk4G2LJckqzZ8pENp1S541KNHh65U6QrcrCefGWtLfYR0v1qOheCxLltp7YWqYos7oZWViRMiY021SJm3QWA77H2AGUmf1383Vmbsz3rMmRE76F7FiDiiKTVc5JmGHpPPUoBnTuyfDwtOBXyxe8rLbc2D2NGrl2R26XB75+5hhcRa4jbuH5dPXIx9UT1+bkTP1dRdlUwEu+jeHtbsEv+k8k70olfrH/mL/f3fJ2f5kPT2gV9lnPf/Ps37LSiaekBCHoF+idxW1zGRkIrB46aCv/OwRwUyTRnKn+pqWR5PV9IZP32cnYupAmQeDxOQEbea6v7FEO7PIzjMq4IoGexjeXrEn1OB9iatogywGKnoudrBQ6JVGl7Hvs4GkrTbIVx5eGfd1wVxUPr8m5uQJVOAF+laiXAx+1Wz6xT6zO+HCaLCjoZLPQy3dYbwyxNhzuKt7ZJZWJEp2SNMpcdo0r3dOLvfysmmyUh7N4j6kYcSqybnv2i4bQGUKtyZUojc7RCe2jIB29oh8sQxRRxLNqR6el2HlWuIoRzdL0VGU0cR+W88jLkOf7fh+WvPZr7kd5Pt/2S+777oPXl0OUgF44OfUXaxPtE3ZIVE+SoxR3iljkx7HNpLUggp0eGZNh6B3qYLjvFzz4jkNdc2t3vKh3dMuBWLWzU3EyZV80U/q6jEK0zzB60vGIHsS4UT5bnOXzynx4j7lknSurcplcZKdFYt0IIq/KKMvt5blSQYr4yWZEZURlFIXAL0olEf2kMpYV83Dxqakqg31QMPpTESwfptwQsdhw+qR+u2TZo5JEnqwZBnHh3oe6ICzig+NyFIf34h/3tb/hi/6Gb7arOZbEbkxR0p1Nd4zsVfP5X3zt5DfM3+EsGkliQjpEK0KgVM0Nx6RArI1ENaWs/vCCJzs7PyB6iNiDjLQOQaHLpmkHQT30YWTxOmJ7jd1r+pdyceNS4Mxc0o2TVVIElGBMFfP8s0NTEooL9KVdZNEO6IKK3LYHntV7rt1BfACKX820zlGeeCEb/XVczpyKqXqdJOaTJFcKuYw5BPTmKAqEENG+xUaB1JNVszrAL8UDZeo0shOJN03EVhKOCBR7d8eb/ZLHTUfYVLRPkt1Ub4vSyBfUpK2InSN0luFaE1oZJ1yytmfBhj2ucJxkw5t8DbapmeWpU6fns+UuLnkXlrweJG5is2tJDxX1vaZ5J06s61/t0Qf5TsKnV8Qa/DLxanHkRbNjaXo2qZmN0CbuypBckTiOp41/+pzzi/Vh749wXYti4RhQ4+mFz10DdTXLPicpr9kOVIBKFd1Xjr1p+Ss+5lm958ftAy/dhp+2b1l/dOTudsHdsMDqxMKM/NPlV/xp/Q0v9AGjHA7NtQ58Uj9yuzjw+bpjXDlUkgiD5i4Dhv5wzf/U/wvaxlO7wP3TgvRQ4x41/LcfvofVNvN4cLwOV9zqqpBQ7/nvf/K/8z+a/4p/7/6IamtpHiRjKbSZRTWRVTlrCgyPQ4vZG7T3s/ps+u49wvnqs+NtWAn8XsAbcbmdSLp63pwmL5cEeDTkdPEY69srF26fcLkla0glhz1MmUKpWGSUAteXrCYfcA+OTiv6m5q9qrhTK0wVCVsnHas7eUvl5yMf32z46eJdkWorWlXNUvYhWswoHBD7eEQ9bLAPK+q7BX7RcTgs+M3BoUyWA+p7pLDn6xMz4hnxGVapn0nL+1QLZwpBYn0Wr7G3Nyt6b7k/GoZrizs49LHBAGrwEOMp3ieX8YWJtMazNKKeuzZ7XtmnucPfp5q17um05952su9huAtLXocr3oxrfrF5xVebNZtdKypVIwaTH76BSZATo99De/RhwAJ6TOjBzRzO4crQX2uGW0XQidZ6OjOyGRr80WF3mrfbBb+qX7C2PT/vfsufLV7z9Lzhl+tr4rQHKhhXhuMzjV8nVFC4rRYVk9boriN7LyMga8GVgf4U9qvUxbL06V0Siow6jX7P1HrJCDKjW0voDL4T1ZEKwgNt33r000H2qdrOaL1K0iChhO8T3Wmsk43CLxR+KWeMu1a4naFdOdzWY3aDjJqnRIAiLIpBz3EQl6q0qkdRIYdG0V9V3Dcd39Qrvm5uZo5sn0f2ueIxdvx1/zF/vX/JbzbPeHi7Qm8s9VbhNlPUTwkbdpQa4NTYADNYYvpSNBZyuypTln5XREDWS2SMc3PzKMq+QF0QHvc9TfL3y9L7gewsKllMMaBKdZnRFERGlFPyyautB2SzH6/0nAx7rriaCcnTc3rGYDeTaV2Ykl5lTGBMpDKRpR24dgeu7GH2AnBFYXSiyuQSLnbZjX0TV3MHKjNKKXpi0gL7ByGKmV6S39WhJ/c9hIBSai6yXFPk+WiBziu5xuyKVN9lbB2payFXTWOzMVoOo8P3FrPXuL1wGXQ5uLOTkWJsnWQ1LTXDWhO68ndcsM7nthEpasZsZmVOKsVNnCTFJFIZaexiw4PveBhbdr3Mls1RF7v2THMfMO82AhErRbY3AsN2ErJ5W+1Z6VN0xvR3AcV40c8qkvcKHlz5DB+eOcfaSEEzQelTl1O4PKp4dGCEPCkBhgm7D9RPlvFKcdw63g7L4jUxClSq5eBoTJj/fRo3ePTMe9JMPjbl9wURtH1CJTWPIA+PDaG17F2SYudBUz1etsnWm0j1teN//eLn/Her/5dGwUJn/sQ98F8+/2s2f9qw+eXHuIPGbj1oqG1grfviLyRrxNAHx+TaIPbxaY5JiJky1nK88yvMIO7ZWWuyMfO7nu3JfHK+D2c1zmRAKJD/ZcVPaGFSb6rERFKRRijKfmBKNtqUkaa8BGnmYUQ5i60Mzb2MgJKtiF0S6whPMY3McsZFkeseo+MutdzqHWso6hPxQTntW5k8jqjNHgd0bxtSrTlaJzyRgub9IWuSiwtvTawpHGKCGFG0ZqSyEUq6dnJlvDdJqkNEHT12SJheE71ERByjk5gdPRmrnrx4hGB++sBTkO/fDS/5or/hy8MVv3rznPG+wT0aVJAIiH7x4YtU1spkQGtpNrQokNTo0TGie4vuq4JUa3zXgJLxk3WSO/jOL7nfddDrmVh+DI5drNEkrsyBV82W/68F35a9cSoqFvLsuJ2iuSuGhEaj1yvyJMIpzc8/ZJn5lyhKfyc+ZaIyaCl8kpVRvxmQezXZZlSObAxpygcr49xpQpAqTshV+X1sM6GD2EgRlbWirhW1VZjdeJZeIN9FyoKcuW81ld+3qm0mjqCCYjgY9iUi6J1flvFn5KAHHmPHXVzy98dnfLm/5m7XoTcWt9FUGzFFPBU8efbWmcJjRX41iZ7E1R/k+n1bhFFR4VeOnWt445asXT/7s3V6nAvOSgewoOIf6LSc+0FkcwBTZxXMTMZVqdwMK5Cb2Y1UCVSy2F6KIoH2TuTHXJjsc8FT4HFxUc3vhQTGIKZ1Skn1tnI9SzuIpf+Z0+N0eRHpTs9qsA+uxyiQrUQuiGInZU1MalaHGQ9mTKg+kI9H8rEnjyNa6ZmK5La2ENUUY5HyZi3ITq4Sqk5Utadx4ZQAnzR9tPS9g6PBHEQJZvvitVOk+lnLDfcrw7AS8mxsINWXHSTTAyFKLSl4NAmT03smh1NBgqLI5B1PoeXRtzyNLUPvxKJ/BLfNVNtE9TCQHx6FyFrXMmprgDbyot6VlPQDjR7pUyWFQjEarHQ6Fa4qzL4m54Zol5DPY63ISs+HJZR5eJZRjCqhg5gT94OUMEdPvXH0W8uwNzz2LfduwdIM1DrQJyfRBEXh4LWeO/I+GzxC2HuvtE5q5nzZY5LA0UpksmavickSTcZupWistpfdw+oxsPjS8NX1Cz7/syWfmh0LrVgpxX/R/TXmR5l//eoV3VtN+00iA7UJrPT7RFOfJQvM9KooJIUr15WRBoBDiuRH35ZCAbBafpWVrSaWguf3dY3vBYhesGJ7Gv9OEDhZ7m8IWpqiySqp3FtiJHsPw4A6VpjKUT82hLbwHQYtXJ8oRpgoRY7gR81+qLj3C96GNa/MnpecVDfnYZDyxQVy3EMINPfXkibtStzIBL1fco2cnHonvqFWCYc8+zrLmItMeS/KZ5nGJFOzWIqdHAKqH8Tk7pjJg6hLD8FxiBW9ce81DVUx9gQ5CMdsOKSau7jkt8dbfrO75fVmRfi6o32rae5kT+6fCwrzwTXFERkt/z7x6UY/j5vNwYEx6KZC/agpGVjQukBImm/6NcenBt2Lb1uKmjEZjrHCqMTK9LyotvPB75cWv9CEhSJ0gmq4HbRvpUlFa/KyQ+0OpRgTb7n5OfqBSq05kEKpkhaevvMdyKpYrdjCSdWlGRoKkdoHkZFPjtnn6mSFFLmuFEuz51ThotVZip8GeabLGLHxaf6zcpMVOcpvJhXeJavaJmLxoLIHjT9UPB4b7scFdTEpXehhHn1+ebji3W7BcdvIvraRQOnmMZVEdEFXY128mBxnoMdkopiwu1JUa4XtNH7QjF44iUPleHItb5vlyVzUxdkby2rho37fnvP97fPtFal2xNbhryr8UhQ4E/EoKehvFOBIdoHdB8QCuxAaVSmIaiPk0eIXMfkeiHxXlagCLV14PttAiktvzie1hyuuqJJjFKiUYp/yDC92KtMoNfu9fGg9xXZOij53NzbfVl1kUFGg8+wDORTSWwioIFD7RMqaHsrQZfIiYttA3XieL/dzsGilA31oOfgKv6+wW0O1VVJEbCJ269F9IDWWVBnGtagPhmvFcJtJbSJXl6FY52MhD5gsm7rPkUYfWelxdjqePA4Smm3WPIaOx7FjO9QEb1BeUC+3z2JlvjmSfUA1NWrRMlxpxuvM+ubAX6y+4J/UX/KZeyRmxVAS2/e5msdnIMGlC+W50h6PkLmnDne8BOGpVPFtUOhKlxgIQXFkM9CSXm6mokihDwk9jFSPFdWNodpoXj+uGKPhXb8gZs3BOw5Dxf5QY12krUf2z2oOCxnNNeo1oDikmjfjmu1QoUY1m9yZIZKMPUG5tfDSlEsy16/VrEr40HIPR25/CdW24n/+l/+c//r63/Hz6h3fJMOVHvhXi1/wr//0P2d3t6R7LcF7lQ50cxEpa59qcSmPYncfOoVeeBYqzPETTknkx92wEH+bmCXNuTaz3DbVjnGlGK+SePAUcvR7n7mQly9lSIw3SbpilUkHjbHSjYem7B1Ro4IRHx6twGVMSuhpJFG5klAv36n2YPdqFlxUm3ziCGXHIyv+rf6YP2rvJahW3fGYaraxmaW4yQjKqqpirqk1U5Cj8fJrdly/YBkoZMxc4mO8cCHKMap1olERnyV8cRdrMSD91shMxSSRKUHiU8yQhC82aoZRrAc2ocVpQaweTcdCjXgV3nMvf0wdX/kbvhyu+eXjS94+LvEPDcsvNMsvE8uvBvQxsP+0Y//xBahIGWMpnYQSEZKgcEWmDsAwQteSWsfxVnP8KJN/1PN8uefgK77erKm+cehB7uMYNGMUi4FpLN6ZgXDr6R8rTG/lQLwWbhZZHLqrbRT+4+jl+zKnz6/CGVr1A2XpkxQbwJ0ZOirOGvryI6WpULORrjRCwjsjJTCaWBtCo4oFAkTDPLKYuCzaC+cw7EoDVc6aWMPxo1x8hwx2L/5Yk0pLZSkYh8n24MKCp33riY2oGo/PDaEzbLuGr5drEsLxa7TnwXe8G5Z8s12x2zawsVRPiupJ/I/qhyCUlzFK8VbLPjILbrLsL7aP6D5iN/18P1JXEVYVbm3FikUbRtXwrpGA7clgeFI2VjqgMaXw+e71/aeJ1nO1OOXYiMuvmm9GbBTjEsh2lpfDqRPJFpm7jwoznjJOJr+xVd2AAAAgAElEQVSS2XiwMOznOqVUuFAY2lkzRDsflKcIgPLP4rg4wef6Qsa9T7YwwmMZokggqTMCI08wo6BSZaOdTJ5gPlCFVKbmYic2mdRmbBtou4FVM3Db7OmsZMNM19QHC4MueTDiK2H7OCuzlDPFllwOx9BBXEVUEzHVZTj6Qg8zJ2YqICbHX6cCK0ZemGPJ11HcpZa3fs1rf8Vvdrf89uGG/V1H/ZWTIL6NuJuqlMm1Rf3oFeHZkuFZzfZTjb8OXLvALjY8po7HdGBRDl6tEgtGRmVmr5HpXnrOcrfm//bhk2Tufqb75AtyHRWKfCI050w+340mL5MiCfW95YGOXV8zDhZ/dNBrzN7Qt4lj1/DbyrOwEuvw0oip3z5XbEIjsvTSTYmsUhNbLTP3NeibkaYdqWzgSWcGXYnT6iVLKfSYqLaJ//D0Ef/R4kv+WfVOUM5CRH5xtePd1ZLh2s3eFVP3kxBk4ZBqQirj5kqcTI0tCF+eRlEy3t35enZXT1aXcWEhZbpi/V7GYVU5Rk1pTKYR5g9ZuUrlXczvx6/00mmGoDBlzAGgghRiualk7NbWxK7Cd8IHTFXhAhSnZLcrvj5ZSOBhYXladdyNS+6aJY/pgcfYcUgVwwSLl+5ZOwdtQ1p37F85+meKcZ1n9/ULjd35m7CcHdblfTSzUACYc71iFmn41jdSoJaolsnQThovLyi8c5iDxx0q7E4ztDVvqiW1CWxCzVPVMiQ3O5kDsw/PfVjweljzul/x5n5N2FS4J0P9kGnvAu7NDkKkXlYXcQbzhJgU2bcaiwNw5aQAchZCRVq2+KtGUJlFZLnoaa3n8diy3bQsHuVZSw7SYDgMFQ9jx2t/PRPxTRsJXTG5LQ1mXCb0QaOiwh6jFDs+nMxvzwNC/4Dw5e9amvfFLkBRaeaZeH+uctbFV4oyJs5OaBAqS/L7pAuYrDNEIRyoH4us3UsTEIubtF8nYiP8nuT0fGZNRU/OzJLyS5fdjahgAYftDeYo/nK7saazotodtGUbGnZBLDmSN1IjTMaeRa16UpAVRbdJKKVnFF4H4fGao0cd+lkQoXPGaIU1CtOXQOZRMRYC85jevx6nZP+YQ3i/67q+76IngzaVciGbaUyBcDNAqTBJJTVdG2wvFzBDsAmx2M7IZpWMHERRvVdEpEl9oU83C3OylI5nkrRpRRSegu5kVcYlCQcXIzw+G0yWIby4IAfxqNBJCq6pcCvmWUqJ83RWxUhrMtgqPI1YqQI1ZnITabuBdTNw3Rx5Vh9mP4xNaEWaHox8r8eSj1KMtNRxlBvfVbMJU2jlpVZdoG49TXVZtd4oz6jMHCI3HUR9dqz0kRdmz4tC2IsktimyTzXfjGu+2a7Yv+2ov3Gsfy1eRPZwklKmrsK/XLD/uOLwSnH4NOCuezrneQot92HJtT5gzH7+PE7FmSckMQSpmD/q+Z8T+nMJyU5M/oB8Yv5/py1KyihkVIhRZGeKbX+5nMEwJsWIQ20tbif5QbYHvzD4tebuquNtu+Sp6di4hoR0nftQE4KZO/1kxaHZd6qkNieeXe+4bQ8s3cBvTeLeLBjdZUSsbBTKR+w+8uXTFW9erAHopgI/Zz5ZPvH1+iXDWs8Fz3nR4RHkJkaNzuLpkS1YF+dCJ5aW8pBqdmM9j7SyLQisymL7YQrxsEqzosgo+RzAe6jOxWLYKqFKhywArwYl6hZRi0mRprK8f1plVGXLaKsqHaFjXCrCEsIiF2NCBekUKqtSpu4cfiXcrUffso0NQ7Gt34eacRrdg4zy6op4taB/1bH/RDFeZ8IqYvZyulxo7M4vh0+KJYWlz/a91HL5DhP15HqdDX2UHCIJrp0ODUF38ujl1zCie4/bR+zWCU+saXhtV8J98XWJszkdymOys2jirl9wf2gJTxX2yeCeFM1TpLrv4e09KI1bt9TdhxEepdR8YKkgBUf2HtXUUFekxqJiJlzVjNeW0EJuEqtmoDGe3lvYOOpHSQoPrUINhuPgeBg6vh6v5tiguhkZ6qY4K8tIVHWBPFQly0p4MnOxc9akvufb9QNXzBlT+JvTs/1tJeI0pZifoYJkSHr6WfFlRb08K7j6MrJSSjx0ooyD9BCoHjPaO9zBECvJWRtuFOMNxDoTG7FsSGV0nw2yEWY1n52XNiF6Wz6IUpijxQwQBsN+dOxcTWMk7Pa9rKzpXE+n6565lWcAhCiys+zHuRDZfZIYjmNPntR9SqGNwVRGIp282HyEIJmEPk2xRGl25zYyv/691/W9BU9cVLPsXKmTMiI5MStDQQ5CpoqNjBRML/O4ZAukfMiY/Ui2WpJVd45Uqxl2FiKWJrQaX5RHyTG7Ki9qMRjqg+VQ8qkmcnHRhDBmPY9LHBL62anLOuemeFB0epDAvdI9LKsBU0dik+WFajS5Nui6gpzE9KlpyG1NbtwMS4ZW4ReZtIw064GPV1ueNXtuqwMvqq2MarLm0Xccg6MfHXYvCcDVJlM9jaIE2+xKEF8rfIlGSQeziqzWR9bNwLq+wAgM6PSp/TwvIDo9sNZ9SdMuPJ8c2aSGN37NF4drnp463IOleQfLrz22+ALFRcV4VbH/uGLzmeb4ccR9dOTPX74TD5DqyMfVE6uSRu+zEcJscic3ZZUk1FQo+fRnL+Q0b04X3Mfk1IwW6qDIfcaS4CwYWFxPS9dlNWFZ4VeWp88sx5eZ8UWgvT0SgiaMFnvQ1A/icu0OmeFKFAPjIByvlen5mXsHwCFb/u/6J7T1yFB1ZUwlB/XxuaZ/nuHFwJ9ev+Nls+XKHunsyJf1Ne+6y2Tp+uhJtUPHzP6p4avhmsekWU3yTJX5SXfPv1kHxnUlisgsdgN9VhLbQeYpdlLwALGYhC4qQRydhlpJgOh9WPB4aFlM5OZKywFSRremL5uKy4X/pn4neLQ5MzG86Bqt8EuUArog5prWEHqB7lRW+FEkyMaLsZzKGZUdqrL0zxuOLyzbz2B8HrBXI6G32HcOHRRmTLhDQI2JptUM15bhKIXAyvRclUJjSJYx2NkXKHaW/Oqa3act2z8y9P/0yLObHS8XO35zf8v+zYL85jISbMrqOwNxnYq4YgbYlRFzRPOq3fJ5d8O7RYNfO8atplpWGOeEIOyiFPBJEC9TOJDJa4ZgGIKlN7Jv2nIQTFl+rfHiA0QWaX3xXDIj2H1CPx2Id/cA2NUCt7ogWqIpf+bMugClTwTroGU82gjJODlAZ3wUr6rdXUf3laG9i4wLkWLbrWYwLb/Nkvv1cbfhyh1pKs9hESVuZZVJi0jdeOJQUz9l7Jf3goBZU5RZ33HcvZcRd9mZ4c4Obyl6pFELSc9RLHoKxC65h7PtSmCegkBppM2J54M6TQeyyYwri19qqtZhhojdjphjiaIINWjN8aPTWTr/XC1F0NTMjcnOKP8lS+2P0rwYhe0b9KBQo6YfHVtXU5k4i24mt3FMcVCui1eQV+iVNJV6NDPFZY5FSYXeojlx0rwoDymBs6pymMGViBnZg3NSP9jja1rfr9JKJzWEfIlqTld+zzGxIDKx4pQknqaKrFxMVjNrfOq65iTb8nBIZAOSmo783MrEsxTyoqBCz74tlZIxzEQm7fBAei/n4/vWlOMkiqGxjHkiVqVZqZEL2x5diHjGgEmzGmEeZ5X8j1SLYWJbj9w0B26rA8+qHbd2XxCMQoKNBu8N1SCFoh0Sui/s/ZgkK6j87FiJt41qA6uCGF1Xxw9cnaypcIhalZFDQpNY655rfaRRCdCzkdQ2tTyFlr2vSYPBFZa9CrnkVEW0T8RG0z/THD4NNC+O/Pj2kT9ff0NrpIj8yD3xzOykqFISZjiZ9MXCaE9KZPBFh/jefWmU5zvOht9ZoT1JHWfzuqwxlaASOiqULsZ8SeSRoTP0N6YUO5H2+YFPbx7Z+YqnQ0vvKiYHVLl2+fcMxcHWz8VGSpGIZHJNfw6KNLWMN5vW87LZ8tyJN8q1O3Koq5kr8sFVvIYkXVnPL7zP0ChBepZmQLlUxsgwJjOTYydpep8cKeqTsZ+GykY6HXAI1+c+GV6Pa477ilWxXZB3uljkh4Syp/T4WO5p4jRC0+QfVOwA6IJKSRBgIqpMQFR4ejipOya4XOdMMgpdcobCQjNcKcYXgeVHOz69fuT+2PE63BA3bvbvUcDs8ZFhbQfJOEOJNLtfsd823GxLTpNPc2RKaGCx7Pnx6pE/Xtzho+FXx4qwvWy/eeWeTtdbeHOTWGDai56Z3YwYDMnxeNMyBEN/fy0KyYOjWnUyOtJKDnNzdnCWSJdVM/BqseEn3T1/sfgCp2QvfYqnIvs+LDAqMybD42JJHBTxUMwd2wqzWpHHURyDL1GCnCMmKYMxwnua+DOl4YiNEuJ3I3/+MFRs9g32zglResyoNqOywhwUyRhGVfNldSVq0k6JvYfLgoi4jKoSVRU4JjlX8rHsj98lU/4WsnNpLiFIAK9RipgzvqhaGyWRQbsqkWojXFetZCRcRlO6z1SPo1h4xETuGuK6Ylwb/LKM5JpMuvFS9CehMAxrhX1eUT2GE2Wk2LxM49qsBOE6PhO1sAAOhWKSwSfzg0Za59/T7NeVxNPnfNw8qVmdjQxVJDWa0BWCL4DSmBoJkmYib0+8OjGjzFoV8+IoRXzKRfqomKJs0vRs20xlE40Noqg1w0yN0CqhS7P1+9b3Fzznlv3StJZuesKrzn4hfJ1kVSleijR3yAIpTq6YE9SXmFOIVRAmt6mFh3f+c8U4rBBps2wM8wWWXxEl6EF2+Pm/XQjdFTisUhFHnG3ftUoonUj6xOHJ0whucu+dfhWukyBfIvN1VWBZj1y5I8+qHTd2z1VJJj+kmlQ6guT1ex4EavDC3k8RrCE5UwIspWK3deCq7rmtBTW6ZDUqgh7Q+RTd0ChPp4Ws2qhiE06mz+KTs481e19B0LP5nI6pED0kqyrWQhRcfiyHy0+Xd/yj7htJDybxwmxY656VHuUhzKL+EkLyyXZbitcTDGnIgvxciNKF7pTdpYJ0TSqCq7Qo5ZLCaCW8Lh/JRhDFca0Ynwe6F3t+cvvAn6+/4ev+ii9U5ot6OXdMJ/dkZHyhMpUKLJTGcxoRhGBO4ZR54vFArhNtPfLc7YqxoWdtFxyr6r3N4/vWPFIq/LdpTUVFoxSdGdAmF/KjEpfhrEvQoUDwQ7biCH1m8leZWIJbZRP/Ji756nBF2rmSEn5qftQU5FmM0sjMxVdEzQXW9PtLTQcBjD09A5ULhMK3CLVYO0hTUTb40oRko2ZOkW81fgXt8wM/e/aWn199yW+Oz7jfdMTavt+ocYLdF3YoUQ+Gr/01bw8LeHLUm4zbRfQQJN7BiAX+uhl41W75rLljs2z5qluzby4bTX5iH2Ypeq0iHjlA+mxpVKBWkWcmU5dnf5+/YLtq6KPl/7lZMu4cw0bTLWtMiDM/LVk9K4KySxiTuKp7ftw98heLL/hX3a/nEcxXoWVEmsdvwjUJxTE6vl6uGQZN3AsHKi5q3M0V7PbiFWMveFbPgzhzno1rs9EzEpWsJtQS1xIbeYL73hE3Fcs7RXtXvIXK82V7SvNh2dmONyrTWo/TCVWV6I1S5DUucKQUPMM4k83fW+foE4DWJcTzQhoEJ+7oJLDo9MCqHnjTRGJt8Qt5NnWQotwOUjzbTS+kbSCtGsaVY1hr/CoTrgN25VkvevrRMRwdscuMVwodzAkgKE1bMqVwCJBLY9U/02X8I5OWEGTfHUrzc4mRKyD3bSo4ZnBDvVcnalViHUykrTxjbRmCxi/Ki1beTzNKwwil9tQn0EPHjDUZlSzKO6y15JTL+WdF8Tc91wayy1QusHCjhMnqfrZUcSqRlP7ePed7Cx59GMuHLFkorvzFmgLbCWHvRFCaumEhCNqDSJdViCTX4FeO2EphlGGW7prtUOCumlBL5oYOCj8YNn2N0RmjE1YlIRSrQEUq/iLC+ZjgOnEKhWMeuQy8O60T+qAI2QjMe0a+UplZGZFDAO8Fdsm58HfEJ4Em0Tae6+bIq3rDc7vj1u5Y6WMJCpT54xgkiHNW9fRx9rNRTUNetMTOSifUZnIbWbQjz5sdHzcbnrvthy4JKAVPWZND5Wl0BJ02XOmWp3QkEelzxTE6xmiKLbiQMvUQ0aOoQnLjiE4yaz5a7vmo3fKskkyliYR5yDVVjjQ5zF3stxPQPYYp+6Aqxc90cE7I24dWrCG0Ql4U1F74HnGv0CXsdgr0I0lxGlrFcAXtiwM/e/6On19/wZ83X/G37iMSis/dc7I2J2SjIJMpKg5BzLYeU+IpOX4bbvjV5jnHx4b2SeEOMpqJTs1o32135I+qd7y021kpcakJGMh4OTuNX1hUFVmagZVOHLLikPMcfJoLsmqOkoEzYoRbg3zND74j7i12XzpFC+u6F6v4gsr8cviEXz/c0nxjcVuP7YsFfkjln7Fw2pgLiEk08A9ZdRUwOmF0prKB3ktx5utEqvRc1KaSV2b2EbsP2N1IuKqL7BW6ShK3d7EWoUMw1KMS1CDk2dl9amSGZPnK37BNDf/Xw2d88/UN3VeGxddH7N0RvT/C7VIOGqUYo+FxbPnC3vC6X3E8Vuj+soNk9S2VjCnO2A3hPdJryhmtFAs10pmB6kxEkQryizUnEm5BNewB7NYwto7N0LD1TXlWLQsVpElUiXRGYl2anlfNhmfra157ix80+48NybW0q4+ov9mRjaF6Gj94fbl25T1LcrBbI2Tl2f9GM95UHJ9p+heZdO1FjftYsfw7y9WvI8vf7BifnWJn7B70IITeITu2tuWuGeicx7hEaDNceVaLnqum5xE5h9L+gKmvoa7IlRPyci4NeJB9Jec851GpC4Uu59l00z7aaM9VdcRWgeQqQis8OhUnMY5CJU1c1OhKvvf+ZctwrcWodhFxVwOf3G5orOexb3kC+mtRJ8VKESvzHjdoUjlDJtlMahLDtcLtFPZwIrlT9qyn0LF17e9e0HestFqQG0tYVmKBUkkh7VykNhLWee2Os0mnVZHWeZ7qhke9oO8NatCYoz6R7fPpnVMlxFcHhd1D/ahpncLsVzCMcsYsWsJVy3hV4VcKv86w9ny83vDZ4o7Pmnd8Vr1jkxpqveCNX5FQElT6e9b3Y1wxyUtVfHaAk8GWPiGFEzwuG46a54Z6FEQorVpS48j2lJ0xKWPMENGHnlwbVKpmwyX5+xWDd9TOYzRYHWeVwYhwExwi47w2B5rsWemRRnHxSGu+1DKHnVQTqdDrf+erU0pm0sYIebmMtISsrIh1xjSBZTOwdj1L07MyRxZ6KIGTmiZLkJuZCJplE0uVJjdCFFMhzuMs8Y5RAnEmTUhGSGjpMohSbP4THs2hQOiGzDaJdLhTCZ8jQxYezS427ENF7608rInikq1RjZWE22UtbtIacpaHfhdqXvvr9+T9ToU5HBRkg+/0MBeWfWqF01CKHvJJvXXpyrqgi1UmR7D21PnD2Wi2SNWTErQkO1g2Izf1ged2x8ocJWSvSJHm8+f8IUhyrU+h422qeRtX/Hp8yddbcRd1JUQ1WfGayAaUFQfZa3PghdlyrUc2qeEpdtzpy7K0shGjtlhrjJUD/ZBVMT6T8c42NqSjxe2zEKXD+yR/kK6MqEpQp3xnt/Ve/KyUok+ZL4cb9tuG5Yb3XI1FMi4HQy4FiLJpVmUZlf+geJdptZWXcVbpHL3OGJOK6V4u8l41x9LMKhAo0TWAEj7IXb8gJMPrw5K0cdg9p7BGzqYcGX67vyFlxdr2fL1do3YGt6c4nYcTwVQ42+yONb81N2x8w9/d3ZIeaurtpejA6dlOkyKxjLkd4imyTR6nMjoz/7cxGgj6FEr8raVixPSRamNFolw7HtYtX1ZXrFzPr6vnXOsDjfJsUlOaQ3k+Oj3y0m35eLHhODoevebwqpIg4KVjWa1x+4A5frj5QGuyEi0kdTX73cwme0rItuOVqIsWV70oInOFShJHND5r6W+l0cuG2X9JMhoV/trio6FujtSNZ9866m5kUY+01s/nC4Cq65MR4lTsTLESf+CagKDfGyAKM18Fy0lF1gK5me+hb2Wsdx6QOSG+VieayjMu7f/f3pv8Spbl932fM90pIt6UmTV2VVd3EyKlhkjAhheWCEGQdoYBbw34vzGgf8JbLbU1vLIWFmSQkkhaLdLsJpssdldVV85viOHGHc7gxe/cG/GyhoykV2q8H/CQb8p4N+5wzm/4DvgIKhr6pOb9cdarG+//zXlfVtxbt6Y9Y3eiWm1YlcRK6OihVMQigU04IzYOhQ4zuL7Qfj7mQgchx1SWcRCVaXzev45Ok/IKNar5mqqkMKOhXBRoo6A3xNIdbDkq6WC5ynNR7nnkdjyxay60TDm66E5i9H7/jplS3hiMtPtSRleTNxOT5paXQjZtnGS/U1cg2rw5VkYSmUTu4OSPPkC7RzUVE1V93sejYhwNRkcq57Faxk8BncXfAg5PowJORcbkWelApTT6ZPWPQ0yU9zEZ4tS+mzBKeZY4CWuplFt+WWQr5LFTLKAoPEsnOI1zs2elOxolAntB6exPJRghdBZkcsLqiY2Toq33WcpfzbRGIoyjofXSgWnNaTevKOfK4tmlA0uLVFApT5sGXBrYxcQmFtyFmvVQ0fdObszJWsBpYnJQWIYzl5PbSB8MW19yOzY8zYrDk5KrIc5qpFM7tVKjqD1jZMTFoUqdAIDvMgqB/JBn37KpCzlRQYnMujxqDDIfVxBNonYj527Pld2yUMM9BVqYfu/IHy0J9mobJNn5cnjEr7rH7CbBrU3Woaq0sIk0aJ2ozMiZ7rjSA0+M5aXZ8LW+nIGkb31/9qDYXJSS8HTJsFKeSikC4oKtOo3bCV168OYbIEWnggiz7VMmDESuinbuhkbgaS/jLLdOmU2Rf6i1tNCMJjgtmCl7WGTevGbveg0rK+a0U6fDaHlG1ASGtGlmcqIOyU5Scm7QAoTse8tr1XC3r9hsa9zaCCV9iHOX5iB6Bk93Z/hkWNqem3WD22jsLqG7DKCEeRyvAnRtwauouG1r2lcNxa0opJ8S41Eyv0vFnPiHLDg4Ki/dmpxEjsnSR0frC3kWp6odmGUyouAfTOepbgtiIR5O+wtRpm3swOfle1zZLRempYtuxtMNyYobut3yg+aW1hf4qNl4RWgsw0qRtKF5qahfnHA9c5ckGX1fzXj0Ahq2mv5cM54n1MXAx+d33HQ1N0kRCsdwpkhGNJ6iRa5pL8WxDpL06k4zekNlRupiZN94Vo2QOBo7ZBxpQml1oMMbLeO2N0QG567OOxiHTt1SM0E0eEM+Y4JAZCDyuJzWb5W1rPKvReZRDQlS1IxRM0ZzSHhqQztqvM9+YYUI2eq9xm3kvjsuzGYfujcSn0k7p0un7Rl+5TLLNCcbBYKRsiLZUmY2s1YpGw9PqvSSBO1GYW91oyVGJSwupDgGCN4QR40fhJqvvMb0irBwoBVaazFdLU02UBWoSFWOXBUtV3bHhW5Z6YEBQ6Gak7zC3u6Wni0lRGOHrJqo8wghifR8PqnDuTAnkklULzOteIgi/W+y0unxiDc/+ynELD0uHQ+/SDMLzNpAmdWJi8xiMETaWMpNpuEDIytASGFG0Ldp4AROwUEDJisLD7nqmTLt2cDQykOcqkIeEu9Fl6Mp8AvLsBSPE78KPF6Io/uTYsN7dp2F9QaanBF3yQngyo2YMuAbGM4UKhqSrinWDrMbmbxddBBjQLs19EXJ14szumDZlCe4FyPA1j6JX9Y6VnNlpxHG2CYKk+p1WPLMn/PzjfjoDHclVdZAAQiFnsF9w7kRlc8Et9sGHwyboeR5t5pvvPerDU8KAeoeGxZema10uCZMFlMlewBw6ncY98zK3BFE6Rj05G6fKY92N6LbAbXvUVWB6ReoqHFGWDEL3dPofnaGpwyMSxF79JVmXCn6y4SrR6kigS4W4io9NMTdxLaLmF5ArmKqqxgGw03fcBsbrlLLIgW61LCJMnI4JVKWbvCl4qfvP+P3my+50p4+wZAX8OtxgWm1CEKOmmG03IYFu3iN0xGnFOd2n89ZYmw0VJGPyxsANjHxm7DkL159SPXcsnjuhWUykRaMgsKSXCLUhlBCWWa/rny9qjnRPQgOnnolx6gxKpGOpCjuhTos5OlocVcp4VrRKQnOsD5r2CxEqyqNmiIInX1cWvQ44YKyHEFUrNuKdVsxDhb1ZU3zVLF47tE3W1FWDxGrNYtlQbQFvikZlo6+jOhWHOVPbUpuYjWrmLexnBlbISkKFYS5eJR0r0Nm5HU1ei8q52acgOR5MbUG1Q3YfuSsHShvl+zuHLeu4GY4YwyGxo58WN3xXrHGqUAfhe0aUZTZY6nUnquyZVzJhtueFQx7x7op6K8Mu/ffPg5RbXfvuCb2U7xY4S8quiclu08T6kc7/vtPvuAPL37JXWj4srvi3zU/5ub1AnNr8xhLYUa5zsZL5zQU8v1+tMSkKK2nbgaeLLZcFDJiMYOAhVNMWfFZH5LDJEWrgiMMpnqnhAeOkp4jwdp5w80yLSErIfdPfG4OQBdUHkkp3LXGtnm00yn8uuBFOKOsR5wNFDZgTUTbKEXxMqAWnqoe6bYFYSxwOyXnqYDkDoSJ42cFIwXX0vSc6dOILrsPHMEJ+7q/TIQzT7UYOC87zlwnrgemn5mFS9MxRsujwnLh9uxDhkVEMzO5BIOrSEmxGwuGYOhGy7ZoGGIh+kKNySPRlLvISqABRYIiUhcjK9txbnZcmJaVDuzyxGRMB4PR74rvT3iUIpVGFFlr6WL4Sh+qozyTUxwtROZAhVNBNh67HUStNBgBJ8Xc0sraCMoauTGjyJibiZERpTqe2milDjQmU8hzdteogM4aIiAI+phb/KeEAGaFtSRgQslWrc6u5nlcIh0Yg6mECqi8JS4rwsLhGy0iUFWCKrAsBi6KvXh+qX5OdioViGqk06IQ2bgB53ibdm8AACAASURBVDL1vcnGqVHoe2JumaRa02oeAaresN2X8xjplBhRDOjZEHTCWsgIwrKOoifzOix5Na543S3YtyVqbzB7McG0nahhTqMn7ROmA7fVdDcV/d5xV1RYK1W51onbRmTAn1RbnhQbSu1pTM8H9nbupEzKzrwxevnG198T9xL7/IWKBwagGqWzwySCZjS2j9hWc71reL4843W15AMjBou1GXGVxy+k4tS1YJX8MrKsxtmkbjpf1/0C3elZOFL3AW0VZhTAdxo1+zEbROZzX6mRlZaF45TwtWFYafoLxT9cPeNje4OBe0nF17tz7F7o19V1Yr0u+Wq44p9UvwagS4lLu8saPcI4cvXIR+42j7M0X4+XvPrqgsvnmVHiD+mKGifZ97xJl4kni/1s8wLf7Oq8C1MrftsIGdk/1dQST8wjgdmNujAQxM7DtYniTiriMOi5MxodjEuNzpWmr/IoAenYxNZitobFM0X9KlLeDKS2JXU9yXt04XB3C6ozQ3ljc9EnhAM1eQqe+j6zR1yX3D0QaUTjCPMz2qWCL/pHfL55xPXdgmItxsLFJs7Je+r6Wf0ZpdAp4ZqCYmGwO4NfGPZtyfP9alZddjowRjMnWyNmtrqpzchlKWOCwgZ2LtCaRLtw9I/e/ibTMBwIHcDELgyNm7E745Xnx49u+YOzL/lv6l+xiRU/KK5Z+5Kf2w94bVbEsUAPR90s8gjWykhz0mdzJlC6kbOiw+pAF1zWjkooI5tnOlZVPqae/z26O3CwlvjOUIdOZHSyUasiHrqhSXAmcVNmsUHE6NQrwl6zX1j62uNKT0qKuLeYvSKWyJQl4zAnwLI+AgHfqxOV7MfKJAodaEzPypyW8HSXeQ8uwC8jeuFpqp5V0bGwA6X2s/7WbEStPFUyYiyapWP6aPHRzJ3NCS6y8SWtLyTxGSxDYwmVwVcaPcrzHHJHO03M8IzlFb2qdL+oSgeoxxC/+wp9v/BgNniLpWAHfKlEKEpnvdr4xo2SZ4j3Np0hYrY9qbBAMesRyB+QyhVrM1JeqhfTyXhIBZXFACNWx9xGE7PJK9PNNhIgqPkZSJbS22/KHJPYl5lbc/4gU20i3oqfSShEiyc2Dm01KUbComRs7OySHqqEKQMr17HKCHLpHEiyU6lEUCEDEQcaO1AVI+syoZq8qCuFSpJQ6THOpnNE8ReKe0XXFoQgOhunRJfp/PFozKeJMyB4WnzvQs2Nb1h3FX5vca0SEGSbsDsRRJzceE3ncDuRNA+l2F945/BG7g90Yr8quGsqbpua3aKgNiMr1/Hj4mU2MPTfMDaFQ3s4cJ8C+Z3xLVibCaSsQxT8jhfwfBpHlLOYLuF2sN7UPD0749ViRVeIRlBtBup6YL1yDMHKQtRE0kKop1Pb9sYvuB4W3Ha1dOD2CbsLmD6QnM6qqoBX0t6NjmE2vRNMz6U9jWnna8WwUvRX8NP6K55kIccJT9AlxYvtEtPJM9e89Jgby6+7Rywu5Jc2ES5Mi6gyKnyjqOuBD+xt/nnBl+MV9VeW5kXA3eyJhZ2zKjUGUYbNt10s4IOFdDC/zaz3XWnpKSmOloa5/X0cs+1MTniC01mLPxdX+0RxN5n+Cq5HB1m8x4WeN1Bfy7hBRQhbh7sxVK8VzbNI/XLE3h4881IIpM0WvV5S3hSUN9LV0QMyWnuHhEeos/n+zl5xAaGkT/fxpLLcxoLPd495uj5jvCup12LqaHdBhEm7XoTaJsq3Viit0Z3PPm5C5/edYdOX3LmKhRko9XjvWfNTlwnNwvZiWKqlyKzdSGj2dJeWfjyhwBpGkrWoyS0dBJdXWxHKu1KUFx2fLa/53fIpv+s8fVrziV2zuyiJSfPn3tC+kNGLOrzELPuRbBa/TFpGP85z7vbEpFkPtRBpfJw75DMOK2u7HAvhvQsdfYqJki4Fx/0Ef5p2TGykpEG5iC08RSHjoJCyeJ4uheDTJuJa1vZoFUOvCCuxcQJy4TmNgjQxahH5myjp+mh0H9X8jMwCvjrNUiEL9XbgOcBwLsladJCWnroeWJUDK9fPBstOCY5n0q6bkvdG93O3Xgg6dparAJmmbH3J2tfc2Yp1V9LXJaEWdqAZNERDLPXMzEwGVM474ACVALkPuuTmjlL39+3wqNGjh4Ae7YGpki3biZJd6fEogckZZXLpgOy2ufqIQnFXIQlH3+SWX21IyzrrpQg93e6zwmZQ+CCeRkZHbseaC9fQ2pIumdlsclpYRYpQwGQnKr3zgb3Ndvd+7jq0saSxI1U5sm4iwyornSaDCqUYifqUBa+MoOxrUVauqpHLYs+V3fHIbrnI1e+0HholLdDHdsMH1YbtqmT9uGaoHKHWklRlsHKxlXYeiIM6gAqaXheMpWNwpwztyArGcgQL3aPzGTvT3dyOvQ0NlRIA7X5wqM5gW0V1E6lfearnLfr59VxJNv0lxaaifuXon2fn7GODu0IxXDq2ZxXr1ZJXjxas6o7Las+53fPYbjk3u3tJzZisHM8bAL63xTTikIVGFFqn8zZrB4VwaLUPI24zUt4a0uuSLxcX/KL+gB+VLwhJc2lbPrm45bkNrBcVKcGilGTnw8Wale2JSfFiWPHF9pLn12dUrxT1daC47dHtgHYaMxj0YDCtZr2r+NvuPS5My0I9n8HbV/Y08If2sH9fof7xmt8rnlOpwCYpVipxGzW/9pfcXi+42IDZjxSfP2f1O5/xZ//oB5QfahyGQQ3chgayynn3JPH7j17yB8WaMSX+S/8J//bF77H8MlE/71G7PRSrI1yGEYbTEFAxEarIT5avxIvtO+bn72IvEZMiRY0HrAkzgHmOozGWHA/EUkgDepT72HaR8kb8zMJOCrTpHhkbdSSeKhuD6cF9balfJBbPPNWLHnvbotY7cdc2Bm0tafTozQ77uqB+XaAHzdgdqs8T+QN8YHZslBP7CFQeK+n7HkdKcGJ9dDzfr2jbEr3XosQ+JPQQDkDqspSNfbUgLWu69xoRVDxXdE8S/mqkudjzuNlxWew5s3tcXrAnB+0J3zGNJla641W5YhMq9sHxyO3ESsWugf/1+99gmOjEBmIUIblhmM+5r+V2et0v+Hn3MR/bWy50oFHw31a/4sXyjK+2F+zDhUiWBDJ9HUgwXECs5Vq/3C/ECVwlPijXvB6WdMHiNuJjpyZFZS+eh4LfsfOoDZhB7PLFafeqzr87HE0RJnmTWbtt6koAyYtXZIwRZSUTiVGhe0lgq9uAHvWs0q+iYoganzv45Y2muJHz0CdHl8Dc2TwOk+lAmtq9Uwc0d0FnVwQkSTgVKtA/DiQrQOXmrONiseei3LMwA40eqPRhjB0y+3YqoKsjJLXYFel7ncyA5kYvZs+rs6pn04yMS8v+sSQ9bi82GpOYbygi2kVK67OsiWaXBDD8LJzzfDzn6f6MdizEruk74i0sLTH9MvuAdSLnHm2ubKIsmrZlbiGKPLYmujT7y5heqNYqax3MktNaEqJQCE7oOKKRLH6Sx5+Snu0owNhru2QTC/G+msTf5hPMjAk5JT5z17PJ4RS7WFKbkWXVs1tVjOcGlbL092CInUb73N1wR8AzLe1GrRKlHjNQ+ZDsdEnRRummVHrkSbFh1xS8vFiwsTWjLSCpDBSWc6miSIvblpmuH60mDulgwPaWmHAxx+dkSvKmGfSEw4gpA8yOVVc7qSjjdicLmjHousKGhN573M5lqwG5SWOpCIWm9Ro9iNvtztT4LD71cljNldG3PYAxqdxlO+3hPFRTKYMFM6Nn6lhnwUEZn1oIIp4o2keK/b7gaXvG16tLQOjiV+UOHzXWSPt04QYWrue86GbK8xAtr9oGv3GUdwm3jWJW6EP2y2GWQx9ax+ftYy7dTjBduQo6NTafGPafjvzzH/yahfIZgG640IGXseFn+09xzwuq23wMIWB3iZfXK77y8MSMFErOq7vquP2dJeGTPT9ZvsIpzVde86ebH/LL37zHp89G3M1entsYpXGczzE5sQiFJpWRHxQ3VNl89+8DNr93HZOaZVxSnvXfS3qPO3kTYDR38kjkpEdTbCNmUIS9FApTl1RnETbZCPIIaFS4TaJ5FaleDdi7PaoTWxdV1wJ8hVnyXrcdbr0ApPM3a4SceClXKmH0gFORdayysKpsGBND9HgjsSpibCAUCd9ohqVGjwUqnctmHWVcNK6kg9Jd6VnEzj8ZWF22fHS25ndXz3mv2HBpd7OP3psMPoOsW055Lu2OpemISdPonid2zSOzffsbrCuUczNgWaUkju6TsOygaNclf2sfMUTDna/5tHzNR+6GQgWe9efctDXla2ESap839AzA9ZV0j2NU7AdHYQOF9ZybPVtdyrnsj8avmVhC1KRhRJETn2NA9TEe6oSIHHR45LzFb9z3k5+VAhg1QRsGQKlECJpxsJSDygWZQAZk7ZoWLfmYOol2n3KnUpGMxW5FLgQ4cmOfHp6jpCcc3NKnYz0lUhNQNqFspClHVkXPWbEXa6ScMMeks8yvqIcbsmt87mDOvpYciljg/hh3glfYyFgFhgstbOe9YCCjk2Q3uYQ1Ik0TsgzNJtZ0yvFsPOfpcM71vmE/OMbvmXy8RXgwwOAxnchDizmmSDxP19ftMmUw5IQnyAGaTnR2dB+EU5/brvP+pjNlvRAWmPJx1vaIUxLhpHUZoqYfLTtfiBleqLmNjWyKqZ8BZMcb+qmaID+00t436Cy813Gtpa17XnZsFiWbMyf4o2xeaI1UWlObVSjQ8iAqZBN3KuSkYjoeGS3tMlixUiNXdsdYGW7OGp6ZyK2J9L7GB/EbMz3YvcIO4sESRghDZr4Ncu5OieOHMeQFdcIsTU7xJmOZYtLEqA6b9YSB6QfCrhVBKG3QZyt0COjWYO6kapqkC2JpibUl6XKmCsTS0qvExkauh4Yiz4DF0PCbyc9kovgN1tS3xVT5K2R+bjLIfNqsJmaGUnKc3qNCFLprp+l3jpe7BU+Hi7lVe+GkpdbYYfaNqY0khftQsPMl67Fis6swayujhu2I2ve5qhTNGj0mzF7hW8vX23MeF495Yjd8YO9OlnkH2HwW+eEPX/I/Xv0Mp2CIoj+lCTzz5/xs/QPqp4rq2ssxAMUuwcuSXwzv48qnXGnp8P3oyTV//bsFP/3BM/5B9YwxRX7ln/AX1x9iv6iov7pG3W3zRiW0cNJB+FBl3SlVBz5yNzSZjn4a3+y7Q/Yddf9ruN/WOYp5UZ+0dQKoKNYXdi8jL/FZyp3So5fRWT08aWheBsrXA/Z6h9ruD93oRXP4DyHIvb/vcNsxd4d0ZoipkyFnlRJgdpk8L7U4PUd1YGqN6LkDa5TIGZSFp68Cw5kIukVr8HU1dxL6MyU6JavEcBlIZUSVgaurLR+frfnx8hX/ePEVF0YwhQCbWLOJFV10s5AmyOZUqECld/O6AOQR9NuvsMoYx5S7KJNvlAoxF09grh3bcclf7Upe7pZ8cnbDT5av+Li84Ve7KzZ3NY9fykRh2gtiISOWUEvXIUaRXbBGqNDnpuW5PsNHjRnSBAAlmSxBq7Xop2Wq5T3NHe+Fph5PT3qmOC6Uj8db854eQe814myj6IHoNak3wmQe5f61XSTmwn8G5RtJEIUsJIShUAgI3LZSjJKYrZiOOzzEw5hrUj0+Zs++LWwjkA5jIsuy56zoOLO9+Ezm1xDii8rYMw9KM7GahRBzOMezd2KaQPqiTD+NuqwNqDowXJjZKNsMh3wguYS1QYSIk6KNpXSrgefjOS+61Uw8CP6758tvdUvHB3Q7YBUiDFhrxmUGJkfmysl2iWKdZOQVFGYAlWWjU1WSSvlTepQTEqpE2h5V4UOeAxYipx3LxLFbeopa7CWiiPaFpGfQUuTgpwVQqpDtEt4eSyVjIaM0YwpUqsMpodwtnRh/bhc1fhAA6riXis7mmZkoIMv70aUoTi5NP7N+qjzvnSrSiaI9gcec8myXJZUdee5WfOUNPpboQVgkanKTHUQ5Mzjp8IRKqHqnxGTQaVI64HYQ5c1drNnFkpf+jC/6RzzrVox7h9srzF42BRWlfa6rUhYS50hni0MLeDLDC2lm26kEtnOYPhs/DorYG4be0nk3O9pOnYGYNI5Da3ihBy7MjpV+O6h3tivxB7wTSLUUC40qrawFIcloq3AkZzB9pLwxhNJybVf8+fIjzoqO2oyM0eAzRqA0Qr8ck8YHx91YcTfU/N3zR/C0on6uKNYes59UsiO6G3BbQ3Xrskmn5unlOc4IE+cPFl+y0D0fuZuTruG/+Kd/zn939nf8XvGcXdQUKmbQfsHP9x/zJ198yse/GKiebqEfSOPI2V/dof0Z/9vv/zP+l4//mP9p+SX/pPo1n/zoNc8+Oec9s0GryH/oH/Gv/up/YP2fH/Hen0V4cU2alE77Yc4TVOEgy1R0l4p60b+16n+Xjs8YDlmDiWnu8nxrJFlfTB/QvahnT8wl28rfTFpRaHFFD7U+jDnTARuiUqL5Yofedai2E4yX1mAtaVEfaN+5U5FixKw76RAWFhWidDZP9GG6jnHGNhyDlis1YnRPxSCJhk1UeiRcaB6VO75aXfDl+QW73rEeNHgt5so2slh1nOVx8UWxl2ddJR4XW94r1jyxGz5xr6UII8yFoVGRoL953NPzGGHGGE2Eh7dFmtaIlOQ5S0nwPDFRrAMLBW494f4s2/Oan51f8f+c/xBdBPTTitVvFBd/0zJcONon4pMVFlESuSJiXBTSRufQOjIUBwC21ZFeQSoserUUKnwYRCR2whQpfVi7UpJk53jk/ZbQgFYKA7R5Tb8nIqom/KqIJbIWyZFQJUJp0Vl0r7hLuF3EtoHoNLrOxaF9I4EJmSQyJJEuKdQsPDh1hFRUMLmUB9mTVcwkAJ2ojaynT/RpYI+zVYvJhKHLsuXcddQmj7JIc+EckiFOBSvxXrcHmL0j4YDJDBywawCFDiyrHqUSrY34wTD2Gr3PCaBJuPOes6Zj6eT421jw0p/RJcsX+yuetmd025LUmVnV+dviLaDlw01xcD/NGZfK+OQomadbe1Q0mEHjM4DTbSOm8zJC8FosJAah6k6aEjp7aJCR9GkaZykggvca58LM1Kpnel1HozwLLbPUQG5rq0ShIidOe+iTxyiFT4Eu+QzwzclZFkDTNmUAl7CmVICQwWETqAorImmTVhBIy29IKS8cE5ZGzcmaU4FKy/tZ2Z62KERIyzpxZp/bkhn7hBKj7wEOspVvj2M7jglMJpYAeqaob2LFNpQC+NICVhMfFw2porAa21QyOjKG/kk9vXi+btLe10Gk1GOh2F8axpXM7UMTUY2nqkXo78K1IvKXHxrIiRnMgmyTDcdbIx2BWadvKbL6tQDAyTTxFM2cENl9oH5pSFrTUfDL8j2qeqAuRpwJuVsnMvYRGa903rLtSvb7An5TU73KBqMbj24HUsYrqG5AF5ZiE+YuQ78ueF6tqO3Ie8WGD90tj+wJYwLgX178JU/s+r77eYI/GQr+/aufkL5ocNs9qs8aAtqg1y3NV5a//psP+T+q3+dTd80/Kjb8WG35wOy4DhV/2n3G/33zO9z9xSPO/xbqZ938/5VS0B1AjkmpOVn0jaKwYT6OdwUof1sMw2E5ShnnMI1XpXujxGsvq59PGknK5e6TJlez8bChGQGoJiVyBYdOUJqTplQa6LO+Fk5GIMZIkZYTguQsKm/ksXRCspi8rKax2gnxm7Ccx8u/Ga/kEIlzAWRIVJMVC7AyHVfFjojCmcAYzMxCKXSgtiMfNXdc2Jal6QUkmj+cCozRsgk1v+EyM1tknNXFg/AgHJIcOICpp+o7JM2V3XFuTgDYxzh3dZI/JBG697j1gB4txSaPLZyi32ph1TUFSUF5A/VrGdXNHf8ikaqIWQhHPXpF6AoYNbsgm/ov9+/z5f6SV9sFlZK9S2kZYzH62YEbrWYwMyBdKC0J0LuIERok4ZlwMZoJw5P/zAhmL1MOFYTeHUpFqNSsQ1euI24bMPtRMDy1Ri90tltSh483mVdKOl7T17PLwSQSOz0fuUOqMmhZbH5O2zNW5SCMKB1o7IjT4aCPlQ9ogkNMRfz8c+KBAZjZgNM9H/O91UeRFdCkWebD6UhpA703eG/m9UADV+c7njQ7LotWWIbJ0MaCV+OS1/2CdZeTnV7fF2N8I97e4ZmAXyA3xcTtVzKqU1GAgm49YDqD6Rx+rzF9pFhn7ZPRywY+eWb1ot9j+mwSN3l25Rv10A5UYnRYeAorD/fC9pzbVii9OrJUBS0jY0o4FTMQj5m99bZo05g7L4pdirSxFiBhTiaEYh0JJs3GfMrLxp4SB0E6nVA6zUCsITOf2tQxpsm1Wr43Ih2qg72DCDk1VjbbnU3zjXyYx05ZtDxE6fi6vCUmgb9J/2NM8vc3SNIS0GxDxT6I6Jg2iVAm/ELRXwqYblxU2MdFFuFTDItDtTyD9DSHykPDuJBunV8kUhOom4GLuuO9cjNfwzfHOuKcLonZLpaEEx7QY+aOfINZzFEXmpDIKt9pptUrnzB7T/1KAxYVNDtbsV0W7KqAKQLGBqyNGB0JUeO9ZuwtsbXoVijM1etE/TpgN73QhLNkPaNH7Qfc2lOWmlBo7NqwKyu+tmd8vbgQA9ITaaJ/WH8pNhLRYlTKGB7Nv938lL/96gnnv1aY3SCVqlIoo0ntHvs8svzlJ/zp6lP+z8VP+fHVH7FSmoWCX40Vf3T7E/7D55/x5M8Tqy967Iu1VOQ5Un9IeFS2CYhWWIlnhaws43fg5d4FsAwiRjaNsFIW/oxRZ22lnPQEMRjWIW+IVsYFsrgrlE5zkgIQjZ7XKz2kmXxB7pyqkIilQRcW1YkxcLImWyKIXIZ8TOyXAwpUZcbiu8SX4yN5r0nxYjyT9Up7AnrWqTIpzslHqUcubYtTgcfFNgsSxlniodEDn7jXouFD5Gt/yS6WbEPFJlS0saBPljbvkCFp2lgwJoOPeq66Y9L0GXkdk7r3OcC2KvmwePvcTvkgHZ6YDqDhlFDdiPURs9NzlzA6jduJonMopCBxbcTupk5Mruky06koPMNgSZ1F7wxmUHiv2Cr4f+8+5FW74O6uoU5IUmOMeBN6L5vVm9dq+toYOcZ4WtpuyL58HGQhAJwOM13e9MK+sq042IciCcu5ySOqMVHeBdxmRO9HktWYzs0NAT1CHNQse6ASHPtahSrd+5os9TIlPfdUjXUSoLEaqU50IDgrO2yWZym1x2b9u2lsNzG0DPHeSBQOGJ2Y1JxUT3vOBJAfZ7xaorEDhfHUdhSPtZg7irnjq1Ti/WYjgoNul01wBcfzalhyN1S0XSk2SP1BN+7b4q3Cg/cq+IxZmU/k9OAHyeDNbsBuepKV5Ea1/YxpUCbAGCjuPCiLbXXOcDPTatXgKzEYnXR4UiELWGlF2+as2HNmhep9oQdW2tDoghgjUcuM3SlYKE2pTkMR/uW4yBdHs0sFz8YLMRAclmzHUk66kvFadIngcocnqGzilrPrvWbYFby0C/6qfJ99KLipFjy2m7l93YZyrpymizYmw/W4YD1WtL4g5Hlr0nl2bbP0ts8LbpCEkQTxe1p3x/GL/qNv3HzTDWhyknjna/ooehzNomOXoCsdfmHkofNZ9TkDtKNNszZCssdPF4fkQwMuossgGfpix8fNHe+7NeemZWX2VGmcfdAOqrOGTajYqRITTuwdJOkAJJVZWhX05wpfG3HqPTpEYcBFik1Aj4liF8X8tdD4jcbXhrCKeJPo81iVUaF7jdsozF7hdrB4Gig2UbA7eSSrXE7gsj2IaQeKW01SluHM0PuCm/6cPzGf8OJsyYvFGf/zCW9PEvjE9DT/arzgZ92n/Ov/6w95/GeaR39yjX51Q0pJ3mrIzsPAB3/ccvu65t/83R/yn//pD3hSbbEq8h+ffsr+Fxc8+YvE1X96Kc9qjFCVUhUPuVTS2WfISydWpUT3OPKjOsu6J5PHy5KoT2PKd/XWUrOwV15zohbA5VHiDxxEB9WUbOexU/55NBNBQj70EJlV4ie26eQ8n8evyWrishKsYe5WJmdkLGo0ySoBoo8HDZSJJPsub3PCHYz5Hncq0AC9cozKzKOA6Znoo0glTCJvlfI0WdJh6thUapxHB5MwKzBX0QFNpw+FRR9FnG0fZLQ8dXKG2aRZzx3NKeE5VS9q8gKUFxznz1Ur/18dJRnaGsz2cFwqJ7EYRawdtg3UN4r+N4bxrmSsC1yrWNzJOAhEAHU4q/mbr36I3SlWa6iuB/R2kGTdeyiceBP2gyQ+IciIS6lZOV/e+GljSa0UlbJYDK1qWSjPQvesrLxH0yvsLs2sOrsX5nFhYGwP8ivViw69y4XSop5p5HqAYqMEv7kTnCxAcHmiMoBf5kJycRjRShOBeV+CvBwHSXJvY8PXYcPZCe/xUSnsUY10h5w6dHicCgLX0KNgQZV0eCYPxZAmQ9zDnnfc1Tlm5pbaU5eHomrCGWmVZp2fUo9U2VdRq0QbxRdsG0pe9wvu9qIDJ/AJ0OPfc6SVj2D+9NgwMGlxl50ZSiBVbf7i0LXJLeX8OnYf8r8as4/o3ueMX9+bfWovIEjnwmx4OYkWSffEMCbxgAokQh4dvWtcB6Fih6S5DQ2v/IqbsaH1hRgPHq9mudqYWEGHSk9Ochw0Qy+mfS/MEq0ibSwIuXrqo8UnQ0iKMm9cMemc7Dh6bw/qsrnbRaY5zoeQF34dOGScb4m/bD+aM/EJcDZJgo9RFpw+dw4qM7KqemLUdAo8UjkQFJhEchGc6A1ZKx/GRGIUsLMfjVTn+XQZG3AusCpFd6g0PvsHSZuzUiMTEKtNh/FVlxwmHVRMTw4lI9FYgF9kPaekjmjrmTafq0q3j/hKy1hy7qYhY5R8idWY1Uy7yZhPtIlcG4X+GpIAtsvinlR9Mlo6EkPA7jVuOwlpGa7PJNEeTuQzX0d5cyEp/nL4n7DbJgAABRdJREFUgP/9+g/4oy8+4/yvDYtnI6rrhQI8elIIKGNISgCb7mbPxeeK6q7g8/ZH/LKRpLC8Vlx9FVn9+oBfIQiFP2WTXFwxv5/5fWlFrCNL1+eFTt0Db85sLXU6eUBeOx2SnnzuU1IH0cG5A5xyAZZNQJOMKVIeV6GVdJ+nLm0SxXcZfR46NFPIvaEO73GKKEbIGsGMkA7nISkO69uJGjwAnxUv7+FhnApUahS5iDweWOieQRtRYjZ6Lk4WeZOp3jAgXWRchlGJETM/68dsGHe03nTR0WhLb+w8epi6PPNbf6M796TY0OgTNFwm5WJ5kcPnU+ESDidfHds8TAlotqTQSmGUokiweCrg8+iEreR2EbcTNXO7lyIk2gytaBPutkd1/f2uzjylyCPKlNPV3BEFvtkB+o4YU8QQQAmGZ4JB+HRY+8wgx2O7DEfQecw2jT/TBAPQ2aooYVtPdSPdxFBIwet2SNdrH3OXUfZJX+fiU8vzImMwwVzq7GhwsJxIB4HAEzF1xVGbZMJVvhlTsjOz1I7wOodzlX0f567O4T6b1vYpwZn2pynRWZqOSo0zgUWSKUWfjXB8FI85nwujiZX2fVvGW5WWZ1n5yX9muieUUOFmc0vIYLUj3R15V9Jizm1m3Y24MczaGRN9MDmTE54krcoAJFHSPCQ8aj5pMiYKRKIkPkz2BIlwYiIAh4prSJZtqLjz9Yxl8VFLAjJVnceVZcYLTEquKsjGGEbNbihY24pCB3x2RvdJ0x9JbDf2sHh0wdJl0SRp6cv3j8eH8g35weT2rN4UfvyO+NX2EUU2fFtkpP30MbWvpxZ2ZcQHLNZKQGRRWAVEhcpuuUXpWdUdy2JgYYdZ4XTvHbf76h7Q1JqIM4HKjlTGo0n00THqgYCmUb0kQEqhlRMQ3DTvJR1l098db+6pyYh5p6+Ov3dIVEMhP588skJ2uj9e41WEFGTT1IOS6ml/nOwkdC8Vv0pJOgMlsmAf4wWy9pTpI66V2Xsyiv264Fal7wblvhHXoaLKFc7Pu4/44y8/Q/+XFeefj5Sv9gKeDYHY96S+R1cVylnZtHd7ivWO4nNYfHGBXxb42ogT+rpD3+2k+o0BcrKTQhQ8hrufxKHz815EFubgPSb4q/vP3bsmPVpnoPI9MBaH5+E4aTW5AFPkiiP/wuTtNydAKRcIwgJVb46BjxIYeSkZVcuiKZR8NaZsFCzJzfw6MfvrvUNO94m9PcKomXkjmjSxpGPj6ZJlMbG4sr+cKLb3FMR7pqPVLC+RGOhmfOBxFEdedlPn6JiWLpIU9y1dJoxGTDrT1U9g+ByDtydVzONzPn2eKfVz0hOntc3IdVNKCh4faV4c9hg9xAxU90RnsG02qCQDe/uAydICKaUDFu14XJVfa056psT1xIhAlwJjNlueoQqTwq86gIxNH3PnZjoX5OR6sr1Q895o2pHSR5KuCZWsTxOo2ex9ZsE6ojGYjntM1EmJfxqBzac7H0+lRxwH1vDbws12GXFORk6JN2nvE4hZRqjmXiKtOcA5pgK8VMLebXTP6ijhmTqYXXJsooCjY8bDhqBFiHEqVr8n4VH/f1xjH+IhHuIhHuIhHuIh/muId2jGPsRDPMRDPMRDPMRD/NcZDwnPQzzEQzzEQzzEQ/zWx0PC8xAP8RAP8RAP8RC/9fGQ8DzEQzzEQzzEQzzEb308JDwP8RAP8RAP8RAP8VsfDwnPQzzEQzzEQzzEQ/zWx/8H+qfr9CzztYwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5)) #Determining the output figure size.\n",
    "\n",
    "#Plotting the image:\n",
    "for x in range(10):\n",
    "  plt.subplot(1,10, x+1)\n",
    "  plt.imshow(X_test[x])\n",
    "  plt.axis('off')\n",
    "print( 'label for the images are : {}'. format(y_test[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "KwGcVm_NUyJP",
    "outputId": "07e4ef50-119d-41b7-b4ee-b8837f920d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for the images are : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5)) #Determining the output figure size.\n",
    "\n",
    "#Plotting the image:\n",
    "for x in range(15):\n",
    "  plt.subplot(1,15, x+1)\n",
    "  plt.imshow(X_val[x])\n",
    "  plt.axis('off')\n",
    "print( 'label for the images are : {}'. format(y_val[0:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on the above steps:\n",
    "1. In the above cells the data of training, visualization and teting data are visualized.\n",
    "2. The images seem to be a real time images of House numbers taken by Google Street view.\n",
    "3. The images are not only with single digit there are also more than single digit in a image. But, the number of the image is the digit that is present in the middle of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualizing the distribution of Label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "id": "H4YWXKbbAICA",
    "outputId": "a0190880-73c6-4a80-ae75-9364779fa960"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4186., 4172., 4197., 4281., 4188., 4232., 4168., 4192., 4188.,\n",
       "        4196.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins=10, color='y') #Plotting a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on the above steps:\n",
    "1. The above plot shows that the distribution of the labels in the y_train.\n",
    "2. The distibution is almost uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "id": "EcJJq1MXA-X2",
    "outputId": "354fae6d-2e19-4e4f-bf7a-770a6aab666f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1814., 1828., 1803., 1719., 1812., 1768., 1832., 1808., 1812.,\n",
       "        1804.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQo0lEQVR4nO3dfZBddX3H8feniVJFLVi2DCahiU6wA0wNsoO0VocWKw91BPuHTaYVpI7REVptnXHA/gG1w0ynFW1tbZwoKTBFKAWpGSc+ROrIdKYgG8hAeCrLk2waySotWHVQ4Ns/9qTchE2yu/dmb9jf+zVzZ8/9nt8557uX7GcPv3Pu3VQVkqQ2/NywG5AkzR9DX5IaYuhLUkMMfUlqiKEvSQ1ZPOwG9ueII46o5cuXD7sNSXrR2LJly/eramS6dQd96C9fvpyxsbFhtyFJLxpJHt3bOqd3JKkhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIQf9O3JfjPLnGdqx62L/KM5C578v9cMzfUlqyII+0x/mGZHmz7D+O7d41tviz9RC+++8oEO/RQagNFgL7WfK6R1JaoihL0kN2W/oJ9mQZGeSbT21f06ytXs8kmRrV1+e5Cc96z7Xs82JSe5KMp7kM0namxyUpCGbyZz+FcDfA1ftKlTV7+1aTnIZ8GTP+AeratU0+1kHvB+4FdgEnA58dfYtSweHFi9q6sVvv2f6VXUz8MR067qz9XcD1+xrH0mOAl5VVbdUVTH1C+Ts2bcrSepHv3P6bwEer6oHemorktyR5NtJ3tLVlgATPWMmutq0kqxNMpZkbHJyss8WJUm79Bv6a9j9LH8HcHRVnQD8KfDFJK+a7U6ran1VjVbV6MjItH/bV5I0B3O+Tz/JYuB3gRN31arqaeDpbnlLkgeBY4DtwNKezZd2NUnSPOrnzVlvA+6rqv+ftkkyAjxRVc8meS2wEnioqp5I8lSSk5m6kHsO8Hf9NK6Dixc1pReHmdyyeQ3wH8Drk0wkeV+3ajUvvID7VuDO7hbO64EPVtWui8AfAr4AjAMP4p07kjTv9numX1Vr9lJ/7zS1G4Ab9jJ+DDh+lv1JkgbId+RKUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDZnJH0bfkGRnkm09tUuSbE+ytXuc2bPuoiTjSe5PclpP/fSuNp7kwsF/K5Kk/ZnJmf4VwOnT1D9dVau6xyaAJMcCq4Hjum3+IcmiJIuAzwJnAMcCa7qxkqR5tHh/A6rq5iTLZ7i/s4Brq+pp4OEk48BJ3brxqnoIIMm13dh7Zt2xJGnO+pnTvyDJnd30z+FdbQnwWM+Yia62t/q0kqxNMpZkbHJyso8WJUm95hr664DXAauAHcBlA+sIqKr1VTVaVaMjIyOD3LUkNW2/0zvTqarHdy0n+Tzwle7pdmBZz9ClXY191CVJ82ROZ/pJjup5+i5g1509G4HVSQ5JsgJYCXwHuA1YmWRFkpcydbF349zbliTNxX7P9JNcA5wCHJFkArgYOCXJKqCAR4APAFTV3UmuY+oC7TPA+VX1bLefC4CvA4uADVV198C/G0nSPs3k7p0105Qv38f4S4FLp6lvAjbNqjtJ0kD5jlxJaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIfsN/SQbkuxMsq2n9tdJ7ktyZ5IbkxzW1Zcn+UmSrd3jcz3bnJjkriTjST6TJAfmW5Ik7c1MzvSvAE7fo7YZOL6qfhX4T+CinnUPVtWq7vHBnvo64P3Ayu6x5z4lSQfYfkO/qm4Gntij9o2qeqZ7eguwdF/7SHIU8KqquqWqCrgKOHtuLUuS5moQc/p/CHy15/mKJHck+XaSt3S1JcBEz5iJriZJmkeL+9k4yZ8BzwBXd6UdwNFV9YMkJwL/muS4Oex3LbAW4Oijj+6nRUlSjzmf6Sd5L/AO4Pe7KRuq6umq+kG3vAV4EDgG2M7uU0BLu9q0qmp9VY1W1ejIyMhcW5Qk7WFOoZ/kdOBjwDur6sc99ZEki7rl1zJ1wfahqtoBPJXk5O6unXOAL/fdvSRpVvY7vZPkGuAU4IgkE8DFTN2tcwiwubvz8pbuTp23Ap9I8jPgOeCDVbXrIvCHmLoT6GVMXQPovQ4gSZoH+w39qlozTfnyvYy9AbhhL+vGgONn1Z0kaaB8R64kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhoyo9BPsiHJziTbemqvTrI5yQPd18O7epJ8Jsl4kjuTvLFnm3O78Q8kOXfw344kaV9meqZ/BXD6HrULgZuqaiVwU/cc4AxgZfdYC6yDqV8SwMXAm4CTgIt3/aKQJM2PGYV+Vd0MPLFH+Szgym75SuDsnvpVNeUW4LAkRwGnAZur6omq+m9gMy/8RSJJOoD6mdM/sqp2dMvfA47slpcAj/WMm+hqe6u/QJK1ScaSjE1OTvbRoiSp10Au5FZVATWIfXX7W19Vo1U1OjIyMqjdSlLz+gn9x7tpG7qvO7v6dmBZz7ilXW1vdUnSPOkn9DcCu+7AORf4ck/9nO4unpOBJ7tpoK8Db09yeHcB9+1dTZI0TxbPZFCSa4BTgCOSTDB1F85fAtcleR/wKPDubvgm4ExgHPgxcB5AVT2R5C+A27pxn6iqPS8OS5IOoBmFflWt2cuqU6cZW8D5e9nPBmDDjLuTJA2U78iVpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGjLn0E/y+iRbex5PJflIkkuSbO+pn9mzzUVJxpPcn+S0wXwLkqSZmtEfRp9OVd0PrAJIsgjYDtwInAd8uqo+2Ts+ybHAauA44DXAN5McU1XPzrUHSdLsDGp651Tgwap6dB9jzgKuraqnq+phYBw4aUDHlyTNwKBCfzVwTc/zC5LcmWRDksO72hLgsZ4xE13tBZKsTTKWZGxycnJALUqS+g79JC8F3gn8S1daB7yOqamfHcBls91nVa2vqtGqGh0ZGem3RUlSZxBn+mcAt1fV4wBV9XhVPVtVzwGf5/kpnO3Asp7tlnY1SdI8GUTor6FnaifJUT3r3gVs65Y3AquTHJJkBbAS+M4Aji9JmqE5370DkORQ4LeBD/SU/yrJKqCAR3atq6q7k1wH3AM8A5zvnTuSNL/6Cv2q+hHwi3vU3rOP8ZcCl/ZzTEnS3PmOXElqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0JakhfYd+kkeS3JVka5KxrvbqJJuTPNB9PbyrJ8lnkownuTPJG/s9viRp5gZ1pv+bVbWqqka75xcCN1XVSuCm7jnAGcDK7rEWWDeg40uSZuBATe+cBVzZLV8JnN1Tv6qm3AIcluSoA9SDJGkPgwj9Ar6RZEuStV3tyKra0S1/DziyW14CPNaz7URX202StUnGkoxNTk4OoEVJEsDiAezjN6pqe5JfAjYnua93ZVVVkprNDqtqPbAeYHR0dFbbSpL2ru8z/ara3n3dCdwInAQ8vmvapvu6sxu+HVjWs/nSriZJmgd9hX6SQ5O8ctcy8HZgG7AROLcbdi7w5W55I3BOdxfPycCTPdNAkqQDrN/pnSOBG5Ps2tcXq+prSW4DrkvyPuBR4N3d+E3AmcA48GPgvD6PL0mahb5Cv6oeAt4wTf0HwKnT1As4v59jSpLmznfkSlJDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ2Zc+gnWZbkW0nuSXJ3kg939UuSbE+ytXuc2bPNRUnGk9yf5LRBfAOSpJnr5w+jPwN8tKpuT/JKYEuSzd26T1fVJ3sHJzkWWA0cB7wG+GaSY6rq2T56kCTNwpzP9KtqR1Xd3i3/ELgXWLKPTc4Crq2qp6vqYWAcOGmux5ckzd5A5vSTLAdOAG7tShckuTPJhiSHd7UlwGM9m02w718SkqQB6zv0k7wCuAH4SFU9BawDXgesAnYAl81hn2uTjCUZm5yc7LdFSVKnr9BP8hKmAv/qqvoSQFU9XlXPVtVzwOd5fgpnO7CsZ/OlXe0Fqmp9VY1W1ejIyEg/LUqSevRz906Ay4F7q+pTPfWjeoa9C9jWLW8EVic5JMkKYCXwnbkeX5I0e/3cvfNm4D3AXUm2drWPA2uSrAIKeAT4AEBV3Z3kOuAepu78Od87dyRpfs059Kvq34FMs2rTPra5FLh0rseUJPXHd+RKUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakh8x76SU5Pcn+S8SQXzvfxJall8xr6SRYBnwXOAI4F1iQ5dj57kKSWzfeZ/knAeFU9VFU/Ba4FzprnHiSpWYvn+XhLgMd6nk8Ab9pzUJK1wNru6f8muX+OxzsC+P4ct11ofC125+uxO1+P5x0Ur0UuST+b//LeVsx36M9IVa0H1ve7nyRjVTU6gJZe9HwtdufrsTtfj+ct9Ndivqd3tgPLep4v7WqSpHkw36F/G7AyyYokLwVWAxvnuQdJata8Tu9U1TNJLgC+DiwCNlTV3QfwkH1PES0gvha78/XYna/H8xb0a5GqGnYPkqR54jtyJakhhr4kNWRBhr4f9fC8JMuSfCvJPUnuTvLhYfc0bEkWJbkjyVeG3cuwJTksyfVJ7ktyb5JfG3ZPw5TkT7qfk21Jrkny88PuadAWXOj7UQ8v8Azw0ao6FjgZOL/x1wPgw8C9w27iIPG3wNeq6leAN9Dw65JkCfDHwGhVHc/UzSarh9vV4C240MePethNVe2oqtu75R8y9UO9ZLhdDU+SpcDvAF8Ydi/DluQXgLcClwNU1U+r6n+G29XQLQZelmQx8HLgv4bcz8AtxNCf7qMemg25XkmWAycAtw63k6H6G+BjwHPDbuQgsAKYBP6xm+76QpJDh93UsFTVduCTwHeBHcCTVfWN4XY1eAsx9DWNJK8AbgA+UlVPDbufYUjyDmBnVW0Zdi8HicXAG4F1VXUC8COg2WtgSQ5nalZgBfAa4NAkfzDcrgZvIYa+H/WwhyQvYSrwr66qLw27nyF6M/DOJI8wNe33W0n+abgtDdUEMFFVu/7P73qmfgm06m3Aw1U1WVU/A74E/PqQexq4hRj6ftRDjyRhas723qr61LD7GaaquqiqllbVcqb+XfxbVS24M7mZqqrvAY8leX1XOhW4Z4gtDdt3gZOTvLz7uTmVBXhh+6D8lM1+DOGjHg52bwbeA9yVZGtX+3hVbRpiTzp4/BFwdXeC9BBw3pD7GZqqujXJ9cDtTN31dgcL8CMZ/BgGSWrIQpzekSTthaEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGvJ/iSx5IDZcJTQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test, bins=10, color='g') #Plotting a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on the above steps:\n",
    "1. The above plot shows that the distribution of the labels in the y_test.\n",
    "2. The distibution is almost uniform but still there are some variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "id": "8KRjtLphDOpa",
    "outputId": "00c1ab93-c976-4608-afb5-810f4c2b43f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6000., 6000., 6000., 6000., 6000., 6000., 6000., 6000., 6000.,\n",
       "        6000.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_val, bins=10) #Plotting a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on the above steps:\n",
    "1. The above plot shows that the distribution of the labels in the y_test.\n",
    "2. The distibution is very uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Understanding the shape of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "U-S1OEZNB7pF",
    "outputId": "c4967e19-1391-40f7-b36b-6784ff1ce708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape and Data Type :\n",
      " X --->  Shape : (42000, 32, 32) and  Data Type :  float32\n",
      " y --->  Shape : (42000,)        and  Data Type :  uint8\n",
      "\n",
      "\n",
      "Testing Data Shape and Data Type :\n",
      " X --->  Shape : (18000, 32, 32) and  Data Type :  float32\n",
      " y --->  Shape : (18000,)        and  Data Type :  uint8\n",
      "\n",
      "\n",
      "Validation Data Shape and Data Type :\n",
      " X --->  Shape : (60000, 32, 32) and  Data Type :  float32\n",
      " y --->  Shape : (60000,)        and  Data Type :  uint8\n"
     ]
    }
   ],
   "source": [
    "print('Training Data Shape and Data Type :')\n",
    "print(\" X --->  Shape :\", X_train.shape,\"and  Data Type : \", X_train.dtype) #Extracting the shape and datatype of images.\n",
    "print(\" y --->  Shape :\", y_train.shape,\"       and  Data Type : \", y_train.dtype) #Extracting the shape of the Labels.\n",
    "print('\\n')\n",
    "print('Testing Data Shape and Data Type :')\n",
    "print(\" X --->  Shape :\", X_test.shape,\"and  Data Type : \", X_test.dtype) #Extracting the shape and datatype of images.\n",
    "print(\" y --->  Shape :\", y_test.shape,\"       and  Data Type : \", y_test.dtype) #Extracting the shape of the Labels.\n",
    "print('\\n')\n",
    "print('Validation Data Shape and Data Type :')\n",
    "print(\" X --->  Shape :\", X_val.shape,\"and  Data Type : \", X_val.dtype) #Extracting the shape and datatype of images.\n",
    "print(\" y --->  Shape :\", y_val.shape,\"       and  Data Type : \", y_val.dtype) #Extracting the shape of the Labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on the above steps:\n",
    "1. The above output shows the shape and datatype of the data available to us.\n",
    "2. Training, testing and validation data contains 42000, 18000 and 60000 images respectively.\n",
    "3. All the above dataset consisits images of size 32 x 32 (height x width).\n",
    "4. Data type of Labels (y) is in the form of unsigned integer of 8 bits (i.e) contains whole numbers from 0 to 255.\n",
    "5. Data type of images (X) is in the form of Float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Reshaping the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkWWKpJKIhWe"
   },
   "outputs": [],
   "source": [
    "#Extracting the Reshape of the data:\n",
    "X_train = X_train.reshape(42000,1024)\n",
    "X_test = X_test.reshape(18000,1024)\n",
    "X_val = X_val.reshape(60000,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "eBIWTjivRi2C",
    "outputId": "80083cab-8149-45a4-b2f2-a7435a765d0c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Reshaped Shape:\n",
      " X Shape : (42000, 1024)\n",
      " y Shape : (42000,)\n",
      "\n",
      "\n",
      "Testing Data Reshaped Shape:\n",
      " X Shape : (18000, 1024)\n",
      " y Shape : (18000,)\n",
      "\n",
      "\n",
      "Validation Reshaped Shape:\n",
      " X Shape : (60000, 1024)\n",
      " y Shape : (60000,)\n"
     ]
    }
   ],
   "source": [
    "#Checking the shape of the image and label:\n",
    "print('Training Data Reshaped Shape:')\n",
    "print(\" X Shape :\", X_train.shape)\n",
    "print(\" y Shape :\", y_train.shape)\n",
    "print('\\n')\n",
    "print('Testing Data Reshaped Shape:')\n",
    "print(\" X Shape :\", X_test.shape)\n",
    "print(\" y Shape :\", y_test.shape)\n",
    "print('\\n')\n",
    "print('Validation Reshaped Shape:')\n",
    "print(\" X Shape :\", X_val.shape)\n",
    "print(\" y Shape :\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on the above steps:\n",
    "1. The images dataset is reshaped (i.e) Flattened the data, we do Flattening of the input image in order to club the rows and columns of the image to support the NN architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: One - Hot Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "6Nz-5eoBTb1p",
    "outputId": "d8d2aa79-79ec-40d1-d403-478878bbfb5d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 6 7 4 4 0 3 0 7 3 1 0 1 3 1 1 0 0 8 4]\n",
      "\n",
      "\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:20]) # Printing the Labels before One-Hot Encoding.\n",
    "\n",
    "# On-Hot Encoding:\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes= 10)\n",
    "y_test  = tf.keras.utils.to_categorical(y_test, num_classes= 10)\n",
    "y_val   = tf.keras.utils.to_categorical(y_val, num_classes= 10)\n",
    "print('\\n')\n",
    "print(y_train[0:20]) # Printing the Labels after One-Hot Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on the above steps:\n",
    "1. In the above output we can see two outputs one is Label before one-hot encodeing and another Label is after one-hot encoding.\n",
    "2. The first output shows Labels before One-Hot Encoding (only numbers) which is not suitable for performing Cross-entropy.\n",
    "3. The second output shows the One-Hot encoded Output which is suitable for performing Cross -entropy to estimate the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Normalizing the images:\n",
    "     We have to do Normalization in order to make the pixel values uniform as the pixel values in the original image are different for each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "SN6C1DAnVAVR",
    "outputId": "d151b1ce-1e5e-4bbb-f996-9a076834f8c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data maximum and minimum pixel values :\n",
      " Maximum Pixel Value: 254.9745\n",
      " Minimum Pixel Value: 0.0\n",
      "\n",
      "\n",
      "Testing Data maximum and minimum pixel values :\n",
      " Maximum Pixel Value: 254.9745\n",
      " Minimum Pixel Value: 0.0\n",
      "\n",
      "\n",
      "Vallidation Data maximum and minimum pixel values :\n",
      " Maximum Pixel Value: 254.9745\n",
      " Minimum Pixel Value: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Training Data maximum and minimum pixel values :')\n",
    "print(' Maximum Pixel Value:',X_train.max()) # Fetching the maximum pixel value in X_train\n",
    "print(' Minimum Pixel Value:',X_train.min()) # Fetching the minimum pixel value in X_train\n",
    "print('\\n')\n",
    "print('Testing Data maximum and minimum pixel values :')\n",
    "print(' Maximum Pixel Value:',X_test.max()) # Fetching the maximum pixel value in X_test\n",
    "print(' Minimum Pixel Value:',X_test.min()) # Fetching the minimum pixel value in X_test\n",
    "print('\\n')\n",
    "print('Vallidation Data maximum and minimum pixel values :')\n",
    "print(' Maximum Pixel Value:',X_val.max()) # Fetching the maximum pixel value in X_val\n",
    "print(' Minimum Pixel Value:',X_val.min())  # Fetching the minimum pixel value in X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "hvxVhzNKXViB",
    "outputId": "dff7dc8a-d774-42cf-d92e-b9ab475f3612",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Normalized maximum and minimum pixel values :\n",
      " Maximum Normalized Pixel Value: 1.0\n",
      " Minimum Normalized Pixel Value: 0.0\n",
      "\n",
      "\n",
      "Testing Data Normalized maximum and minimum pixel values :\n",
      " Maximum Normalized Pixel Value: 1.0\n",
      " Minimum Normalized Pixel Value: 0.0\n",
      "\n",
      "\n",
      "Validation Data Normalized maximum and minimum pixel values :\n",
      " Maximum Normalized Pixel Value: 1.0\n",
      " Minimum Normalized Pixel Value: 0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train /  254.9745 #Dividing by the maximum value seen in the above output.\n",
    "X_test = X_test /  254.9745 #Dividing by the maximum value seen in the above output.\n",
    "X_val = X_val /  254.9745 #Dividing by the maximum value seen in the above output.\n",
    "\n",
    "print('Training Data Normalized maximum and minimum pixel values :')\n",
    "print(' Maximum Normalized Pixel Value:',X_train.max())\n",
    "print(' Minimum Normalized Pixel Value:',X_train.min())\n",
    "print('\\n')\n",
    "print('Testing Data Normalized maximum and minimum pixel values :')\n",
    "print(' Maximum Normalized Pixel Value:',X_test.max())\n",
    "print(' Minimum Normalized Pixel Value:',X_test.min())\n",
    "print('\\n')\n",
    "print('Validation Data Normalized maximum and minimum pixel values :')\n",
    "print(' Maximum Normalized Pixel Value:',X_val.max())\n",
    "print(' Minimum Normalized Pixel Value:',X_val.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "  In the above cells the maximum and minimum value of the pixels in the each dataset was understood and Normalized whose values are also printed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Model Building:\n",
    "\n",
    "  Here we build a Neural Network model which is capable of classifying the Google's Street view House Numbers to the maximum accuracy. Here all the models are Sequential Model (ie) these models take single input and give single output in each Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xg6SMcr7WgK"
   },
   "source": [
    "#### Model - 1 Building a basic model (Trial - 1)\n",
    "\n",
    " This model just consist only the Hidden and activation layers, the activation layer is a sigmoid function which makkes any input less than zero to value closer to zero and any input greater than one equal to any value closer to one. In all the models from here the final Layer consists of Softmax as its activation function to convert the output into probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebGEMcCEanxs"
   },
   "outputs": [],
   "source": [
    "model = Sequential()  #Creating a plain Keras Sequential model to stack the layers:\n",
    "\n",
    "#Adding the Input Layer and activation Layer using Keras Dense Function with 1024 Hidden Neurons:\n",
    "model.add(Dense(1024, input_shape = (1024, ), activation='sigmoid', name ='Layer_1'))\n",
    "\n",
    "#Adding the Layer_2and activation Layer using Keras Dense Function with 512 Hidden Neurons:\n",
    "model.add(Dense(512, activation='sigmoid', name ='Layer_2'))\n",
    "\n",
    "#Adding the Layer_3and activation Layer using Keras Dense Function with 128 Hidden Neurons:\n",
    "model.add(Dense(128, activation='sigmoid', name ='Layer_3'))\n",
    "\n",
    "#Adding the Layer_4and activation Layer using Keras Dense Function with 64 Hidden Neurons:\n",
    "model.add(Dense(64, activation='sigmoid', name ='Layer_4'))\n",
    "\n",
    "#Adding the Layer_5 and activation Layer using Keras Dense Function with 32 Hidden Neurons:\n",
    "model.add(Dense(32, activation='sigmoid', name ='Layer_5'))\n",
    "\n",
    "#Adding the Layer_6 and activation Layer using Keras Dense Function with 32 Hidden Neurons:\n",
    "model.add(Dense(32, activation='sigmoid', name ='Layer_6'))\n",
    "\n",
    "#Adding the Output Layer and Softmax as the activation Layer to convert the outputs into probabilities:\n",
    "model.add(Dense(10, activation='softmax', name ='Output_Layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBU4iVIZl9RW"
   },
   "outputs": [],
   "source": [
    "#Performing the Stochastic Gradient Descent Optimization to do optimization and update the parameters. \n",
    "learning_rate = 0.00001\n",
    "epochs = 100\n",
    "sgd = SGD(lr = learning_rate, decay = learning_rate/epochs, momentum = 0.8, nesterov=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6KfmTlPeOg7"
   },
   "outputs": [],
   "source": [
    "# config the model with losses and metrics:\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oe_hYZP8BMyz",
    "outputId": "9b71df57-405a-482f-89d1-38a2fd7a15de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 53us/step - loss: 2.4241 - accuracy: 0.0992\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4236 - accuracy: 0.0992\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4231 - accuracy: 0.0992\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4226 - accuracy: 0.0992\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4222 - accuracy: 0.0992\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4217 - accuracy: 0.0992\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4212 - accuracy: 0.0992\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4208 - accuracy: 0.0992\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4203 - accuracy: 0.0992\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4198 - accuracy: 0.0992\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4194 - accuracy: 0.0992\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4189 - accuracy: 0.0992\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4185 - accuracy: 0.0992\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4180 - accuracy: 0.0992\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4175 - accuracy: 0.0992\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4171 - accuracy: 0.0992\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4166 - accuracy: 0.0992\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4162 - accuracy: 0.0992\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4158 - accuracy: 0.0992\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4153 - accuracy: 0.0992\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4149 - accuracy: 0.0992\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4144 - accuracy: 0.0992\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4140 - accuracy: 0.0992\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4135 - accuracy: 0.0992\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4131 - accuracy: 0.0992\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4127 - accuracy: 0.0992\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4122 - accuracy: 0.0992\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4118 - accuracy: 0.0992\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4114 - accuracy: 0.0992\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4110 - accuracy: 0.0992\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4105 - accuracy: 0.0992\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4101 - accuracy: 0.0992\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4097 - accuracy: 0.0992\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4093 - accuracy: 0.0992\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4088 - accuracy: 0.0992\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4084 - accuracy: 0.0992\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4080 - accuracy: 0.0992\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4076 - accuracy: 0.0992\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4072 - accuracy: 0.0992\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4068 - accuracy: 0.0992\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4064 - accuracy: 0.0992\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4060 - accuracy: 0.0992\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4056 - accuracy: 0.0992\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4051 - accuracy: 0.0992\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4047 - accuracy: 0.0992\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4043 - accuracy: 0.0992\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4039 - accuracy: 0.0992\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4035 - accuracy: 0.0992\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4031 - accuracy: 0.0992\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4028 - accuracy: 0.0992\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4024 - accuracy: 0.0992\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4020 - accuracy: 0.0992\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4016 - accuracy: 0.0992\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4012 - accuracy: 0.0992\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4008 - accuracy: 0.0992\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4004 - accuracy: 0.0992\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4000 - accuracy: 0.0992\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3997 - accuracy: 0.0992\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3993 - accuracy: 0.0992\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3989 - accuracy: 0.0992\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3985 - accuracy: 0.0992\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3981 - accuracy: 0.0992\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3978 - accuracy: 0.0992\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3974 - accuracy: 0.0992\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3970 - accuracy: 0.0992\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3966 - accuracy: 0.0992\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3963 - accuracy: 0.0992\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3959 - accuracy: 0.0992\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3955 - accuracy: 0.0992\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3952 - accuracy: 0.0992\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3948 - accuracy: 0.0992\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3944 - accuracy: 0.0992\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3941 - accuracy: 0.0992\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3937 - accuracy: 0.0992\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3934 - accuracy: 0.0992\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3930 - accuracy: 0.0992\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3927 - accuracy: 0.0992\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3923 - accuracy: 0.0992\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3920 - accuracy: 0.0992\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3916 - accuracy: 0.0992\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3913 - accuracy: 0.0992\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3909 - accuracy: 0.0992\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3906 - accuracy: 0.0992\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3902 - accuracy: 0.0992\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3899 - accuracy: 0.0992\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3895 - accuracy: 0.0992\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3892 - accuracy: 0.0992\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3888 - accuracy: 0.0992\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3885 - accuracy: 0.0992\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3882 - accuracy: 0.0992\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3878 - accuracy: 0.0992\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3875 - accuracy: 0.0992\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3872 - accuracy: 0.0992\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3868 - accuracy: 0.0992\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3865 - accuracy: 0.0992\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3862 - accuracy: 0.0992\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3858 - accuracy: 0.0992\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3855 - accuracy: 0.0992\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3852 - accuracy: 0.0992\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3849 - accuracy: 0.0992\n"
     ]
    }
   ],
   "source": [
    "# Training the model with training datasets:\n",
    "history = model.fit(X_train, y_train, batch_size = 1000, epochs = epochs, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Fk4i016aBmCP",
    "outputId": "41dd122d-faf7-43ca-aa97-7484f80d1ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 91us/step\n",
      "Validation accuracy:  0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "# Testing the prerformance of the model on Validation Dataset:\n",
    "evaluation_val = model.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. In the above cells a Sequential model was created with six hidden layers consisting of above mentioned hidden Neurons.\n",
    "2. The created model was configured with loss and metrices.\n",
    "3. The configured m0del was also trained whose accuracy on training data is around 9.92% ~ 10%\n",
    "4. The accuracy is very low upon evaluating the same model on Validation Data the performance improves it comes exactly 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Let try improving the model by using different activations in the forthcoming trials. The activations with wich the models were tested are ReLU, elu, selu and LeakyReLU in the following trial 2, 3, 4 and  5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EZSQxDN_YLg"
   },
   "source": [
    "#### Model - 1 Building a basic model (Trial - 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "peCwSQC9_IqW"
   },
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Dense(1024, input_shape = (1024, ), activation='relu', name ='Layer_1'))\n",
    "\n",
    "model_1.add(Dense(512, activation='relu', name ='Layer_2'))\n",
    "\n",
    "model_1.add(Dense(128, activation='relu', name ='Layer_3'))\n",
    "\n",
    "model_1.add(Dense(64, activation='relu', name ='Layer_4'))\n",
    "\n",
    "model_1.add(Dense(32, activation='relu', name ='Layer_5'))\n",
    "\n",
    "model_1.add(Dense(32, activation='relu', name ='Layer_6'))\n",
    "\n",
    "model_1.add(Dense(10, activation='softmax', name ='Output_Layer'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "t81ax_oH_mXC",
    "outputId": "6298bffb-41a5-4b31-9b3b-ccaca19f78f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 17us/step - loss: 2.3052 - accuracy: 0.1018\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3051 - accuracy: 0.1020\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3051 - accuracy: 0.1021\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3050 - accuracy: 0.1022\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3050 - accuracy: 0.1024\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3049 - accuracy: 0.1025\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3048 - accuracy: 0.1024\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3048 - accuracy: 0.1025\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3047 - accuracy: 0.1027\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3047 - accuracy: 0.1029\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3046 - accuracy: 0.1029\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3046 - accuracy: 0.1030\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3045 - accuracy: 0.1030\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3045 - accuracy: 0.1034\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3044 - accuracy: 0.1035\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3044 - accuracy: 0.1037\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3043 - accuracy: 0.1036\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3043 - accuracy: 0.1035\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3043 - accuracy: 0.1036\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3042 - accuracy: 0.1036\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3042 - accuracy: 0.1034\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3041 - accuracy: 0.1034\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3041 - accuracy: 0.1033\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3040 - accuracy: 0.1031\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3040 - accuracy: 0.1030\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3040 - accuracy: 0.1029\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3039 - accuracy: 0.1030\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3039 - accuracy: 0.1031\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3038 - accuracy: 0.1031\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3038 - accuracy: 0.1034\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3038 - accuracy: 0.1034\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3037 - accuracy: 0.1032\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3037 - accuracy: 0.1029\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3037 - accuracy: 0.1028\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3036 - accuracy: 0.1027\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3036 - accuracy: 0.1027\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3036 - accuracy: 0.1028\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3035 - accuracy: 0.1030\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3035 - accuracy: 0.1026\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3035 - accuracy: 0.1027\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3034 - accuracy: 0.1028\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3034 - accuracy: 0.1027\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3034 - accuracy: 0.1026\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3034 - accuracy: 0.1024\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3033 - accuracy: 0.1024\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3033 - accuracy: 0.1023\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3033 - accuracy: 0.1021\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3032 - accuracy: 0.1020\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3032 - accuracy: 0.1022\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3032 - accuracy: 0.1023\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3032 - accuracy: 0.1020\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3031 - accuracy: 0.1019\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3031 - accuracy: 0.1016\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3031 - accuracy: 0.1017\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3031 - accuracy: 0.1015\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3030 - accuracy: 0.1013\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3030 - accuracy: 0.1013\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3030 - accuracy: 0.1013\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3030 - accuracy: 0.1014\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3029 - accuracy: 0.1011\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3029 - accuracy: 0.1010\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3029 - accuracy: 0.1009\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3029 - accuracy: 0.1007\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3029 - accuracy: 0.1006\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3028 - accuracy: 0.1005\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3028 - accuracy: 0.1005\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3028 - accuracy: 0.1004\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3028 - accuracy: 0.1005\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3027 - accuracy: 0.1004\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3027 - accuracy: 0.1004\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3027 - accuracy: 0.1002\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3027 - accuracy: 0.1001\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3027 - accuracy: 0.1000\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3026 - accuracy: 0.0999\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3026 - accuracy: 0.1000\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3026 - accuracy: 0.0998\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3026 - accuracy: 0.0997\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3026 - accuracy: 0.0995\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3025 - accuracy: 0.0995\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3025 - accuracy: 0.0995\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3025 - accuracy: 0.0995\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3025 - accuracy: 0.0995\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3025 - accuracy: 0.0994\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3024 - accuracy: 0.0992\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3024 - accuracy: 0.0992\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3024 - accuracy: 0.0991\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3024 - accuracy: 0.0991\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3024 - accuracy: 0.0992\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3024 - accuracy: 0.0992\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3023 - accuracy: 0.0992\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3023 - accuracy: 0.0992\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3023 - accuracy: 0.0991\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3023 - accuracy: 0.0990\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3023 - accuracy: 0.0987\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3022 - accuracy: 0.0987\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3022 - accuracy: 0.0986\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3022 - accuracy: 0.0985\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3022 - accuracy: 0.0985\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3022 - accuracy: 0.0985\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3022 - accuracy: 0.0985\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_1 = model_1.fit(X_train, y_train, batch_size = 1000, epochs = epochs, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KiJ7JrIiABih",
    "outputId": "35256777-4c2c-4f08-dcfa-58726d7fc364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 95us/step\n",
      "Validation accuracy:  0.09736666828393936\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_1 = model_1.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. In the above cells a Sequential model was created with six hidden layers consisting of above mentioned hidden Neurons.\n",
    "2. The created model was configured with loss and metrices.\n",
    "3. The configured model was also trained whose accuracy on training data is around 9.85% ~ 10%\n",
    "4. The accuracy is very low upon evaluating the same model on Validation Data the performance improves it comes around 9.73% ~ 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ij1RQ5nTBdvP"
   },
   "source": [
    "#### Model - 1 Building a basic model (Trial - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sx8kB8-dBdvo"
   },
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Dense(1024, input_shape = (1024, ), activation='elu', name ='Layer_1'))\n",
    "\n",
    "model_2.add(Dense(512, activation='elu', name ='Layer_2'))\n",
    "\n",
    "model_2.add(Dense(128, activation='elu', name ='Layer_3'))\n",
    "\n",
    "model_2.add(Dense(64, activation='elu', name ='Layer_4'))\n",
    "\n",
    "model_2.add(Dense(32, activation='elu', name ='Layer_5'))\n",
    "\n",
    "model_2.add(Dense(32, activation='elu', name ='Layer_6'))\n",
    "\n",
    "model_2.add(Dense(10, activation='softmax', name ='Output_Layer'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tdXTaAL_Bdv8",
    "outputId": "6bfd3a46-8800-4b8a-e42c-11f7a86af287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.3643 - accuracy: 0.1042\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3557 - accuracy: 0.1022\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3493 - accuracy: 0.1013\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3442 - accuracy: 0.0995\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3401 - accuracy: 0.0991\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3367 - accuracy: 0.0988\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3339 - accuracy: 0.0992\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3314 - accuracy: 0.0998\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3293 - accuracy: 0.1005\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3274 - accuracy: 0.1010\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3258 - accuracy: 0.1020\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3244 - accuracy: 0.1027\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3232 - accuracy: 0.1034\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3221 - accuracy: 0.1047\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3211 - accuracy: 0.1062\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3202 - accuracy: 0.1072\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3195 - accuracy: 0.1078\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3188 - accuracy: 0.1089\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3181 - accuracy: 0.1094\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3176 - accuracy: 0.1099\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3171 - accuracy: 0.1105\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3166 - accuracy: 0.1114\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3162 - accuracy: 0.1119\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3158 - accuracy: 0.1120\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3154 - accuracy: 0.1118\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3151 - accuracy: 0.1131\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3148 - accuracy: 0.1130\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3145 - accuracy: 0.1130\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3143 - accuracy: 0.1132\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3140 - accuracy: 0.1132\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3138 - accuracy: 0.1142\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3136 - accuracy: 0.1144\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3134 - accuracy: 0.1142\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3132 - accuracy: 0.1143\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3130 - accuracy: 0.1142\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3129 - accuracy: 0.1144\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3127 - accuracy: 0.1143\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3126 - accuracy: 0.1143\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3125 - accuracy: 0.1142\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3123 - accuracy: 0.1138\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3122 - accuracy: 0.1137\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3121 - accuracy: 0.1136\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3120 - accuracy: 0.1132\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3119 - accuracy: 0.1131\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3118 - accuracy: 0.1128\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3117 - accuracy: 0.1126\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3116 - accuracy: 0.1126\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3115 - accuracy: 0.1123\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3114 - accuracy: 0.1119\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3113 - accuracy: 0.1123\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3113 - accuracy: 0.1121\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3112 - accuracy: 0.1120\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3111 - accuracy: 0.1117\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3110 - accuracy: 0.1116\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3110 - accuracy: 0.1115\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3109 - accuracy: 0.1112\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3108 - accuracy: 0.1111\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3108 - accuracy: 0.1109\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3107 - accuracy: 0.1108\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3106 - accuracy: 0.1107\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3106 - accuracy: 0.1112\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3105 - accuracy: 0.1108\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3105 - accuracy: 0.1105\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3104 - accuracy: 0.1105\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3104 - accuracy: 0.1107\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3103 - accuracy: 0.1106\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3102 - accuracy: 0.1106\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3102 - accuracy: 0.1107\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3101 - accuracy: 0.1105\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3101 - accuracy: 0.1101\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3100 - accuracy: 0.1104\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3100 - accuracy: 0.1102\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3099 - accuracy: 0.1104\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3099 - accuracy: 0.1102\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3099 - accuracy: 0.1100\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3098 - accuracy: 0.1101\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3098 - accuracy: 0.1101\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3097 - accuracy: 0.1099\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3097 - accuracy: 0.1100\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3096 - accuracy: 0.1096\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3096 - accuracy: 0.1098\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3095 - accuracy: 0.1097\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3095 - accuracy: 0.1096\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3094 - accuracy: 0.1096\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3094 - accuracy: 0.1098\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3094 - accuracy: 0.1095\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3093 - accuracy: 0.1096\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3093 - accuracy: 0.1095\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3092 - accuracy: 0.1097\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3092 - accuracy: 0.1097\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3092 - accuracy: 0.1098\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3091 - accuracy: 0.1099\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3091 - accuracy: 0.1098\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3090 - accuracy: 0.1103\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3090 - accuracy: 0.1100\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3090 - accuracy: 0.1101\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3089 - accuracy: 0.1101\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3089 - accuracy: 0.1100\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3089 - accuracy: 0.1102\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3088 - accuracy: 0.1103\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_2 = model_2.fit(X_train, y_train, batch_size = 1000, epochs = epochs, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Bys0aMPUBdwK",
    "outputId": "fdfb9914-87c2-4a1d-b235-bc5083b5fea7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 94us/step\n",
      "Validation accuracy:  0.10991666465997696\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_2 = model_2.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. In the above cells a Sequential model was created with six hidden layers consisting of above mentioned hidden Neurons.\n",
    "2. The created model was configured with loss and metrices.\n",
    "3. The configured m0del was also trained whose accuracy on training data is around 11%\n",
    "4. The accuracy upon evaluating the same model on Validation Data the performance comes around only 11%.\n",
    "5. There is some improvement in this model copared to previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvNpR_8rGJxz"
   },
   "source": [
    "#### Model - 1 Building a basic model (Trial - 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXtXH0rCGJx4"
   },
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Dense(1024, input_shape = (1024, ), activation='selu', name ='Layer_1'))\n",
    "\n",
    "model_3.add(Dense(512, activation='selu', name ='Layer_2'))\n",
    "\n",
    "model_3.add(Dense(128, activation='selu', name ='Layer_3'))\n",
    "\n",
    "model_3.add(Dense(64, activation='selu', name ='Layer_4'))\n",
    "\n",
    "model_3.add(Dense(32, activation='selu', name ='Layer_5'))\n",
    "\n",
    "model_3.add(Dense(32, activation='selu', name ='Layer_6'))\n",
    "\n",
    "model_3.add(Dense(10, activation='softmax', name ='Output_Layer'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SMICbcnqGJyI",
    "outputId": "5ab42954-5308-4a95-9bcf-00348e64c5bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.4808 - accuracy: 0.1041\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4090 - accuracy: 0.1091\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3993 - accuracy: 0.1084\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3939 - accuracy: 0.1087\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3894 - accuracy: 0.1093\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3854 - accuracy: 0.1095\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3817 - accuracy: 0.1082\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3782 - accuracy: 0.1080\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3750 - accuracy: 0.1080\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3719 - accuracy: 0.1080\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3691 - accuracy: 0.1083\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3664 - accuracy: 0.1082\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3638 - accuracy: 0.1082\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3615 - accuracy: 0.1080\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3593 - accuracy: 0.1087\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3572 - accuracy: 0.1089\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3552 - accuracy: 0.1096\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3533 - accuracy: 0.1095\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3515 - accuracy: 0.1099\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3498 - accuracy: 0.1097\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3481 - accuracy: 0.1102\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3466 - accuracy: 0.1102\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3451 - accuracy: 0.1106\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3436 - accuracy: 0.1109\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3422 - accuracy: 0.1113\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3409 - accuracy: 0.1113\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3395 - accuracy: 0.1116\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3383 - accuracy: 0.1117\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3370 - accuracy: 0.1120\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3359 - accuracy: 0.1125\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3347 - accuracy: 0.1128\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3335 - accuracy: 0.1128\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3324 - accuracy: 0.1130\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3313 - accuracy: 0.1140\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3303 - accuracy: 0.1134\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3293 - accuracy: 0.1140\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3283 - accuracy: 0.1143\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3273 - accuracy: 0.1145\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3263 - accuracy: 0.1147\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3254 - accuracy: 0.1148\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3245 - accuracy: 0.1147\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3236 - accuracy: 0.1146\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3227 - accuracy: 0.1157\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3218 - accuracy: 0.1157\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3209 - accuracy: 0.1160\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3201 - accuracy: 0.1164\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3193 - accuracy: 0.1169\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3185 - accuracy: 0.1175\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3177 - accuracy: 0.1178\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3169 - accuracy: 0.1178\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3162 - accuracy: 0.1181\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3154 - accuracy: 0.1182\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3147 - accuracy: 0.1185\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3139 - accuracy: 0.1186\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3132 - accuracy: 0.1201\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3125 - accuracy: 0.1198\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3118 - accuracy: 0.1196\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3111 - accuracy: 0.1203\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3105 - accuracy: 0.1209\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3098 - accuracy: 0.1212\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3091 - accuracy: 0.1213\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3085 - accuracy: 0.1220\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3078 - accuracy: 0.1230\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3072 - accuracy: 0.1230\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3066 - accuracy: 0.1231\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3060 - accuracy: 0.1235\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3053 - accuracy: 0.1239\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3047 - accuracy: 0.1245\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3041 - accuracy: 0.1244\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3035 - accuracy: 0.1250\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3029 - accuracy: 0.1254\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3023 - accuracy: 0.1256\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3018 - accuracy: 0.1257\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3012 - accuracy: 0.1263\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3006 - accuracy: 0.1268\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3001 - accuracy: 0.1271\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2995 - accuracy: 0.1272\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2990 - accuracy: 0.1274\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2984 - accuracy: 0.1279\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2979 - accuracy: 0.1292\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2974 - accuracy: 0.1289\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2968 - accuracy: 0.1296\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2963 - accuracy: 0.1300\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2958 - accuracy: 0.1305\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2953 - accuracy: 0.1306\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2948 - accuracy: 0.1311\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2943 - accuracy: 0.1314\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2938 - accuracy: 0.1318\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2933 - accuracy: 0.1318\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2928 - accuracy: 0.1325\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2923 - accuracy: 0.1323\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2918 - accuracy: 0.1325\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2913 - accuracy: 0.1335\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2908 - accuracy: 0.1334\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2903 - accuracy: 0.1336\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2899 - accuracy: 0.1341\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2894 - accuracy: 0.1344\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2890 - accuracy: 0.1343\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2885 - accuracy: 0.1353\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2880 - accuracy: 0.1347\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_3 = model_3.fit(X_train, y_train, batch_size = 1000, epochs = epochs, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "jSHyNl8HGJyS",
    "outputId": "da863185-f7db-4d14-fbcd-4031dd60886a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 101us/step\n",
      "Validation accuracy:  0.13593333959579468\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_3 = model_3.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. In the above cells a Sequential model was created with six hidden layers consisting of above mentioned hidden Neurons.\n",
    "2. The created model was configured with loss and metrices.\n",
    "3. The configured m0del was also trained whose accuracy on training data is around 13%\n",
    "4. The accuracy upon evaluating the same model on Validation Data the performance improves it comes around 14%.\n",
    "5. This model performance is better than the performance of the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zfSxybhHg5zH"
   },
   "source": [
    "#### Model - 1 Building a basic model (Trial - 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YLOjaRqg5zK"
   },
   "outputs": [],
   "source": [
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(Dense(1024, input_shape = (1024, ), name ='Layer_1'))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model_5.add(Dense(512, name ='Layer_2'))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model_5.add(Dense(128, name ='Layer_3'))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model_5.add(Dense(64, name ='Layer_4'))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model_5.add(Dense(32, name ='Layer_5'))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model_5.add(Dense(32, name ='Layer_6'))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model_5.add(Dense(10, activation='softmax', name ='Output_Layer'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oDMenKSfg5zV",
    "outputId": "fecd2206-7690-4610-83b2-dfa1b561b0b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 17us/step - loss: 2.3087 - accuracy: 0.1018\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3086 - accuracy: 0.1018\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3084 - accuracy: 0.1020\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3083 - accuracy: 0.1019\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3082 - accuracy: 0.1019\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3081 - accuracy: 0.1019\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3079 - accuracy: 0.1019\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3078 - accuracy: 0.1020\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3077 - accuracy: 0.1020\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3076 - accuracy: 0.1018\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3075 - accuracy: 0.1018\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3074 - accuracy: 0.1017\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3073 - accuracy: 0.1017\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3072 - accuracy: 0.1018\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3071 - accuracy: 0.1018\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3070 - accuracy: 0.1016\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3069 - accuracy: 0.1017\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3069 - accuracy: 0.1018\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3068 - accuracy: 0.1017\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3067 - accuracy: 0.1018\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3066 - accuracy: 0.1018\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3066 - accuracy: 0.1016\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3065 - accuracy: 0.1017\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3064 - accuracy: 0.1017\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3063 - accuracy: 0.1017\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3063 - accuracy: 0.1017\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3062 - accuracy: 0.1017\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3061 - accuracy: 0.1017\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3061 - accuracy: 0.1017\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3060 - accuracy: 0.1018\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3059 - accuracy: 0.1019\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3059 - accuracy: 0.1019\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3058 - accuracy: 0.1019\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3058 - accuracy: 0.1019\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3057 - accuracy: 0.1020\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3057 - accuracy: 0.1020\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3056 - accuracy: 0.1019\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3056 - accuracy: 0.1019\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3055 - accuracy: 0.1020\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3055 - accuracy: 0.1020\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3054 - accuracy: 0.1020\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3054 - accuracy: 0.1020\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3053 - accuracy: 0.1022\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3053 - accuracy: 0.1023\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3052 - accuracy: 0.1024\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3052 - accuracy: 0.1026\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3051 - accuracy: 0.1026\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3051 - accuracy: 0.1026\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3051 - accuracy: 0.1028\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3050 - accuracy: 0.1029\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3050 - accuracy: 0.1027\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3049 - accuracy: 0.1027\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3049 - accuracy: 0.1028\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3049 - accuracy: 0.1028\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3048 - accuracy: 0.1030\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3048 - accuracy: 0.1031\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3048 - accuracy: 0.1032\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3047 - accuracy: 0.1033\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3047 - accuracy: 0.1031\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3047 - accuracy: 0.1032\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3046 - accuracy: 0.1031\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3046 - accuracy: 0.1030\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3046 - accuracy: 0.1030\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3046 - accuracy: 0.1031\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3045 - accuracy: 0.1032\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3045 - accuracy: 0.1030\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3045 - accuracy: 0.1030\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3044 - accuracy: 0.1030\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3044 - accuracy: 0.1030\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3044 - accuracy: 0.1028\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3044 - accuracy: 0.1028\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3043 - accuracy: 0.1027\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3043 - accuracy: 0.1026\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3043 - accuracy: 0.1028\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3043 - accuracy: 0.1028\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3042 - accuracy: 0.1031\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3042 - accuracy: 0.1031\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3042 - accuracy: 0.1030\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3042 - accuracy: 0.1027\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3041 - accuracy: 0.1027\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3041 - accuracy: 0.1027\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3041 - accuracy: 0.1028\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3041 - accuracy: 0.1030\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3041 - accuracy: 0.1028\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3040 - accuracy: 0.1026\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3040 - accuracy: 0.1025\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3040 - accuracy: 0.1025\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3040 - accuracy: 0.1025\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3039 - accuracy: 0.1025\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3039 - accuracy: 0.1024\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3039 - accuracy: 0.1022\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3039 - accuracy: 0.1023\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3039 - accuracy: 0.1022\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3038 - accuracy: 0.1021\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3038 - accuracy: 0.1022\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3038 - accuracy: 0.1019\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3038 - accuracy: 0.1019\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3038 - accuracy: 0.1019\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3037 - accuracy: 0.1018\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3037 - accuracy: 0.1021\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_5 = model_5.fit(X_train, y_train, batch_size = 1000, epochs = epochs, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cpBG3eC-g5zf",
    "outputId": "26d31857-0374-4321-8e73-1698648223f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 90us/step\n",
      "Validation accuracy:  0.10204999893903732\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_5 = model_5.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_5[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. In the above cells a Sequential model was created with six hidden layers consisting of above mentioned hidden Neurons.\n",
    "2. The created model was configured with loss and metrices.\n",
    "3. The configured m0del was also trained whose accuracy on training data is around 9.92% ~ 10%\n",
    "4. The accuracy upon evaluating the same model on Validation Data the performance improves it comes exactly 10%.\n",
    "5. Therefore, we can use this model and do some improvemnts on this and try to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhprY-jzitf_"
   },
   "source": [
    "    In the above all trials it can be found that when selu activation functioin was used the model performance improved. But still its performance also very very low for reality. Further, let us try improving that model's performace by initializing weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRaFL9GLjOAR"
   },
   "source": [
    "#### Model - 2 Constructing the model with Weight initalization:\n",
    "    Here the Sequential model is built with Selu activations in the hidden layers and initlaizing the weights based on the 'He-Normal' initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xAWNEBKVjOAV"
   },
   "outputs": [],
   "source": [
    "model_wt = Sequential()\n",
    "\n",
    "model_wt.add(Dense(1024, input_shape = (1024, ), activation='elu', kernel_initializer='he_normal', name ='Layer_1'))\n",
    "\n",
    "model_wt.add(Dense(512, activation='selu', kernel_initializer='he_normal', name ='Layer_2'))\n",
    "\n",
    "model_wt.add(Dense(128, activation='selu', kernel_initializer='he_normal', name ='Layer_3'))\n",
    "\n",
    "model_wt.add(Dense(64, activation='selu', kernel_initializer='he_normal', name ='Layer_4'))\n",
    "\n",
    "model_wt.add(Dense(32, activation='selu', kernel_initializer='he_normal', name ='Layer_5'))\n",
    "\n",
    "model_wt.add(Dense(32, activation='selu', kernel_initializer='he_normal', name ='Layer_6'))\n",
    "\n",
    "model_wt.add(Dense(10, activation='softmax', name ='Output_Layer'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LUaMuNLRjOAf",
    "outputId": "c3a84b74-8bd1-45c8-9707-1a1a378f470d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "42000/42000 [==============================] - 1s 19us/step - loss: 2.9848 - accuracy: 0.0876\n",
      "Epoch 2/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7770 - accuracy: 0.0850\n",
      "Epoch 3/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7329 - accuracy: 0.0864\n",
      "Epoch 4/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6964 - accuracy: 0.0864\n",
      "Epoch 5/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6644 - accuracy: 0.0865\n",
      "Epoch 6/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6360 - accuracy: 0.0875\n",
      "Epoch 7/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6112 - accuracy: 0.0890\n",
      "Epoch 8/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5899 - accuracy: 0.0897\n",
      "Epoch 9/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5715 - accuracy: 0.0913\n",
      "Epoch 10/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5555 - accuracy: 0.0928\n",
      "Epoch 11/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5415 - accuracy: 0.0940\n",
      "Epoch 12/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5289 - accuracy: 0.0954\n",
      "Epoch 13/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5176 - accuracy: 0.0962\n",
      "Epoch 14/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5075 - accuracy: 0.0971\n",
      "Epoch 15/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4984 - accuracy: 0.0983\n",
      "Epoch 16/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4901 - accuracy: 0.1003\n",
      "Epoch 17/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4825 - accuracy: 0.1011\n",
      "Epoch 18/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4755 - accuracy: 0.1020\n",
      "Epoch 19/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4691 - accuracy: 0.1029\n",
      "Epoch 20/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4630 - accuracy: 0.1032\n",
      "Epoch 21/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4574 - accuracy: 0.1035\n",
      "Epoch 22/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4522 - accuracy: 0.1040\n",
      "Epoch 23/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4474 - accuracy: 0.1047\n",
      "Epoch 24/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4428 - accuracy: 0.1049\n",
      "Epoch 25/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4386 - accuracy: 0.1047\n",
      "Epoch 26/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4346 - accuracy: 0.1052\n",
      "Epoch 27/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4308 - accuracy: 0.1053\n",
      "Epoch 28/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4272 - accuracy: 0.1055\n",
      "Epoch 29/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4238 - accuracy: 0.1056\n",
      "Epoch 30/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4207 - accuracy: 0.1057\n",
      "Epoch 31/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4176 - accuracy: 0.1058\n",
      "Epoch 32/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4146 - accuracy: 0.1061\n",
      "Epoch 33/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4119 - accuracy: 0.1067\n",
      "Epoch 34/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4092 - accuracy: 0.1068\n",
      "Epoch 35/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4066 - accuracy: 0.1067\n",
      "Epoch 36/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4041 - accuracy: 0.1073\n",
      "Epoch 37/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4016 - accuracy: 0.1078\n",
      "Epoch 38/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3992 - accuracy: 0.1079\n",
      "Epoch 39/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3970 - accuracy: 0.1088\n",
      "Epoch 40/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3947 - accuracy: 0.1087\n",
      "Epoch 41/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3926 - accuracy: 0.1092\n",
      "Epoch 42/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3906 - accuracy: 0.1085\n",
      "Epoch 43/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3886 - accuracy: 0.1087\n",
      "Epoch 44/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3866 - accuracy: 0.1090\n",
      "Epoch 45/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3847 - accuracy: 0.1096\n",
      "Epoch 46/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3829 - accuracy: 0.1100\n",
      "Epoch 47/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3811 - accuracy: 0.1097\n",
      "Epoch 48/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3794 - accuracy: 0.1102\n",
      "Epoch 49/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3778 - accuracy: 0.1107\n",
      "Epoch 50/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3761 - accuracy: 0.1108\n",
      "Epoch 51/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3746 - accuracy: 0.1110\n",
      "Epoch 52/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3730 - accuracy: 0.1113\n",
      "Epoch 53/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3715 - accuracy: 0.1117\n",
      "Epoch 54/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3700 - accuracy: 0.1122\n",
      "Epoch 55/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3685 - accuracy: 0.1118\n",
      "Epoch 56/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3671 - accuracy: 0.1131\n",
      "Epoch 57/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3657 - accuracy: 0.1125\n",
      "Epoch 58/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3644 - accuracy: 0.1126\n",
      "Epoch 59/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3630 - accuracy: 0.1124\n",
      "Epoch 60/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3617 - accuracy: 0.1132\n",
      "Epoch 61/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3604 - accuracy: 0.1133\n",
      "Epoch 62/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3592 - accuracy: 0.1128\n",
      "Epoch 63/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3579 - accuracy: 0.1134\n",
      "Epoch 64/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3567 - accuracy: 0.1141\n",
      "Epoch 65/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3555 - accuracy: 0.1136\n",
      "Epoch 66/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3544 - accuracy: 0.1138\n",
      "Epoch 67/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3532 - accuracy: 0.1145\n",
      "Epoch 68/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3521 - accuracy: 0.1145\n",
      "Epoch 69/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3510 - accuracy: 0.1151\n",
      "Epoch 70/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3499 - accuracy: 0.1150\n",
      "Epoch 71/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3489 - accuracy: 0.1157\n",
      "Epoch 72/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3478 - accuracy: 0.1152\n",
      "Epoch 73/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3469 - accuracy: 0.1156\n",
      "Epoch 74/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3459 - accuracy: 0.1160\n",
      "Epoch 75/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3449 - accuracy: 0.1164\n",
      "Epoch 76/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3439 - accuracy: 0.1171\n",
      "Epoch 77/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3430 - accuracy: 0.1172\n",
      "Epoch 78/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3421 - accuracy: 0.1174\n",
      "Epoch 79/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3412 - accuracy: 0.1172\n",
      "Epoch 80/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3402 - accuracy: 0.1179\n",
      "Epoch 81/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3393 - accuracy: 0.1181\n",
      "Epoch 82/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3385 - accuracy: 0.1183\n",
      "Epoch 83/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3376 - accuracy: 0.1188\n",
      "Epoch 84/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3368 - accuracy: 0.1184\n",
      "Epoch 85/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3359 - accuracy: 0.1185\n",
      "Epoch 86/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3351 - accuracy: 0.1193\n",
      "Epoch 87/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3343 - accuracy: 0.1193\n",
      "Epoch 88/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3334 - accuracy: 0.1197\n",
      "Epoch 89/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3326 - accuracy: 0.1199\n",
      "Epoch 90/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3318 - accuracy: 0.1203\n",
      "Epoch 91/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3311 - accuracy: 0.1203\n",
      "Epoch 92/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3303 - accuracy: 0.1202\n",
      "Epoch 93/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3295 - accuracy: 0.1210\n",
      "Epoch 94/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3288 - accuracy: 0.1208\n",
      "Epoch 95/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3281 - accuracy: 0.1211\n",
      "Epoch 96/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3274 - accuracy: 0.1214\n",
      "Epoch 97/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3267 - accuracy: 0.1215\n",
      "Epoch 98/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3260 - accuracy: 0.1222\n",
      "Epoch 99/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3253 - accuracy: 0.1217\n",
      "Epoch 100/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3246 - accuracy: 0.1219\n",
      "Epoch 101/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3239 - accuracy: 0.1223\n",
      "Epoch 102/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3233 - accuracy: 0.1228\n",
      "Epoch 103/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3226 - accuracy: 0.1221\n",
      "Epoch 104/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3220 - accuracy: 0.1229\n",
      "Epoch 105/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3214 - accuracy: 0.1227\n",
      "Epoch 106/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3207 - accuracy: 0.1230\n",
      "Epoch 107/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3201 - accuracy: 0.1232\n",
      "Epoch 108/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3195 - accuracy: 0.1233\n",
      "Epoch 109/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3189 - accuracy: 0.1239\n",
      "Epoch 110/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3183 - accuracy: 0.1237\n",
      "Epoch 111/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3177 - accuracy: 0.1238\n",
      "Epoch 112/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3171 - accuracy: 0.1235\n",
      "Epoch 113/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3165 - accuracy: 0.1246\n",
      "Epoch 114/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3159 - accuracy: 0.1246\n",
      "Epoch 115/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3154 - accuracy: 0.1249\n",
      "Epoch 116/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3148 - accuracy: 0.1251\n",
      "Epoch 117/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3142 - accuracy: 0.1256\n",
      "Epoch 118/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3137 - accuracy: 0.1255\n",
      "Epoch 119/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3132 - accuracy: 0.1262\n",
      "Epoch 120/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3126 - accuracy: 0.1263\n",
      "Epoch 121/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3121 - accuracy: 0.1267\n",
      "Epoch 122/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3115 - accuracy: 0.1263\n",
      "Epoch 123/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3110 - accuracy: 0.1268\n",
      "Epoch 124/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3104 - accuracy: 0.1270\n",
      "Epoch 125/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3099 - accuracy: 0.1272\n",
      "Epoch 126/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3094 - accuracy: 0.1272\n",
      "Epoch 127/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3088 - accuracy: 0.1277\n",
      "Epoch 128/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3083 - accuracy: 0.1282\n",
      "Epoch 129/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3078 - accuracy: 0.1281\n",
      "Epoch 130/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3073 - accuracy: 0.1280\n",
      "Epoch 131/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3068 - accuracy: 0.1281\n",
      "Epoch 132/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3063 - accuracy: 0.1299\n",
      "Epoch 133/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3058 - accuracy: 0.1290\n",
      "Epoch 134/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3053 - accuracy: 0.1295\n",
      "Epoch 135/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3048 - accuracy: 0.1295\n",
      "Epoch 136/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3043 - accuracy: 0.1296\n",
      "Epoch 137/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3038 - accuracy: 0.1304\n",
      "Epoch 138/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3033 - accuracy: 0.1304\n",
      "Epoch 139/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3028 - accuracy: 0.1310\n",
      "Epoch 140/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3023 - accuracy: 0.1314\n",
      "Epoch 141/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3019 - accuracy: 0.1312\n",
      "Epoch 142/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3014 - accuracy: 0.1316\n",
      "Epoch 143/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3009 - accuracy: 0.1315\n",
      "Epoch 144/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3004 - accuracy: 0.1323\n",
      "Epoch 145/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2999 - accuracy: 0.1324\n",
      "Epoch 146/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2995 - accuracy: 0.1324\n",
      "Epoch 147/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2990 - accuracy: 0.1324\n",
      "Epoch 148/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2986 - accuracy: 0.1330\n",
      "Epoch 149/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2981 - accuracy: 0.1333\n",
      "Epoch 150/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2976 - accuracy: 0.1338\n",
      "Epoch 151/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2972 - accuracy: 0.1338\n",
      "Epoch 152/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2967 - accuracy: 0.1345\n",
      "Epoch 153/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2963 - accuracy: 0.1345\n",
      "Epoch 154/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2959 - accuracy: 0.1347\n",
      "Epoch 155/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2954 - accuracy: 0.1350\n",
      "Epoch 156/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2950 - accuracy: 0.1349\n",
      "Epoch 157/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2945 - accuracy: 0.1355\n",
      "Epoch 158/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2941 - accuracy: 0.1356\n",
      "Epoch 159/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2937 - accuracy: 0.1351\n",
      "Epoch 160/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2932 - accuracy: 0.1363\n",
      "Epoch 161/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2928 - accuracy: 0.1365\n",
      "Epoch 162/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2924 - accuracy: 0.1371\n",
      "Epoch 163/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2919 - accuracy: 0.1364\n",
      "Epoch 164/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2915 - accuracy: 0.1367\n",
      "Epoch 165/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2911 - accuracy: 0.1375\n",
      "Epoch 166/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2907 - accuracy: 0.1373\n",
      "Epoch 167/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2902 - accuracy: 0.1377\n",
      "Epoch 168/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2898 - accuracy: 0.1379\n",
      "Epoch 169/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2894 - accuracy: 0.1387\n",
      "Epoch 170/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2890 - accuracy: 0.1377\n",
      "Epoch 171/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2886 - accuracy: 0.1391\n",
      "Epoch 172/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2882 - accuracy: 0.1393\n",
      "Epoch 173/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2878 - accuracy: 0.1394\n",
      "Epoch 174/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2873 - accuracy: 0.1395\n",
      "Epoch 175/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2869 - accuracy: 0.1394\n",
      "Epoch 176/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2866 - accuracy: 0.1400\n",
      "Epoch 177/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2861 - accuracy: 0.1403\n",
      "Epoch 178/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2857 - accuracy: 0.1410\n",
      "Epoch 179/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2853 - accuracy: 0.1409\n",
      "Epoch 180/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2849 - accuracy: 0.1413\n",
      "Epoch 181/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2845 - accuracy: 0.1416\n",
      "Epoch 182/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2841 - accuracy: 0.1418\n",
      "Epoch 183/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2837 - accuracy: 0.1419\n",
      "Epoch 184/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2833 - accuracy: 0.1419\n",
      "Epoch 185/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2830 - accuracy: 0.1423\n",
      "Epoch 186/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2826 - accuracy: 0.1431\n",
      "Epoch 187/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2822 - accuracy: 0.1428\n",
      "Epoch 188/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2818 - accuracy: 0.1434\n",
      "Epoch 189/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2814 - accuracy: 0.1435\n",
      "Epoch 190/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2811 - accuracy: 0.1436\n",
      "Epoch 191/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2806 - accuracy: 0.1435\n",
      "Epoch 192/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2803 - accuracy: 0.1448\n",
      "Epoch 193/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2799 - accuracy: 0.1445\n",
      "Epoch 194/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2795 - accuracy: 0.1445\n",
      "Epoch 195/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2791 - accuracy: 0.1446\n",
      "Epoch 196/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2787 - accuracy: 0.1449\n",
      "Epoch 197/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2784 - accuracy: 0.1457\n",
      "Epoch 198/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2780 - accuracy: 0.1460\n",
      "Epoch 199/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2776 - accuracy: 0.1455\n",
      "Epoch 200/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2773 - accuracy: 0.1465\n",
      "Epoch 201/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2769 - accuracy: 0.1467\n",
      "Epoch 202/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2765 - accuracy: 0.1465\n",
      "Epoch 203/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2762 - accuracy: 0.1475\n",
      "Epoch 204/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2758 - accuracy: 0.1475\n",
      "Epoch 205/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2754 - accuracy: 0.1477\n",
      "Epoch 206/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2750 - accuracy: 0.1483\n",
      "Epoch 207/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2747 - accuracy: 0.1477\n",
      "Epoch 208/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2743 - accuracy: 0.1489\n",
      "Epoch 209/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2740 - accuracy: 0.1487\n",
      "Epoch 210/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2736 - accuracy: 0.1484\n",
      "Epoch 211/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2732 - accuracy: 0.1489\n",
      "Epoch 212/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2729 - accuracy: 0.1488\n",
      "Epoch 213/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2725 - accuracy: 0.1494\n",
      "Epoch 214/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2722 - accuracy: 0.1493\n",
      "Epoch 215/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2718 - accuracy: 0.1506\n",
      "Epoch 216/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2715 - accuracy: 0.1509\n",
      "Epoch 217/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2711 - accuracy: 0.1505\n",
      "Epoch 218/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2707 - accuracy: 0.1508\n",
      "Epoch 219/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2704 - accuracy: 0.1515\n",
      "Epoch 220/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2701 - accuracy: 0.1510\n",
      "Epoch 221/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2697 - accuracy: 0.1519\n",
      "Epoch 222/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2693 - accuracy: 0.1518\n",
      "Epoch 223/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2690 - accuracy: 0.1528\n",
      "Epoch 224/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2686 - accuracy: 0.1521\n",
      "Epoch 225/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2683 - accuracy: 0.1528\n",
      "Epoch 226/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2679 - accuracy: 0.1531\n",
      "Epoch 227/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2676 - accuracy: 0.1528\n",
      "Epoch 228/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2672 - accuracy: 0.1536\n",
      "Epoch 229/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2669 - accuracy: 0.1535\n",
      "Epoch 230/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2665 - accuracy: 0.1541\n",
      "Epoch 231/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2662 - accuracy: 0.1551\n",
      "Epoch 232/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2658 - accuracy: 0.1550\n",
      "Epoch 233/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2655 - accuracy: 0.1557\n",
      "Epoch 234/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2651 - accuracy: 0.1554\n",
      "Epoch 235/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2648 - accuracy: 0.1550\n",
      "Epoch 236/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2644 - accuracy: 0.1558\n",
      "Epoch 237/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2641 - accuracy: 0.1563\n",
      "Epoch 238/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2637 - accuracy: 0.1562\n",
      "Epoch 239/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2634 - accuracy: 0.1563\n",
      "Epoch 240/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2631 - accuracy: 0.1567\n",
      "Epoch 241/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2627 - accuracy: 0.1573\n",
      "Epoch 242/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2624 - accuracy: 0.1575\n",
      "Epoch 243/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2621 - accuracy: 0.1570\n",
      "Epoch 244/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2617 - accuracy: 0.1573\n",
      "Epoch 245/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2614 - accuracy: 0.1575\n",
      "Epoch 246/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2610 - accuracy: 0.1587\n",
      "Epoch 247/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2607 - accuracy: 0.1577\n",
      "Epoch 248/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2603 - accuracy: 0.1579\n",
      "Epoch 249/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2600 - accuracy: 0.1583\n",
      "Epoch 250/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2596 - accuracy: 0.1592\n",
      "Epoch 251/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2593 - accuracy: 0.1589\n",
      "Epoch 252/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2590 - accuracy: 0.1595\n",
      "Epoch 253/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2586 - accuracy: 0.1595\n",
      "Epoch 254/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2583 - accuracy: 0.1596\n",
      "Epoch 255/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2580 - accuracy: 0.1599\n",
      "Epoch 256/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2576 - accuracy: 0.1605\n",
      "Epoch 257/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2573 - accuracy: 0.1605\n",
      "Epoch 258/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2569 - accuracy: 0.1610\n",
      "Epoch 259/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2566 - accuracy: 0.1610\n",
      "Epoch 260/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2563 - accuracy: 0.1613\n",
      "Epoch 261/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2560 - accuracy: 0.1615\n",
      "Epoch 262/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2556 - accuracy: 0.1620\n",
      "Epoch 263/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2553 - accuracy: 0.1622\n",
      "Epoch 264/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2549 - accuracy: 0.1625\n",
      "Epoch 265/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2546 - accuracy: 0.1622\n",
      "Epoch 266/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2543 - accuracy: 0.1625\n",
      "Epoch 267/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2539 - accuracy: 0.1634\n",
      "Epoch 268/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2536 - accuracy: 0.1635\n",
      "Epoch 269/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2533 - accuracy: 0.1634\n",
      "Epoch 270/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2529 - accuracy: 0.1634\n",
      "Epoch 271/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2526 - accuracy: 0.1636\n",
      "Epoch 272/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2523 - accuracy: 0.1646\n",
      "Epoch 273/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2519 - accuracy: 0.1644\n",
      "Epoch 274/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2516 - accuracy: 0.1654\n",
      "Epoch 275/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2513 - accuracy: 0.1645\n",
      "Epoch 276/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2509 - accuracy: 0.1656\n",
      "Epoch 277/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2506 - accuracy: 0.1656\n",
      "Epoch 278/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2503 - accuracy: 0.1654\n",
      "Epoch 279/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2499 - accuracy: 0.1661\n",
      "Epoch 280/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2496 - accuracy: 0.1667\n",
      "Epoch 281/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2493 - accuracy: 0.1662\n",
      "Epoch 282/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2489 - accuracy: 0.1664\n",
      "Epoch 283/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2486 - accuracy: 0.1672\n",
      "Epoch 284/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2483 - accuracy: 0.1670\n",
      "Epoch 285/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2480 - accuracy: 0.1676\n",
      "Epoch 286/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2476 - accuracy: 0.1675\n",
      "Epoch 287/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2473 - accuracy: 0.1678\n",
      "Epoch 288/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2470 - accuracy: 0.1685\n",
      "Epoch 289/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2466 - accuracy: 0.1679\n",
      "Epoch 290/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2463 - accuracy: 0.1692\n",
      "Epoch 291/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2459 - accuracy: 0.1687\n",
      "Epoch 292/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2456 - accuracy: 0.1697\n",
      "Epoch 293/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2453 - accuracy: 0.1699\n",
      "Epoch 294/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2449 - accuracy: 0.1696\n",
      "Epoch 295/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2446 - accuracy: 0.1697\n",
      "Epoch 296/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2443 - accuracy: 0.1705\n",
      "Epoch 297/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2439 - accuracy: 0.1702\n",
      "Epoch 298/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2436 - accuracy: 0.1709\n",
      "Epoch 299/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2433 - accuracy: 0.1708\n",
      "Epoch 300/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2430 - accuracy: 0.1715\n",
      "Epoch 301/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2426 - accuracy: 0.1713\n",
      "Epoch 302/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2423 - accuracy: 0.1717\n",
      "Epoch 303/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2419 - accuracy: 0.1720\n",
      "Epoch 304/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2416 - accuracy: 0.1722\n",
      "Epoch 305/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2413 - accuracy: 0.1722\n",
      "Epoch 306/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2409 - accuracy: 0.1727\n",
      "Epoch 307/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2406 - accuracy: 0.1726\n",
      "Epoch 308/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2403 - accuracy: 0.1729\n",
      "Epoch 309/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2400 - accuracy: 0.1739\n",
      "Epoch 310/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2396 - accuracy: 0.1735\n",
      "Epoch 311/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2393 - accuracy: 0.1738\n",
      "Epoch 312/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2389 - accuracy: 0.1748\n",
      "Epoch 313/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2386 - accuracy: 0.1748\n",
      "Epoch 314/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2383 - accuracy: 0.1747\n",
      "Epoch 315/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2380 - accuracy: 0.1753\n",
      "Epoch 316/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2376 - accuracy: 0.1750\n",
      "Epoch 317/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2373 - accuracy: 0.1756\n",
      "Epoch 318/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2370 - accuracy: 0.1757\n",
      "Epoch 319/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2366 - accuracy: 0.1757\n",
      "Epoch 320/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2363 - accuracy: 0.1766\n",
      "Epoch 321/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2360 - accuracy: 0.1766\n",
      "Epoch 322/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2356 - accuracy: 0.1768\n",
      "Epoch 323/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2353 - accuracy: 0.1765\n",
      "Epoch 324/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2350 - accuracy: 0.1772\n",
      "Epoch 325/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2346 - accuracy: 0.1770\n",
      "Epoch 326/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2343 - accuracy: 0.1773\n",
      "Epoch 327/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2340 - accuracy: 0.1780\n",
      "Epoch 328/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2336 - accuracy: 0.1774\n",
      "Epoch 329/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2333 - accuracy: 0.1788\n",
      "Epoch 330/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2330 - accuracy: 0.1782\n",
      "Epoch 331/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2326 - accuracy: 0.1790\n",
      "Epoch 332/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2323 - accuracy: 0.1789\n",
      "Epoch 333/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2320 - accuracy: 0.1795\n",
      "Epoch 334/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2316 - accuracy: 0.1798\n",
      "Epoch 335/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2313 - accuracy: 0.1797\n",
      "Epoch 336/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2310 - accuracy: 0.1799\n",
      "Epoch 337/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2306 - accuracy: 0.1798\n",
      "Epoch 338/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2303 - accuracy: 0.1801\n",
      "Epoch 339/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2300 - accuracy: 0.1807\n",
      "Epoch 340/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2296 - accuracy: 0.1810\n",
      "Epoch 341/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2293 - accuracy: 0.1811\n",
      "Epoch 342/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2290 - accuracy: 0.1812\n",
      "Epoch 343/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2286 - accuracy: 0.1820\n",
      "Epoch 344/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2283 - accuracy: 0.1823\n",
      "Epoch 345/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2279 - accuracy: 0.1821\n",
      "Epoch 346/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2276 - accuracy: 0.1827\n",
      "Epoch 347/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2273 - accuracy: 0.1829\n",
      "Epoch 348/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2269 - accuracy: 0.1837\n",
      "Epoch 349/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2266 - accuracy: 0.1832\n",
      "Epoch 350/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2263 - accuracy: 0.1835\n",
      "Epoch 351/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2259 - accuracy: 0.1840\n",
      "Epoch 352/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2256 - accuracy: 0.1840\n",
      "Epoch 353/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2252 - accuracy: 0.1849\n",
      "Epoch 354/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2249 - accuracy: 0.1852\n",
      "Epoch 355/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2246 - accuracy: 0.1855\n",
      "Epoch 356/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2242 - accuracy: 0.1855\n",
      "Epoch 357/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2239 - accuracy: 0.1860\n",
      "Epoch 358/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2235 - accuracy: 0.1852\n",
      "Epoch 359/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2232 - accuracy: 0.1864\n",
      "Epoch 360/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2229 - accuracy: 0.1866\n",
      "Epoch 361/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2225 - accuracy: 0.1874\n",
      "Epoch 362/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2222 - accuracy: 0.1870\n",
      "Epoch 363/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2218 - accuracy: 0.1871\n",
      "Epoch 364/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2215 - accuracy: 0.1886\n",
      "Epoch 365/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2211 - accuracy: 0.1880\n",
      "Epoch 366/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2208 - accuracy: 0.1880\n",
      "Epoch 367/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2205 - accuracy: 0.1882\n",
      "Epoch 368/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2201 - accuracy: 0.1883\n",
      "Epoch 369/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2198 - accuracy: 0.1889\n",
      "Epoch 370/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2194 - accuracy: 0.1890\n",
      "Epoch 371/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2191 - accuracy: 0.1889\n",
      "Epoch 372/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2188 - accuracy: 0.1900\n",
      "Epoch 373/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2184 - accuracy: 0.1896\n",
      "Epoch 374/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2181 - accuracy: 0.1907\n",
      "Epoch 375/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2177 - accuracy: 0.1902\n",
      "Epoch 376/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2174 - accuracy: 0.1917\n",
      "Epoch 377/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2170 - accuracy: 0.1910\n",
      "Epoch 378/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2167 - accuracy: 0.1915\n",
      "Epoch 379/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2163 - accuracy: 0.1918\n",
      "Epoch 380/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2160 - accuracy: 0.1921\n",
      "Epoch 381/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2156 - accuracy: 0.1926\n",
      "Epoch 382/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2153 - accuracy: 0.1926\n",
      "Epoch 383/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2149 - accuracy: 0.1924\n",
      "Epoch 384/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2146 - accuracy: 0.1934\n",
      "Epoch 385/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2142 - accuracy: 0.1932\n",
      "Epoch 386/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2139 - accuracy: 0.1938\n",
      "Epoch 387/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2136 - accuracy: 0.1938\n",
      "Epoch 388/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2132 - accuracy: 0.1948\n",
      "Epoch 389/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2128 - accuracy: 0.1945\n",
      "Epoch 390/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2125 - accuracy: 0.1950\n",
      "Epoch 391/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2122 - accuracy: 0.1946\n",
      "Epoch 392/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2118 - accuracy: 0.1957\n",
      "Epoch 393/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2115 - accuracy: 0.1959\n",
      "Epoch 394/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2111 - accuracy: 0.1958\n",
      "Epoch 395/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2108 - accuracy: 0.1964\n",
      "Epoch 396/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2104 - accuracy: 0.1967\n",
      "Epoch 397/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2101 - accuracy: 0.1973\n",
      "Epoch 398/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2097 - accuracy: 0.1974\n",
      "Epoch 399/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2094 - accuracy: 0.1982\n",
      "Epoch 400/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2090 - accuracy: 0.1972\n",
      "Epoch 401/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2087 - accuracy: 0.1980\n",
      "Epoch 402/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2083 - accuracy: 0.1988\n",
      "Epoch 403/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2079 - accuracy: 0.1992\n",
      "Epoch 404/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2076 - accuracy: 0.1992\n",
      "Epoch 405/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2073 - accuracy: 0.1995\n",
      "Epoch 406/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2069 - accuracy: 0.1995\n",
      "Epoch 407/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2065 - accuracy: 0.2003\n",
      "Epoch 408/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2062 - accuracy: 0.1994\n",
      "Epoch 409/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2059 - accuracy: 0.2006\n",
      "Epoch 410/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2055 - accuracy: 0.2000\n",
      "Epoch 411/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2052 - accuracy: 0.2004\n",
      "Epoch 412/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2048 - accuracy: 0.2017\n",
      "Epoch 413/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2045 - accuracy: 0.2015\n",
      "Epoch 414/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2041 - accuracy: 0.2015\n",
      "Epoch 415/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2037 - accuracy: 0.2018\n",
      "Epoch 416/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2034 - accuracy: 0.2011\n",
      "Epoch 417/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2030 - accuracy: 0.2027\n",
      "Epoch 418/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2027 - accuracy: 0.2026\n",
      "Epoch 419/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2023 - accuracy: 0.2028\n",
      "Epoch 420/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2019 - accuracy: 0.2037\n",
      "Epoch 421/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2016 - accuracy: 0.2041\n",
      "Epoch 422/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2012 - accuracy: 0.2036\n",
      "Epoch 423/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2009 - accuracy: 0.2039\n",
      "Epoch 424/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2005 - accuracy: 0.2049\n",
      "Epoch 425/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2002 - accuracy: 0.2046\n",
      "Epoch 426/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1998 - accuracy: 0.2051\n",
      "Epoch 427/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1994 - accuracy: 0.2047\n",
      "Epoch 428/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1991 - accuracy: 0.2051\n",
      "Epoch 429/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1987 - accuracy: 0.2056\n",
      "Epoch 430/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1983 - accuracy: 0.2057\n",
      "Epoch 431/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1980 - accuracy: 0.2063\n",
      "Epoch 432/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1976 - accuracy: 0.2067\n",
      "Epoch 433/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1973 - accuracy: 0.2070\n",
      "Epoch 434/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1969 - accuracy: 0.2068\n",
      "Epoch 435/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1965 - accuracy: 0.2074\n",
      "Epoch 436/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1962 - accuracy: 0.2076\n",
      "Epoch 437/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1958 - accuracy: 0.2075\n",
      "Epoch 438/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1954 - accuracy: 0.2079\n",
      "Epoch 439/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1951 - accuracy: 0.2088\n",
      "Epoch 440/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1947 - accuracy: 0.2088\n",
      "Epoch 441/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1944 - accuracy: 0.2090\n",
      "Epoch 442/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1940 - accuracy: 0.2087\n",
      "Epoch 443/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1936 - accuracy: 0.2093\n",
      "Epoch 444/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1933 - accuracy: 0.2094\n",
      "Epoch 445/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1929 - accuracy: 0.2107\n",
      "Epoch 446/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1925 - accuracy: 0.2099\n",
      "Epoch 447/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1922 - accuracy: 0.2098\n",
      "Epoch 448/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1918 - accuracy: 0.2110\n",
      "Epoch 449/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1914 - accuracy: 0.2112\n",
      "Epoch 450/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1911 - accuracy: 0.2120\n",
      "Epoch 451/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1907 - accuracy: 0.2108\n",
      "Epoch 452/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1903 - accuracy: 0.2120\n",
      "Epoch 453/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1900 - accuracy: 0.2123\n",
      "Epoch 454/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1896 - accuracy: 0.2122\n",
      "Epoch 455/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1892 - accuracy: 0.2127\n",
      "Epoch 456/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1888 - accuracy: 0.2128\n",
      "Epoch 457/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1885 - accuracy: 0.2132\n",
      "Epoch 458/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1881 - accuracy: 0.2136\n",
      "Epoch 459/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1877 - accuracy: 0.2143\n",
      "Epoch 460/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1874 - accuracy: 0.2143\n",
      "Epoch 461/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1870 - accuracy: 0.2139\n",
      "Epoch 462/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1866 - accuracy: 0.2151\n",
      "Epoch 463/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1862 - accuracy: 0.2152\n",
      "Epoch 464/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1859 - accuracy: 0.2148\n",
      "Epoch 465/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1855 - accuracy: 0.2150\n",
      "Epoch 466/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1852 - accuracy: 0.2165\n",
      "Epoch 467/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1847 - accuracy: 0.2159\n",
      "Epoch 468/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1844 - accuracy: 0.2159\n",
      "Epoch 469/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1840 - accuracy: 0.2162\n",
      "Epoch 470/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1836 - accuracy: 0.2166\n",
      "Epoch 471/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1833 - accuracy: 0.2165\n",
      "Epoch 472/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1829 - accuracy: 0.2175\n",
      "Epoch 473/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1825 - accuracy: 0.2181\n",
      "Epoch 474/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1821 - accuracy: 0.2178\n",
      "Epoch 475/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1818 - accuracy: 0.2182\n",
      "Epoch 476/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1814 - accuracy: 0.2189\n",
      "Epoch 477/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1810 - accuracy: 0.2186\n",
      "Epoch 478/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1806 - accuracy: 0.2193\n",
      "Epoch 479/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1802 - accuracy: 0.2197\n",
      "Epoch 480/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1798 - accuracy: 0.2198\n",
      "Epoch 481/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1795 - accuracy: 0.2199\n",
      "Epoch 482/500\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1791 - accuracy: 0.2200\n",
      "Epoch 483/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1787 - accuracy: 0.2202\n",
      "Epoch 484/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1783 - accuracy: 0.2206\n",
      "Epoch 485/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1779 - accuracy: 0.2218\n",
      "Epoch 486/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1776 - accuracy: 0.2212\n",
      "Epoch 487/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1771 - accuracy: 0.2221\n",
      "Epoch 488/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1767 - accuracy: 0.2219\n",
      "Epoch 489/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1763 - accuracy: 0.2225\n",
      "Epoch 490/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.1760 - accuracy: 0.2222\n",
      "Epoch 491/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1756 - accuracy: 0.2228\n",
      "Epoch 492/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1752 - accuracy: 0.2231\n",
      "Epoch 493/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1748 - accuracy: 0.2242\n",
      "Epoch 494/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1744 - accuracy: 0.2237\n",
      "Epoch 495/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.1740 - accuracy: 0.2245\n",
      "Epoch 496/500\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.1736 - accuracy: 0.2243\n",
      "Epoch 497/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1732 - accuracy: 0.2246\n",
      "Epoch 498/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1728 - accuracy: 0.2255\n",
      "Epoch 499/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1724 - accuracy: 0.2256\n",
      "Epoch 500/500\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1720 - accuracy: 0.2255\n"
     ]
    }
   ],
   "source": [
    "model_wt.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_wt = model_wt.fit(X_train, y_train, batch_size = 1000, epochs = 500, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oRip6y8XjOAo",
    "outputId": "bcdc8cb6-fe23-44d3-d3ec-b5144408d09d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 90us/step\n",
      "Validation accuracy:  0.156616672873497\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_wt = model_wt.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_wt[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. In the above cells a Sequential model was created with six hidden layers consisting of above mentioned hidden Neurons.\n",
    "2. The created model was configured with loss and metrices.\n",
    "3. The configured m0del was also trained whose accuracy on training data is around 23%\n",
    "4. The accuracy is very low upon evaluating the same model on Validation Data the performance improves it comes just 16%.\n",
    "5. Therefore, we can use this model and do some improvemnts on this and try to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymoco6aCxL2H"
   },
   "source": [
    "    Further trials are done by adding the BatchNormalization layer and initiating the 'He-normal' weight initialization to the  models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model - 3: Building Models with BatchNormalization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YcEO7ajbdLPL"
   },
   "source": [
    "##### Model - 3 :Batch Normalization (Trial - 1):\n",
    "    Here a Sequential Neural Network model is built by adding the BatchNormalization Layer with scaling and shifting parameters turned on, this model is given a selu activation with 'He-normal' weight iniitialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLz85VT9f1Gd"
   },
   "outputs": [],
   "source": [
    "model_bn = Sequential()\n",
    "\n",
    "model_bn.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True))\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(10, name ='Output_Layer'))\n",
    "model_bn.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "llnwemWarriw",
    "outputId": "ae2477fb-2c8b-43b9-905f-265bf5fa34c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 2.9761 - accuracy: 0.1044\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.9445 - accuracy: 0.1045\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.9148 - accuracy: 0.1049\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8887 - accuracy: 0.1048\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8642 - accuracy: 0.1052\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.8422 - accuracy: 0.1060\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8225 - accuracy: 0.1065\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.8030 - accuracy: 0.1061\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7868 - accuracy: 0.1065\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7710 - accuracy: 0.1070\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7569 - accuracy: 0.1076\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7439 - accuracy: 0.1079\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7310 - accuracy: 0.1079\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7200 - accuracy: 0.1088\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7093 - accuracy: 0.1089\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6986 - accuracy: 0.1094\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6880 - accuracy: 0.1101\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6785 - accuracy: 0.1116\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6701 - accuracy: 0.1111\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6616 - accuracy: 0.1107\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6529 - accuracy: 0.1116\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6451 - accuracy: 0.1121\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6379 - accuracy: 0.1121\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6309 - accuracy: 0.1130\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6228 - accuracy: 0.1126\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6168 - accuracy: 0.1138\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6099 - accuracy: 0.1147\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6026 - accuracy: 0.1149\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5967 - accuracy: 0.1147\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.5909 - accuracy: 0.1154\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5851 - accuracy: 0.1155\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.5794 - accuracy: 0.1152\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5739 - accuracy: 0.1165\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.5687 - accuracy: 0.1160\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5634 - accuracy: 0.1168\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5579 - accuracy: 0.1181\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5534 - accuracy: 0.1189\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5490 - accuracy: 0.1186\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5443 - accuracy: 0.1194\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5399 - accuracy: 0.1189\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5353 - accuracy: 0.1196\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5308 - accuracy: 0.1210\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5267 - accuracy: 0.1213\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5232 - accuracy: 0.1228\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5188 - accuracy: 0.1217\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.5147 - accuracy: 0.1224\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.5107 - accuracy: 0.1232\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.5073 - accuracy: 0.1227\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.5034 - accuracy: 0.1238\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.5008 - accuracy: 0.1234\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4968 - accuracy: 0.1247\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4933 - accuracy: 0.1252\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4899 - accuracy: 0.1249\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4868 - accuracy: 0.1264\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4838 - accuracy: 0.1267\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4805 - accuracy: 0.1273\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4769 - accuracy: 0.1270\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4747 - accuracy: 0.1278\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4721 - accuracy: 0.1279\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4684 - accuracy: 0.1286\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4660 - accuracy: 0.1283\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4626 - accuracy: 0.1290\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4607 - accuracy: 0.1314\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4573 - accuracy: 0.1300\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4545 - accuracy: 0.1306\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4523 - accuracy: 0.1313\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4499 - accuracy: 0.1309\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4471 - accuracy: 0.1320\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4447 - accuracy: 0.1323\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4423 - accuracy: 0.1335\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4405 - accuracy: 0.1320\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4378 - accuracy: 0.1343\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4356 - accuracy: 0.1339\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4340 - accuracy: 0.1346\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4312 - accuracy: 0.1345\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4284 - accuracy: 0.1369\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.4259 - accuracy: 0.1370\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4241 - accuracy: 0.1369\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4221 - accuracy: 0.1370\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4202 - accuracy: 0.1367\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4180 - accuracy: 0.1383\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4156 - accuracy: 0.1381\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4138 - accuracy: 0.1381\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4117 - accuracy: 0.1389\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4101 - accuracy: 0.1392\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4083 - accuracy: 0.1400\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4060 - accuracy: 0.1406\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4043 - accuracy: 0.1407\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4028 - accuracy: 0.1410\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4006 - accuracy: 0.1411\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3986 - accuracy: 0.1412\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3975 - accuracy: 0.1415\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3952 - accuracy: 0.1416\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3930 - accuracy: 0.1430\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3917 - accuracy: 0.1433\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3903 - accuracy: 0.1437\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3883 - accuracy: 0.1443\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3873 - accuracy: 0.1445\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3853 - accuracy: 0.1444\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3837 - accuracy: 0.1448\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3817 - accuracy: 0.1448\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3800 - accuracy: 0.1462\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3785 - accuracy: 0.1470\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3771 - accuracy: 0.1475\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3755 - accuracy: 0.1475\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3739 - accuracy: 0.1480\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3721 - accuracy: 0.1485\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3705 - accuracy: 0.1485\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3694 - accuracy: 0.1483\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3676 - accuracy: 0.1491\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3666 - accuracy: 0.1498\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3651 - accuracy: 0.1495\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3637 - accuracy: 0.1503\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3623 - accuracy: 0.1514\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3608 - accuracy: 0.1507\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3597 - accuracy: 0.1527\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3585 - accuracy: 0.1518\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3569 - accuracy: 0.1517\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3554 - accuracy: 0.1523\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3542 - accuracy: 0.1531\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3526 - accuracy: 0.1525\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3512 - accuracy: 0.1540\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3497 - accuracy: 0.1543\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3484 - accuracy: 0.1542\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3477 - accuracy: 0.1549\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3464 - accuracy: 0.1551\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3447 - accuracy: 0.1562\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3431 - accuracy: 0.1563\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3424 - accuracy: 0.1569\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3414 - accuracy: 0.1573\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3398 - accuracy: 0.1581\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3387 - accuracy: 0.1584\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3375 - accuracy: 0.1585\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3363 - accuracy: 0.1579\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3350 - accuracy: 0.1597\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3342 - accuracy: 0.1603\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3330 - accuracy: 0.1593\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3311 - accuracy: 0.1600\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3301 - accuracy: 0.1601\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3291 - accuracy: 0.1603\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3283 - accuracy: 0.1610\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3274 - accuracy: 0.1620\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3257 - accuracy: 0.1618\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3250 - accuracy: 0.1622\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3241 - accuracy: 0.1623\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3225 - accuracy: 0.1634\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3208 - accuracy: 0.1625\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3206 - accuracy: 0.1636\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3192 - accuracy: 0.1632\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3187 - accuracy: 0.1637\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3170 - accuracy: 0.1640\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3162 - accuracy: 0.1649\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3149 - accuracy: 0.1648\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3140 - accuracy: 0.1649\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3134 - accuracy: 0.1652\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3122 - accuracy: 0.1662\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3110 - accuracy: 0.1671\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3102 - accuracy: 0.1672\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3084 - accuracy: 0.1682\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3081 - accuracy: 0.1676\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3070 - accuracy: 0.1678\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3058 - accuracy: 0.1680\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3051 - accuracy: 0.1684\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3044 - accuracy: 0.1696\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3028 - accuracy: 0.1703\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3021 - accuracy: 0.1698\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3010 - accuracy: 0.1696\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3002 - accuracy: 0.1720\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2991 - accuracy: 0.1702\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2988 - accuracy: 0.1718\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2978 - accuracy: 0.1708\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2962 - accuracy: 0.1711\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2956 - accuracy: 0.1724\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2948 - accuracy: 0.1726\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2934 - accuracy: 0.1737\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2929 - accuracy: 0.1718\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2920 - accuracy: 0.1744\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2914 - accuracy: 0.1740\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2901 - accuracy: 0.1742\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2889 - accuracy: 0.1747\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2888 - accuracy: 0.1749\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2871 - accuracy: 0.1745\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2863 - accuracy: 0.1758\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2850 - accuracy: 0.1758\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2847 - accuracy: 0.1761\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2835 - accuracy: 0.1778\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2827 - accuracy: 0.1767\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2822 - accuracy: 0.1771\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2808 - accuracy: 0.1776\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2799 - accuracy: 0.1778\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2793 - accuracy: 0.1786\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2782 - accuracy: 0.1788\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2772 - accuracy: 0.1783\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2764 - accuracy: 0.1790\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2761 - accuracy: 0.1790\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2748 - accuracy: 0.1803\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2738 - accuracy: 0.1801\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2731 - accuracy: 0.1803\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2727 - accuracy: 0.1802\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.2717 - accuracy: 0.1802\n"
     ]
    }
   ],
   "source": [
    "model_bn.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_bn = model_bn.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eb9-yoCAf1G5",
    "outputId": "e55c80d4-ccea-4f28-d89a-d57e81e227a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 98us/step\n",
      "Validation accuracy:  0.18226666748523712\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bt = model_bn.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bt[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us also try optimizing the model with Adam optimizer then configure the model with loss function and metrices, train the modela and evaluate the model performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CSl2h0OMrbXb",
    "outputId": "0097430e-abcd-4784-fd4b-c57f941e862c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 32us/step - loss: 2.7266 - accuracy: 0.1179\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4433 - accuracy: 0.1487\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3083 - accuracy: 0.1844\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2185 - accuracy: 0.2171\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1429 - accuracy: 0.2494\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.0756 - accuracy: 0.2758\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.0119 - accuracy: 0.3035\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9534 - accuracy: 0.3284\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9015 - accuracy: 0.3541\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8554 - accuracy: 0.3774\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8124 - accuracy: 0.3975\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7734 - accuracy: 0.4163\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7359 - accuracy: 0.4330\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.7012 - accuracy: 0.4502\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6688 - accuracy: 0.4642\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.6381 - accuracy: 0.4786\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6074 - accuracy: 0.4921\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5791 - accuracy: 0.5042\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5524 - accuracy: 0.5164\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5286 - accuracy: 0.5254\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5037 - accuracy: 0.5390\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4805 - accuracy: 0.5458\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4579 - accuracy: 0.5558\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4369 - accuracy: 0.5656\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4165 - accuracy: 0.5727\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3975 - accuracy: 0.5790\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3770 - accuracy: 0.5874\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3590 - accuracy: 0.5954\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.3447 - accuracy: 0.6016\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3254 - accuracy: 0.6096\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3097 - accuracy: 0.6156\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2936 - accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2790 - accuracy: 0.6276\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2643 - accuracy: 0.6305\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2515 - accuracy: 0.6361\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2362 - accuracy: 0.6422\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2231 - accuracy: 0.6461\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2110 - accuracy: 0.6512\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.1970 - accuracy: 0.6550\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1853 - accuracy: 0.6587\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1731 - accuracy: 0.6638\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1631 - accuracy: 0.6671\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1506 - accuracy: 0.6720\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1391 - accuracy: 0.6747\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1295 - accuracy: 0.6794\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1181 - accuracy: 0.6824\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.1090 - accuracy: 0.6857\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1002 - accuracy: 0.6880\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0893 - accuracy: 0.6924\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0808 - accuracy: 0.6949\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0711 - accuracy: 0.6988\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0620 - accuracy: 0.7002\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0536 - accuracy: 0.7025\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0444 - accuracy: 0.7060\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0362 - accuracy: 0.7098\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.0282 - accuracy: 0.7114\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0210 - accuracy: 0.7138\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0122 - accuracy: 0.7171\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.0045 - accuracy: 0.7182\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.9959 - accuracy: 0.7213\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9892 - accuracy: 0.7235\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.9815 - accuracy: 0.7267\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.9765 - accuracy: 0.7278\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.9689 - accuracy: 0.7303\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9628 - accuracy: 0.7315\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9542 - accuracy: 0.7348\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9456 - accuracy: 0.7362\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9409 - accuracy: 0.7376\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9333 - accuracy: 0.7409\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9271 - accuracy: 0.7428\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9199 - accuracy: 0.7471\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9157 - accuracy: 0.7454\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9085 - accuracy: 0.7485\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9023 - accuracy: 0.7514\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8964 - accuracy: 0.7548\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8906 - accuracy: 0.7539\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.8861 - accuracy: 0.7568\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8811 - accuracy: 0.7567\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8738 - accuracy: 0.7600\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8683 - accuracy: 0.7614\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8624 - accuracy: 0.7625\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8557 - accuracy: 0.7649\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8510 - accuracy: 0.7680\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8470 - accuracy: 0.7665\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8407 - accuracy: 0.7695\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8358 - accuracy: 0.7721\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8325 - accuracy: 0.7719\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8268 - accuracy: 0.7743\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8195 - accuracy: 0.7767\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.8156 - accuracy: 0.7767\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8109 - accuracy: 0.7786\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8079 - accuracy: 0.7799\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8012 - accuracy: 0.7817\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7962 - accuracy: 0.7832\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7913 - accuracy: 0.7855\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7877 - accuracy: 0.7855\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7814 - accuracy: 0.7893\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7774 - accuracy: 0.7907\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7748 - accuracy: 0.7917\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7704 - accuracy: 0.7913\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7663 - accuracy: 0.7912\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7600 - accuracy: 0.7940\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7563 - accuracy: 0.7957\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7517 - accuracy: 0.7980\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7476 - accuracy: 0.7990\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7422 - accuracy: 0.8003\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7394 - accuracy: 0.8009\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7347 - accuracy: 0.8025\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7319 - accuracy: 0.8027\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7285 - accuracy: 0.8043\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7224 - accuracy: 0.8059\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7188 - accuracy: 0.8063\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7154 - accuracy: 0.8081\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7104 - accuracy: 0.8123\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7085 - accuracy: 0.8106\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7048 - accuracy: 0.8118\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7004 - accuracy: 0.8121\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6969 - accuracy: 0.8139\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6927 - accuracy: 0.8153\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6887 - accuracy: 0.8166\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6864 - accuracy: 0.8169\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6820 - accuracy: 0.8180\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6779 - accuracy: 0.8195\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6744 - accuracy: 0.8206\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6712 - accuracy: 0.8202\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6673 - accuracy: 0.8233\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.6639 - accuracy: 0.8240\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6599 - accuracy: 0.8243\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6585 - accuracy: 0.8253\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6550 - accuracy: 0.8265\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6531 - accuracy: 0.8260\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6473 - accuracy: 0.8280\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6439 - accuracy: 0.8306\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6399 - accuracy: 0.8309\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6362 - accuracy: 0.8329\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6353 - accuracy: 0.8309\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6303 - accuracy: 0.8339\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6265 - accuracy: 0.8363\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6251 - accuracy: 0.8353\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6200 - accuracy: 0.8375\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6183 - accuracy: 0.8370\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6146 - accuracy: 0.8377\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6111 - accuracy: 0.8400\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6098 - accuracy: 0.8402\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6061 - accuracy: 0.8415\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6039 - accuracy: 0.8401\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6001 - accuracy: 0.8426\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5984 - accuracy: 0.8447\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5941 - accuracy: 0.8448\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5915 - accuracy: 0.8448\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.5893 - accuracy: 0.8450\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5846 - accuracy: 0.8475\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5831 - accuracy: 0.8475\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5800 - accuracy: 0.8486\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5782 - accuracy: 0.8494\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5744 - accuracy: 0.8505\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5711 - accuracy: 0.8520\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5689 - accuracy: 0.8520\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5659 - accuracy: 0.8535\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5624 - accuracy: 0.8550\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.5601 - accuracy: 0.8540\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5584 - accuracy: 0.8549\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5540 - accuracy: 0.8560\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5527 - accuracy: 0.8571\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5510 - accuracy: 0.8559\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5485 - accuracy: 0.8573\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5459 - accuracy: 0.8584\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5440 - accuracy: 0.8586\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5401 - accuracy: 0.8602\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5371 - accuracy: 0.8618\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5348 - accuracy: 0.8626\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5314 - accuracy: 0.8636\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5282 - accuracy: 0.8637\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5277 - accuracy: 0.8630\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5251 - accuracy: 0.8658\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5214 - accuracy: 0.8659\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5189 - accuracy: 0.8669\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5169 - accuracy: 0.8676\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5133 - accuracy: 0.8694\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5095 - accuracy: 0.8710\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5093 - accuracy: 0.8704\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5066 - accuracy: 0.8714\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5062 - accuracy: 0.8697\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5032 - accuracy: 0.8723\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.4993 - accuracy: 0.8733\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4987 - accuracy: 0.8736\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4980 - accuracy: 0.8727\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4941 - accuracy: 0.8754\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4922 - accuracy: 0.8762\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4907 - accuracy: 0.8744\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4853 - accuracy: 0.8780\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4851 - accuracy: 0.8766\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4803 - accuracy: 0.8796\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4803 - accuracy: 0.8787\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4789 - accuracy: 0.8804\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4758 - accuracy: 0.8802\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4724 - accuracy: 0.8814\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4695 - accuracy: 0.8831\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4697 - accuracy: 0.8814\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4667 - accuracy: 0.8823\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.00001)\n",
    "model_bn.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history_bn_adam = model_bn.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ls0-AAJx-M7Z",
    "outputId": "987829a6-019d-4a73-99e5-069ad215e31f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 93us/step\n",
      "Validation accuracy:  0.8321166634559631\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bt_ad = model_bn.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bt_ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. Above the Neural Network model was created as said initially.\n",
    "2. The performance of the model when using SGD optimizer was very low on training data but on validation data it was little better still the performance is just 18%.\n",
    "2. The performance of the model when using Adam optimizer was high on training data but on validation data it was around 83% only this may be due to overfitting of the model during training so some regularization need to be done further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bt5_VdmPeJd2"
   },
   "source": [
    "##### Model - 3 : (Trial - 2):\n",
    "        Here a Sequential Neural Network model is built by adding the BatchNormalization Layer without scaling and shifting parameters turned on, this model is given a selu activation with 'He-normal' weight iniitialization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JC9e2UYEeJd5"
   },
   "outputs": [],
   "source": [
    "model_bn = Sequential()\n",
    "\n",
    "model_bn.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "model_bn.add(BatchNormalization()) #Adding a Batch Normalization Layer.\n",
    "model_bn.add(Activation('selu')) #Adding a Selu acrivation Layer.\n",
    "\n",
    "model_bn.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "model_bn.add(BatchNormalization( ))\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "model_bn.add(BatchNormalization( ))\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "model_bn.add(BatchNormalization( ))\n",
    "model_bn.add(Activation('selu'))\n",
    "\n",
    "model_bn.add(Dense(10, name ='Output_Layer'))\n",
    "model_bn.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "D469VtS0eJeH",
    "outputId": "d7f10c92-ced6-4a8e-fd05-f36eb30316db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 2.9477 - accuracy: 0.0981\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.9259 - accuracy: 0.0988\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.9053 - accuracy: 0.0987\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.8858 - accuracy: 0.0995\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8679 - accuracy: 0.1003\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8503 - accuracy: 0.1013\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.8347 - accuracy: 0.1005\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.8195 - accuracy: 0.1023\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8055 - accuracy: 0.1027\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7922 - accuracy: 0.1037\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7806 - accuracy: 0.1043\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7675 - accuracy: 0.1055\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7579 - accuracy: 0.1067\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7468 - accuracy: 0.1074\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7378 - accuracy: 0.1075\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7289 - accuracy: 0.1070\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7206 - accuracy: 0.1081\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7128 - accuracy: 0.1085\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7050 - accuracy: 0.1090\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6978 - accuracy: 0.1090\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6904 - accuracy: 0.1097\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6828 - accuracy: 0.1102\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6760 - accuracy: 0.1113\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6704 - accuracy: 0.1102\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6630 - accuracy: 0.1118\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6578 - accuracy: 0.1125\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6522 - accuracy: 0.1128\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6456 - accuracy: 0.1118\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6409 - accuracy: 0.1130\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6352 - accuracy: 0.1137\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6292 - accuracy: 0.1146\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6238 - accuracy: 0.1143\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6190 - accuracy: 0.1139\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6145 - accuracy: 0.1144\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6094 - accuracy: 0.1157\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6049 - accuracy: 0.1149\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6000 - accuracy: 0.1146\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5949 - accuracy: 0.1169\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5909 - accuracy: 0.1160\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5862 - accuracy: 0.1171\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5826 - accuracy: 0.1174\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5783 - accuracy: 0.1181\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5745 - accuracy: 0.1170\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5702 - accuracy: 0.1178\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.5657 - accuracy: 0.1190\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5624 - accuracy: 0.1187\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5584 - accuracy: 0.1190\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5552 - accuracy: 0.1191\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5508 - accuracy: 0.1189\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5478 - accuracy: 0.1203\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5449 - accuracy: 0.1195\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5404 - accuracy: 0.1206\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5371 - accuracy: 0.1207\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5340 - accuracy: 0.1205\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5314 - accuracy: 0.1211\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5282 - accuracy: 0.1214\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5240 - accuracy: 0.1226\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5212 - accuracy: 0.1212\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5181 - accuracy: 0.1219\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5147 - accuracy: 0.1229\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5119 - accuracy: 0.1224\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5091 - accuracy: 0.1215\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5058 - accuracy: 0.1231\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.5027 - accuracy: 0.1239\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5005 - accuracy: 0.1248\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4978 - accuracy: 0.1247\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4947 - accuracy: 0.1249\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4923 - accuracy: 0.1258\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4896 - accuracy: 0.1247\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4870 - accuracy: 0.1255\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4850 - accuracy: 0.1257\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4822 - accuracy: 0.1258\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4795 - accuracy: 0.1260\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4774 - accuracy: 0.1265\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4749 - accuracy: 0.1253\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4716 - accuracy: 0.1271\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4694 - accuracy: 0.1276\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4673 - accuracy: 0.1269\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4652 - accuracy: 0.1275\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4628 - accuracy: 0.1281\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4609 - accuracy: 0.1282\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4585 - accuracy: 0.1288\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4558 - accuracy: 0.1288\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4542 - accuracy: 0.1289\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4524 - accuracy: 0.1299\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4492 - accuracy: 0.1293\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4478 - accuracy: 0.1302\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4457 - accuracy: 0.1311\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4436 - accuracy: 0.1305\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4416 - accuracy: 0.1304\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4394 - accuracy: 0.1312\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4377 - accuracy: 0.1321\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4355 - accuracy: 0.1311\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4340 - accuracy: 0.1317\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4315 - accuracy: 0.1320\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4299 - accuracy: 0.1328\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4281 - accuracy: 0.1336\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4263 - accuracy: 0.1333\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4244 - accuracy: 0.1333\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4228 - accuracy: 0.1333\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4211 - accuracy: 0.1331\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4196 - accuracy: 0.1333\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4173 - accuracy: 0.1345\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4161 - accuracy: 0.1350\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4141 - accuracy: 0.1349\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4126 - accuracy: 0.1349\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4103 - accuracy: 0.1350\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4091 - accuracy: 0.1357\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4074 - accuracy: 0.1369\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4056 - accuracy: 0.1368\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4043 - accuracy: 0.1380\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4027 - accuracy: 0.1371\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.4013 - accuracy: 0.1377\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3998 - accuracy: 0.1386\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3982 - accuracy: 0.1388\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3967 - accuracy: 0.1394\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3957 - accuracy: 0.1387\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3934 - accuracy: 0.1380\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3921 - accuracy: 0.1395\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3910 - accuracy: 0.1397\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3892 - accuracy: 0.1398\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3877 - accuracy: 0.1400\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3866 - accuracy: 0.1403\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3845 - accuracy: 0.1417\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3835 - accuracy: 0.1418\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3820 - accuracy: 0.1415\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3806 - accuracy: 0.1409\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3795 - accuracy: 0.1423\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3787 - accuracy: 0.1430\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3770 - accuracy: 0.1429\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3756 - accuracy: 0.1426\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3741 - accuracy: 0.1432\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3733 - accuracy: 0.1427\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3717 - accuracy: 0.1438\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3703 - accuracy: 0.1440\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3692 - accuracy: 0.1440\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3675 - accuracy: 0.1453\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.3666 - accuracy: 0.1445\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3650 - accuracy: 0.1448\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3640 - accuracy: 0.1460\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3626 - accuracy: 0.1460\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3612 - accuracy: 0.1456\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3604 - accuracy: 0.1460\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3592 - accuracy: 0.1459\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3575 - accuracy: 0.1466\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3571 - accuracy: 0.1473\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3560 - accuracy: 0.1456\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3541 - accuracy: 0.1467\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3534 - accuracy: 0.1470\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3520 - accuracy: 0.1482\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3514 - accuracy: 0.1474\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3500 - accuracy: 0.1485\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3490 - accuracy: 0.1489\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3477 - accuracy: 0.1494\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3468 - accuracy: 0.1482\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3454 - accuracy: 0.1494\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3442 - accuracy: 0.1507\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3432 - accuracy: 0.1495\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3425 - accuracy: 0.1505\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3412 - accuracy: 0.1513\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3400 - accuracy: 0.1510\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3393 - accuracy: 0.1519\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3380 - accuracy: 0.1515\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3373 - accuracy: 0.1527\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3359 - accuracy: 0.1519\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3349 - accuracy: 0.1516\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3343 - accuracy: 0.1519\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3336 - accuracy: 0.1530\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3323 - accuracy: 0.1528\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3308 - accuracy: 0.1534\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3303 - accuracy: 0.1536\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3292 - accuracy: 0.1546\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3282 - accuracy: 0.1540\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3270 - accuracy: 0.1555\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3264 - accuracy: 0.1551\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3253 - accuracy: 0.1559\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3239 - accuracy: 0.1560\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3234 - accuracy: 0.1559\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3223 - accuracy: 0.1567\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3214 - accuracy: 0.1559\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3207 - accuracy: 0.1574\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3202 - accuracy: 0.1574\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3189 - accuracy: 0.1577\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3179 - accuracy: 0.1577\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3168 - accuracy: 0.1581\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3164 - accuracy: 0.1587\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3154 - accuracy: 0.1585\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3147 - accuracy: 0.1587\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3135 - accuracy: 0.1591\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3126 - accuracy: 0.1595\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3118 - accuracy: 0.1597\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3116 - accuracy: 0.1602\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3097 - accuracy: 0.1603\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3096 - accuracy: 0.1611\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3080 - accuracy: 0.1599\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3074 - accuracy: 0.1607\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3066 - accuracy: 0.1611\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3057 - accuracy: 0.1619\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.3046 - accuracy: 0.1621\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3043 - accuracy: 0.1624\n"
     ]
    }
   ],
   "source": [
    "model_bn.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_bn = model_bn.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_QHjOooYeJeS",
    "outputId": "ce841226-c7fe-4e4a-8988-ef41b5a35350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 97us/step\n",
      "Validation accuracy:  0.16308332979679108\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bt = model_bn.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bt[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us also try optimizing the model with Adam optimizer then configure the model with loss function and metrices, train the modela and evaluate the model performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7fmnNkdOeJea",
    "outputId": "34ba93a5-32c0-4818-ec16-e973b17fedad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 35us/step - loss: 2.6605 - accuracy: 0.1035\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4106 - accuracy: 0.1315\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3064 - accuracy: 0.1639\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2280 - accuracy: 0.1983\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1587 - accuracy: 0.2320\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0925 - accuracy: 0.2662\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0249 - accuracy: 0.2975\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9600 - accuracy: 0.3289\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.8982 - accuracy: 0.3602\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.8419 - accuracy: 0.3855\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7877 - accuracy: 0.4122\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.7386 - accuracy: 0.4358\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6928 - accuracy: 0.4561\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6507 - accuracy: 0.4761\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.6123 - accuracy: 0.4941\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5775 - accuracy: 0.5101\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5439 - accuracy: 0.5261\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5129 - accuracy: 0.5378\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.4843 - accuracy: 0.5503\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4577 - accuracy: 0.5612\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4313 - accuracy: 0.5723\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4080 - accuracy: 0.5823\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3860 - accuracy: 0.5902\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3639 - accuracy: 0.5995\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3443 - accuracy: 0.6054\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3264 - accuracy: 0.6127\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3073 - accuracy: 0.6200\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2897 - accuracy: 0.6260\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2724 - accuracy: 0.6313\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.2575 - accuracy: 0.6380\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.2413 - accuracy: 0.6418\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2270 - accuracy: 0.6474\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.2129 - accuracy: 0.6522\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1992 - accuracy: 0.6566\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1860 - accuracy: 0.6617\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1738 - accuracy: 0.6664\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1614 - accuracy: 0.6700\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1491 - accuracy: 0.6738\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1371 - accuracy: 0.6774\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.1254 - accuracy: 0.6811\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1157 - accuracy: 0.6858\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1049 - accuracy: 0.6894\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0945 - accuracy: 0.6938\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0844 - accuracy: 0.6955\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0773 - accuracy: 0.6979\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0673 - accuracy: 0.7016\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0579 - accuracy: 0.7040\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0476 - accuracy: 0.7081\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0402 - accuracy: 0.7085\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0317 - accuracy: 0.7125\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0215 - accuracy: 0.7176\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0142 - accuracy: 0.7185\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.0062 - accuracy: 0.7208\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9973 - accuracy: 0.7249\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9897 - accuracy: 0.7272\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.9825 - accuracy: 0.7300\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9755 - accuracy: 0.7318\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9685 - accuracy: 0.7343\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9613 - accuracy: 0.7365\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9524 - accuracy: 0.7379\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.9471 - accuracy: 0.7405\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9422 - accuracy: 0.7404\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9324 - accuracy: 0.7468\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9271 - accuracy: 0.7471\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9207 - accuracy: 0.7501\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9146 - accuracy: 0.7518\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9083 - accuracy: 0.7534\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9013 - accuracy: 0.7555\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8950 - accuracy: 0.7579\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8895 - accuracy: 0.7585\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8840 - accuracy: 0.7613\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8796 - accuracy: 0.7623\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8721 - accuracy: 0.7638\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8666 - accuracy: 0.7664\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8607 - accuracy: 0.7688\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8559 - accuracy: 0.7692\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8513 - accuracy: 0.7708\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8452 - accuracy: 0.7730\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8393 - accuracy: 0.7738\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8342 - accuracy: 0.7756\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8283 - accuracy: 0.7765\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8239 - accuracy: 0.7794\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8193 - accuracy: 0.7817\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8143 - accuracy: 0.7818\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8089 - accuracy: 0.7825\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8047 - accuracy: 0.7862\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7990 - accuracy: 0.7861\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7941 - accuracy: 0.7887\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7911 - accuracy: 0.7867\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7853 - accuracy: 0.7917\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7817 - accuracy: 0.7921\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7765 - accuracy: 0.7940\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7727 - accuracy: 0.7945\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7674 - accuracy: 0.7959\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7635 - accuracy: 0.7980\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7602 - accuracy: 0.7982\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7547 - accuracy: 0.8003\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7490 - accuracy: 0.8013\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7448 - accuracy: 0.8032\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7412 - accuracy: 0.8034\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.7395 - accuracy: 0.8029\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7323 - accuracy: 0.8063\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7311 - accuracy: 0.8059\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7260 - accuracy: 0.8090\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7211 - accuracy: 0.8085\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7179 - accuracy: 0.8096\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7137 - accuracy: 0.8118\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7100 - accuracy: 0.8129\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7066 - accuracy: 0.8128\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7025 - accuracy: 0.8155\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6978 - accuracy: 0.8174\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6948 - accuracy: 0.8166\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6915 - accuracy: 0.8189\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6877 - accuracy: 0.8197\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6844 - accuracy: 0.8204\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6805 - accuracy: 0.8211\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6776 - accuracy: 0.8219\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6718 - accuracy: 0.8240\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6692 - accuracy: 0.8241\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6650 - accuracy: 0.8276\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6632 - accuracy: 0.8264\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6599 - accuracy: 0.8281\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6563 - accuracy: 0.8280\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6524 - accuracy: 0.8298\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6488 - accuracy: 0.8313\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6462 - accuracy: 0.8307\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6423 - accuracy: 0.8329\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6389 - accuracy: 0.8332\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6334 - accuracy: 0.8378\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6324 - accuracy: 0.8347\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6290 - accuracy: 0.8365\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6250 - accuracy: 0.8379\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6234 - accuracy: 0.8380\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6197 - accuracy: 0.8402\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6163 - accuracy: 0.8402\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6128 - accuracy: 0.8420\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6114 - accuracy: 0.8415\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6059 - accuracy: 0.8440\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6039 - accuracy: 0.8440\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6035 - accuracy: 0.8437\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5986 - accuracy: 0.8461\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5954 - accuracy: 0.8468\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5924 - accuracy: 0.8478\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5904 - accuracy: 0.8474\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5877 - accuracy: 0.8485\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5842 - accuracy: 0.8487\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.5808 - accuracy: 0.8515\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5792 - accuracy: 0.8518\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5759 - accuracy: 0.8535\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5717 - accuracy: 0.8547\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5695 - accuracy: 0.8552\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5680 - accuracy: 0.8543\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5642 - accuracy: 0.8548\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5612 - accuracy: 0.8573\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5585 - accuracy: 0.8583\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5551 - accuracy: 0.8581\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5534 - accuracy: 0.8590\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5522 - accuracy: 0.8590\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5500 - accuracy: 0.8601\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5457 - accuracy: 0.8617\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5444 - accuracy: 0.8606\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5400 - accuracy: 0.8625\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5383 - accuracy: 0.8626\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5356 - accuracy: 0.8622\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 17us/step - loss: 0.5322 - accuracy: 0.8643\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.5293 - accuracy: 0.8653\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5282 - accuracy: 0.8670\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5240 - accuracy: 0.8680\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.5229 - accuracy: 0.8671\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5226 - accuracy: 0.8667\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5166 - accuracy: 0.8698\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5152 - accuracy: 0.8702\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5137 - accuracy: 0.8695\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5126 - accuracy: 0.8716\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 17us/step - loss: 0.5065 - accuracy: 0.8727\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5039 - accuracy: 0.8743\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5017 - accuracy: 0.8739\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5029 - accuracy: 0.8738\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.4995 - accuracy: 0.8746\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4945 - accuracy: 0.8764\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4940 - accuracy: 0.8761\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4934 - accuracy: 0.8756\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4892 - accuracy: 0.8781\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4873 - accuracy: 0.8789\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4848 - accuracy: 0.8797\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4818 - accuracy: 0.8801\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4797 - accuracy: 0.8814\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4795 - accuracy: 0.8793\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4766 - accuracy: 0.8819\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4724 - accuracy: 0.8832\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4701 - accuracy: 0.8843\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4705 - accuracy: 0.8832\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4667 - accuracy: 0.8859\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4634 - accuracy: 0.8858\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4624 - accuracy: 0.8865\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4615 - accuracy: 0.8859\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4561 - accuracy: 0.8892\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4566 - accuracy: 0.8877\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4567 - accuracy: 0.8871\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4522 - accuracy: 0.8895\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.00001)\n",
    "model_bn.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history_bn_adam = model_bn.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RwDJLO17eJej",
    "outputId": "a639ccc7-48c4-4e29-e622-242d9d684f33",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 90us/step\n",
      "Validation accuracy:  0.8375833630561829\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bt_ad = model_bn.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bt_ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEtGviopxjCb"
   },
   "source": [
    "##### Inference on the above steps:\n",
    "1. Above the Neural Network model was created as said initially.\n",
    "2. The performance of the model when using SGD optimizer was very low on training data but on validation data it was little better still the performance is just 16%.\n",
    "2. The performance of the model when using Adam optimizer was high on training data but on validation data it was around 83.75% only this may be due to overfitting of the model during training so some regularization need to be done further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12KP1ahqehHa"
   },
   "source": [
    "##### Model - 3 : (Trial - 3):\n",
    "     Here a Sequential Neural Network model is built by adding the BatchNormalization Layer without scaling and shifting parameters turned on, this model is given a RELU activation with 'He-normal' weight iniitialization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3oXZKzvehHd"
   },
   "outputs": [],
   "source": [
    "model_bn = Sequential()\n",
    "\n",
    "model_bn.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "model_bn.add(BatchNormalization( ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "model_bn.add(BatchNormalization( ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "model_bn.add(BatchNormalization( ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(10, name ='Output_Layer'))\n",
    "model_bn.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PF7JmPILehHm",
    "outputId": "3b54c9d6-f973-4482-b467-0cb67ad8c9d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 25us/step - loss: 2.6686 - accuracy: 0.1054\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6642 - accuracy: 0.1049\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6615 - accuracy: 0.1060\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6588 - accuracy: 0.1062\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6564 - accuracy: 0.1070\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6542 - accuracy: 0.1067\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6498 - accuracy: 0.1069\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6482 - accuracy: 0.1058\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6461 - accuracy: 0.1069\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6441 - accuracy: 0.1067\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6420 - accuracy: 0.1075\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6378 - accuracy: 0.1080\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6365 - accuracy: 0.1088\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6336 - accuracy: 0.1084\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6315 - accuracy: 0.1091\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6289 - accuracy: 0.1082\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6262 - accuracy: 0.1094\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6241 - accuracy: 0.1095\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6224 - accuracy: 0.1095\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6204 - accuracy: 0.1074\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6186 - accuracy: 0.1093\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6163 - accuracy: 0.1090\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6125 - accuracy: 0.1101\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6106 - accuracy: 0.1104\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6090 - accuracy: 0.1096\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6076 - accuracy: 0.1106\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6039 - accuracy: 0.1115\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6038 - accuracy: 0.1102\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6009 - accuracy: 0.1114\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5996 - accuracy: 0.1103\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5970 - accuracy: 0.1113\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5951 - accuracy: 0.1122\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5931 - accuracy: 0.1122\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5917 - accuracy: 0.1122\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5891 - accuracy: 0.1122\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5876 - accuracy: 0.1125\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5859 - accuracy: 0.1133\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5843 - accuracy: 0.1152\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5826 - accuracy: 0.1129\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5807 - accuracy: 0.1134\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5785 - accuracy: 0.1146\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5771 - accuracy: 0.1143\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.5747 - accuracy: 0.1148\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5735 - accuracy: 0.1143\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.5708 - accuracy: 0.1152\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5694 - accuracy: 0.1145\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5677 - accuracy: 0.1159\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5654 - accuracy: 0.1150\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.5637 - accuracy: 0.1151\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5620 - accuracy: 0.1164\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5600 - accuracy: 0.1155\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5587 - accuracy: 0.1174\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5574 - accuracy: 0.1165\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5560 - accuracy: 0.1177\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5538 - accuracy: 0.1173\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5515 - accuracy: 0.1175\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5501 - accuracy: 0.1179\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5479 - accuracy: 0.1182\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5461 - accuracy: 0.1191\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5452 - accuracy: 0.1179\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.5429 - accuracy: 0.1180\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5415 - accuracy: 0.1194\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5394 - accuracy: 0.1194\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5383 - accuracy: 0.1196\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5368 - accuracy: 0.1198\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5344 - accuracy: 0.1204\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5339 - accuracy: 0.1201\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5322 - accuracy: 0.1204\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5313 - accuracy: 0.1208\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.5290 - accuracy: 0.1219\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5267 - accuracy: 0.1211\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.5252 - accuracy: 0.1199\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5244 - accuracy: 0.1224\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5220 - accuracy: 0.1225\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5211 - accuracy: 0.1226\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5197 - accuracy: 0.1216\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5185 - accuracy: 0.1222\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5163 - accuracy: 0.1224\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5156 - accuracy: 0.1235\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5126 - accuracy: 0.1235\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5120 - accuracy: 0.1242\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5094 - accuracy: 0.1256\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.5089 - accuracy: 0.1240\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5068 - accuracy: 0.1246\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.5054 - accuracy: 0.1243\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5040 - accuracy: 0.1244\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5026 - accuracy: 0.1251\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5016 - accuracy: 0.1255\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5010 - accuracy: 0.1259\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4984 - accuracy: 0.1257\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4970 - accuracy: 0.1265\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4957 - accuracy: 0.1262\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4940 - accuracy: 0.1264\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4933 - accuracy: 0.1268\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4915 - accuracy: 0.1267\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.4902 - accuracy: 0.1263\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4885 - accuracy: 0.1273\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4867 - accuracy: 0.1285\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4843 - accuracy: 0.1273\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4845 - accuracy: 0.1285\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4825 - accuracy: 0.1281\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4804 - accuracy: 0.1282\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.4803 - accuracy: 0.1290\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4793 - accuracy: 0.1290\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4772 - accuracy: 0.1295\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4752 - accuracy: 0.1300\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4750 - accuracy: 0.1290\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.4729 - accuracy: 0.1303\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4723 - accuracy: 0.1298\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4709 - accuracy: 0.1304\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4688 - accuracy: 0.1300\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4693 - accuracy: 0.1304\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4659 - accuracy: 0.1303\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4653 - accuracy: 0.1319\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4647 - accuracy: 0.1316\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4631 - accuracy: 0.1314\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4617 - accuracy: 0.1322\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4606 - accuracy: 0.1325\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4580 - accuracy: 0.1325\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4574 - accuracy: 0.1322\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4563 - accuracy: 0.1328\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4544 - accuracy: 0.1334\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4530 - accuracy: 0.1337\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4525 - accuracy: 0.1331\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4509 - accuracy: 0.1342\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4495 - accuracy: 0.1339\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4497 - accuracy: 0.1346\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4469 - accuracy: 0.1344\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4460 - accuracy: 0.1347\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4444 - accuracy: 0.1349\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4439 - accuracy: 0.1368\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4423 - accuracy: 0.1360\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4412 - accuracy: 0.1361\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4398 - accuracy: 0.1352\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4385 - accuracy: 0.1366\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4370 - accuracy: 0.1374\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4356 - accuracy: 0.1365\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4352 - accuracy: 0.1372\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4338 - accuracy: 0.1374\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4324 - accuracy: 0.1381\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4320 - accuracy: 0.1378\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4307 - accuracy: 0.1378\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4293 - accuracy: 0.1388\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4281 - accuracy: 0.1381\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4265 - accuracy: 0.1388\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.4261 - accuracy: 0.1395\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4241 - accuracy: 0.1401\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4233 - accuracy: 0.1393\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4224 - accuracy: 0.1394\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4214 - accuracy: 0.1406\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4207 - accuracy: 0.1387\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4183 - accuracy: 0.1410\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4168 - accuracy: 0.1410\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4160 - accuracy: 0.1408\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4150 - accuracy: 0.1423\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4146 - accuracy: 0.1409\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4125 - accuracy: 0.1421\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4108 - accuracy: 0.1420\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4112 - accuracy: 0.1425\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4099 - accuracy: 0.1424\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4085 - accuracy: 0.1428\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4070 - accuracy: 0.1433\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4067 - accuracy: 0.1435\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4057 - accuracy: 0.1436\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4054 - accuracy: 0.1432\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4032 - accuracy: 0.1451\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4023 - accuracy: 0.1448\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4010 - accuracy: 0.1454\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4003 - accuracy: 0.1451\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3984 - accuracy: 0.1453\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3976 - accuracy: 0.1452\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3961 - accuracy: 0.1444\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3964 - accuracy: 0.1471\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3949 - accuracy: 0.1465\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3928 - accuracy: 0.1461\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3922 - accuracy: 0.1474\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3909 - accuracy: 0.1469\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3905 - accuracy: 0.1464\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3888 - accuracy: 0.1469\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3878 - accuracy: 0.1473\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3867 - accuracy: 0.1475\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3869 - accuracy: 0.1488\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3847 - accuracy: 0.1496\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3839 - accuracy: 0.1483\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3830 - accuracy: 0.1486\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3820 - accuracy: 0.1489\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3809 - accuracy: 0.1505\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3792 - accuracy: 0.1490\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3787 - accuracy: 0.1505\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3777 - accuracy: 0.1510\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3767 - accuracy: 0.1512\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3757 - accuracy: 0.1519\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3748 - accuracy: 0.1506\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3736 - accuracy: 0.1526\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3715 - accuracy: 0.1527\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3717 - accuracy: 0.1524\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3705 - accuracy: 0.1516\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3697 - accuracy: 0.1522\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3683 - accuracy: 0.1532\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3669 - accuracy: 0.1521\n"
     ]
    }
   ],
   "source": [
    "model_bn.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_bn = model_bn.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sOuN3PtvehHv",
    "outputId": "28dac8c8-3221-4cab-e7bb-420e2e87da19",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 86us/step\n",
      "Validation accuracy:  0.15189999341964722\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bt = model_bn.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bt[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us also try optimizing the model with Adam optimizer then configure the model with loss function and metrices, train the modela and evaluate the model performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oMcD8Y2fehH5",
    "outputId": "94d9bc45-87f5-49a1-cbd1-bfede13efa53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 2.6643 - accuracy: 0.1046\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5659 - accuracy: 0.1160\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4851 - accuracy: 0.1305\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4156 - accuracy: 0.1435\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3512 - accuracy: 0.1607\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2932 - accuracy: 0.1754\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2399 - accuracy: 0.1904\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1909 - accuracy: 0.2084\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1466 - accuracy: 0.2233\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1050 - accuracy: 0.2403\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.0665 - accuracy: 0.2564\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.0298 - accuracy: 0.2723\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9960 - accuracy: 0.2904\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9647 - accuracy: 0.3050\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9347 - accuracy: 0.3212\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9057 - accuracy: 0.3354\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.8795 - accuracy: 0.3504\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.8539 - accuracy: 0.3642\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.8305 - accuracy: 0.3765\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8067 - accuracy: 0.3894\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.7851 - accuracy: 0.4023\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7642 - accuracy: 0.4115\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.7444 - accuracy: 0.4235\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7251 - accuracy: 0.4345\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7060 - accuracy: 0.4440\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.6881 - accuracy: 0.4542\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.6707 - accuracy: 0.4636\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.6547 - accuracy: 0.4725\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.6381 - accuracy: 0.4808\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.6223 - accuracy: 0.4885\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.6078 - accuracy: 0.4956\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5932 - accuracy: 0.5032\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.5777 - accuracy: 0.5105\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.5638 - accuracy: 0.5178\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5495 - accuracy: 0.5249\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.5356 - accuracy: 0.5312\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5224 - accuracy: 0.5382\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.5092 - accuracy: 0.5447\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4978 - accuracy: 0.5498\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4858 - accuracy: 0.5536\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4726 - accuracy: 0.5619\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4614 - accuracy: 0.5686\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.4506 - accuracy: 0.5717\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4382 - accuracy: 0.5772\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.4272 - accuracy: 0.5850\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4148 - accuracy: 0.5893\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.4044 - accuracy: 0.5965\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3937 - accuracy: 0.6019\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.3835 - accuracy: 0.6057\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3730 - accuracy: 0.6146\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.3633 - accuracy: 0.6187\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3527 - accuracy: 0.6234\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.3426 - accuracy: 0.6300\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.3332 - accuracy: 0.6360\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3224 - accuracy: 0.6415\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.3138 - accuracy: 0.6463\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3030 - accuracy: 0.6516\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2955 - accuracy: 0.6561\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2850 - accuracy: 0.6634\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.2763 - accuracy: 0.6677\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.2667 - accuracy: 0.6718\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2575 - accuracy: 0.6765\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.2491 - accuracy: 0.6817\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2398 - accuracy: 0.6875\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2322 - accuracy: 0.6896\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2229 - accuracy: 0.6966\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.2142 - accuracy: 0.6987\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2058 - accuracy: 0.7046\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1975 - accuracy: 0.7073\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1898 - accuracy: 0.7111\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1807 - accuracy: 0.7168\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1728 - accuracy: 0.7190\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.1654 - accuracy: 0.7233\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.1565 - accuracy: 0.7265\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1488 - accuracy: 0.7295\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1419 - accuracy: 0.7329\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1336 - accuracy: 0.7367\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1252 - accuracy: 0.7390\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1181 - accuracy: 0.7440\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1113 - accuracy: 0.7455\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1039 - accuracy: 0.7480\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0956 - accuracy: 0.7526\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0888 - accuracy: 0.7546\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0804 - accuracy: 0.7576\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.0742 - accuracy: 0.7598\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0662 - accuracy: 0.7653\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.0605 - accuracy: 0.7659\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.0532 - accuracy: 0.7680\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.0451 - accuracy: 0.7723\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0380 - accuracy: 0.7742\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.0331 - accuracy: 0.7770\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0247 - accuracy: 0.7792\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.0175 - accuracy: 0.7816\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0108 - accuracy: 0.7855\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.0033 - accuracy: 0.7868\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9978 - accuracy: 0.7884\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9908 - accuracy: 0.7919\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9842 - accuracy: 0.7925\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9775 - accuracy: 0.7963\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.9712 - accuracy: 0.7960\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.9641 - accuracy: 0.8008\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9589 - accuracy: 0.8010\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9524 - accuracy: 0.8048\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.9450 - accuracy: 0.8066\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9394 - accuracy: 0.8081\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9333 - accuracy: 0.8103\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9272 - accuracy: 0.8128\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9200 - accuracy: 0.8145\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9155 - accuracy: 0.8159\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9081 - accuracy: 0.8165\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9028 - accuracy: 0.8199\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.8970 - accuracy: 0.8217\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8910 - accuracy: 0.8227\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8849 - accuracy: 0.8254\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8790 - accuracy: 0.8268\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8733 - accuracy: 0.8278\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8684 - accuracy: 0.8304\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8605 - accuracy: 0.8322\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.8552 - accuracy: 0.8331\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8507 - accuracy: 0.8352\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.8457 - accuracy: 0.8369\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8397 - accuracy: 0.8382\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.8343 - accuracy: 0.8387\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8272 - accuracy: 0.8424\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.8234 - accuracy: 0.8432\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8170 - accuracy: 0.8446\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.8119 - accuracy: 0.8451\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8064 - accuracy: 0.8472\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8018 - accuracy: 0.8492\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.7954 - accuracy: 0.8508\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7904 - accuracy: 0.8519\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7866 - accuracy: 0.8517\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7803 - accuracy: 0.8541\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7744 - accuracy: 0.8571\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7691 - accuracy: 0.8571\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7651 - accuracy: 0.8595\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7597 - accuracy: 0.8592\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7557 - accuracy: 0.8599\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7494 - accuracy: 0.8625\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7449 - accuracy: 0.8645\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7398 - accuracy: 0.8643\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7349 - accuracy: 0.8661\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7297 - accuracy: 0.8676\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7255 - accuracy: 0.8690\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7195 - accuracy: 0.8718\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7149 - accuracy: 0.8719\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7104 - accuracy: 0.8730\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7065 - accuracy: 0.8726\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7009 - accuracy: 0.8758\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6968 - accuracy: 0.8772\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6922 - accuracy: 0.8765\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6865 - accuracy: 0.8803\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6817 - accuracy: 0.8805\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6778 - accuracy: 0.8814\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6728 - accuracy: 0.8830\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6696 - accuracy: 0.8815\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6649 - accuracy: 0.8843\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.6601 - accuracy: 0.8848\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6543 - accuracy: 0.8871\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6506 - accuracy: 0.8876\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.6469 - accuracy: 0.8896\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6421 - accuracy: 0.8913\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6382 - accuracy: 0.8906\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6335 - accuracy: 0.8918\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6292 - accuracy: 0.8925\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.6256 - accuracy: 0.8935\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6206 - accuracy: 0.8959\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6161 - accuracy: 0.8957\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6112 - accuracy: 0.8975\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6080 - accuracy: 0.8985\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.6053 - accuracy: 0.8988\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5996 - accuracy: 0.9009\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.5957 - accuracy: 0.9014\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.5914 - accuracy: 0.9013\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5860 - accuracy: 0.9033\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5835 - accuracy: 0.9033\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5778 - accuracy: 0.9066\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5755 - accuracy: 0.9052\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5716 - accuracy: 0.9062\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5663 - accuracy: 0.9080\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.5626 - accuracy: 0.9088\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5596 - accuracy: 0.9095\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.5549 - accuracy: 0.9110\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5524 - accuracy: 0.9111\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5473 - accuracy: 0.9127\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5441 - accuracy: 0.9127\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5401 - accuracy: 0.9142\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5367 - accuracy: 0.9150\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5327 - accuracy: 0.9156\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5287 - accuracy: 0.9162\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5244 - accuracy: 0.9172\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5211 - accuracy: 0.9183\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.5184 - accuracy: 0.9175\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5143 - accuracy: 0.9200\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5100 - accuracy: 0.9210\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5070 - accuracy: 0.9208\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.5024 - accuracy: 0.9224\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5000 - accuracy: 0.9242\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4962 - accuracy: 0.9240\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.4939 - accuracy: 0.9241\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.00001)\n",
    "model_bn.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history_bn_adam = model_bn.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NKyVzeWHehIF",
    "outputId": "26696326-2aae-4e6d-9c99-0adddcbc03f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 88us/step\n",
      "Validation accuracy:  0.8808500170707703\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bt_ad = model_bn.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bt_ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "St_pazSFxo5U"
   },
   "source": [
    "##### Inference on the above steps:\n",
    "1. Above the Neural Network model was created as said initially.\n",
    "2. The performance of the model when using SGD optimizer was very low on training data but on validation data it was little better still the performance is just 15.21%.\n",
    "2. The performance of the model when using Adam optimizer was high on training data but on validation data it was around 88.08% only this may be due to overfitting of the model during training so some regularization need to be done further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAea6vfYfC_H"
   },
   "source": [
    "##### Model - 3 : (Trial - 4):\n",
    "    Here a Sequential Neural Network model is built by adding the BatchNormalization Layer with scaling and shifting parameters turned on, this model is given a relu activation with 'He-normal' weight iniitialization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTCEHo4rfC_O"
   },
   "outputs": [],
   "source": [
    "model_bn = Sequential()\n",
    "\n",
    "model_bn.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(10, name ='Output_Layer'))\n",
    "model_bn.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "STY21drVfC_j",
    "outputId": "6e13758f-0f4f-4289-cb2e-01f698a1d48a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 2.5877 - accuracy: 0.1004\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5868 - accuracy: 0.1002\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5834 - accuracy: 0.1007\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5813 - accuracy: 0.1014\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5793 - accuracy: 0.1018\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5781 - accuracy: 0.1010\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5754 - accuracy: 0.1022\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5735 - accuracy: 0.1015\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5729 - accuracy: 0.1013\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5698 - accuracy: 0.1024\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5688 - accuracy: 0.1029\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5674 - accuracy: 0.1015\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5650 - accuracy: 0.1028\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5634 - accuracy: 0.1030\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5623 - accuracy: 0.1021\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5595 - accuracy: 0.1042\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5583 - accuracy: 0.1048\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5561 - accuracy: 0.1045\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5541 - accuracy: 0.1052\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5534 - accuracy: 0.1052\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5514 - accuracy: 0.1057\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5488 - accuracy: 0.1048\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5473 - accuracy: 0.1057\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5465 - accuracy: 0.1072\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5435 - accuracy: 0.1056\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5421 - accuracy: 0.1066\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5408 - accuracy: 0.1067\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5387 - accuracy: 0.1080\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5376 - accuracy: 0.1087\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5364 - accuracy: 0.1078\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5343 - accuracy: 0.1083\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5329 - accuracy: 0.1085\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5317 - accuracy: 0.1084\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5280 - accuracy: 0.1102\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5276 - accuracy: 0.1089\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5267 - accuracy: 0.1103\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5253 - accuracy: 0.1095\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5233 - accuracy: 0.1096\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5213 - accuracy: 0.1100\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5197 - accuracy: 0.1120\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5184 - accuracy: 0.1111\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5171 - accuracy: 0.1113\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5161 - accuracy: 0.1115\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5134 - accuracy: 0.1110\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5126 - accuracy: 0.1115\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5099 - accuracy: 0.1131\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5087 - accuracy: 0.1127\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5076 - accuracy: 0.1127\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5053 - accuracy: 0.1139\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5052 - accuracy: 0.1131\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5029 - accuracy: 0.1134\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5019 - accuracy: 0.1154\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.5002 - accuracy: 0.1152\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4986 - accuracy: 0.1155\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.4975 - accuracy: 0.1141\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4965 - accuracy: 0.1142\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4943 - accuracy: 0.1170\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4930 - accuracy: 0.1156\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4908 - accuracy: 0.1163\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4901 - accuracy: 0.1151\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4887 - accuracy: 0.1167\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4866 - accuracy: 0.1183\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4854 - accuracy: 0.1180\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4843 - accuracy: 0.1189\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4826 - accuracy: 0.1175\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4817 - accuracy: 0.1162\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4806 - accuracy: 0.1174\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4794 - accuracy: 0.1184\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4782 - accuracy: 0.1187\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4757 - accuracy: 0.1189\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4740 - accuracy: 0.1190\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4729 - accuracy: 0.1193\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4720 - accuracy: 0.1204\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4705 - accuracy: 0.1199\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4689 - accuracy: 0.1199\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4678 - accuracy: 0.1204\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4669 - accuracy: 0.1199\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4652 - accuracy: 0.1222\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4646 - accuracy: 0.1210\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4631 - accuracy: 0.1202\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4617 - accuracy: 0.1224\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4601 - accuracy: 0.1230\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4589 - accuracy: 0.1227\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4573 - accuracy: 0.1215\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4557 - accuracy: 0.1227\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4547 - accuracy: 0.1217\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4538 - accuracy: 0.1233\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4520 - accuracy: 0.1240\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4509 - accuracy: 0.1226\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4503 - accuracy: 0.1252\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4481 - accuracy: 0.1250\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4472 - accuracy: 0.1235\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4459 - accuracy: 0.1243\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4451 - accuracy: 0.1258\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4439 - accuracy: 0.1252\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4421 - accuracy: 0.1271\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4412 - accuracy: 0.1260\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4398 - accuracy: 0.1246\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4381 - accuracy: 0.1268\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4371 - accuracy: 0.1265\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4364 - accuracy: 0.1270\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4350 - accuracy: 0.1268\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4342 - accuracy: 0.1276\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4328 - accuracy: 0.1269\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4305 - accuracy: 0.1275\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4301 - accuracy: 0.1285\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4288 - accuracy: 0.1278\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4279 - accuracy: 0.1270\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4267 - accuracy: 0.1293\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4251 - accuracy: 0.1287\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4250 - accuracy: 0.1285\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4230 - accuracy: 0.1287\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4218 - accuracy: 0.1301\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4218 - accuracy: 0.1285\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4199 - accuracy: 0.1303\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.4197 - accuracy: 0.1295\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4189 - accuracy: 0.1301\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.4166 - accuracy: 0.1325\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4142 - accuracy: 0.1313\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4145 - accuracy: 0.1321\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4136 - accuracy: 0.1328\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4118 - accuracy: 0.1327\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4108 - accuracy: 0.1326\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4106 - accuracy: 0.1321\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4086 - accuracy: 0.1331\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4077 - accuracy: 0.1327\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.4069 - accuracy: 0.1340\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4053 - accuracy: 0.1339\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4040 - accuracy: 0.1328\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4021 - accuracy: 0.1335\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4023 - accuracy: 0.1336\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4005 - accuracy: 0.1330\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.4002 - accuracy: 0.1331\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3993 - accuracy: 0.1362\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3982 - accuracy: 0.1360\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3964 - accuracy: 0.1352\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3962 - accuracy: 0.1350\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3957 - accuracy: 0.1355\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3936 - accuracy: 0.1354\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3929 - accuracy: 0.1368\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3917 - accuracy: 0.1368\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3903 - accuracy: 0.1350\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3900 - accuracy: 0.1370\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3887 - accuracy: 0.1369\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3877 - accuracy: 0.1384\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3855 - accuracy: 0.1390\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3851 - accuracy: 0.1380\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3851 - accuracy: 0.1388\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3829 - accuracy: 0.1394\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3825 - accuracy: 0.1389\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3813 - accuracy: 0.1398\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3806 - accuracy: 0.1399\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3786 - accuracy: 0.1396\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3785 - accuracy: 0.1395\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3764 - accuracy: 0.1404\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3770 - accuracy: 0.1404\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3762 - accuracy: 0.1405\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3738 - accuracy: 0.1409\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3728 - accuracy: 0.1408\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3719 - accuracy: 0.1428\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3713 - accuracy: 0.1421\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3700 - accuracy: 0.1418\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3691 - accuracy: 0.1431\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3688 - accuracy: 0.1430\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3672 - accuracy: 0.1430\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3663 - accuracy: 0.1441\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3658 - accuracy: 0.1437\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3645 - accuracy: 0.1444\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3636 - accuracy: 0.1431\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3631 - accuracy: 0.1440\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3615 - accuracy: 0.1438\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3607 - accuracy: 0.1445\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3603 - accuracy: 0.1459\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3594 - accuracy: 0.1452\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3581 - accuracy: 0.1464\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3572 - accuracy: 0.1457\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3554 - accuracy: 0.1461\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3546 - accuracy: 0.1453\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3539 - accuracy: 0.1460\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3533 - accuracy: 0.1467\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3518 - accuracy: 0.1473\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3511 - accuracy: 0.1480\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3490 - accuracy: 0.1482\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3492 - accuracy: 0.1473\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3496 - accuracy: 0.1475\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3476 - accuracy: 0.1480\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3459 - accuracy: 0.1497\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 0s 10us/step - loss: 2.3462 - accuracy: 0.1481\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3438 - accuracy: 0.1488\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3434 - accuracy: 0.1508\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3439 - accuracy: 0.1480\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3419 - accuracy: 0.1509\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3413 - accuracy: 0.1498\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3411 - accuracy: 0.1505\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3397 - accuracy: 0.1505\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3390 - accuracy: 0.1513\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3381 - accuracy: 0.1506\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3368 - accuracy: 0.1519\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3364 - accuracy: 0.1516\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.3348 - accuracy: 0.1517\n"
     ]
    }
   ],
   "source": [
    "model_bn.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_bn = model_bn.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "skdpwkI8fC_2",
    "outputId": "2a1c7e6a-dd50-4b16-b5aa-24328663ef44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 86us/step\n",
      "Validation accuracy:  0.14908333122730255\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bt = model_bn.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bt[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us also try optimizing the model with Adam optimizer then configure the model with loss function and metrices, train the modela and evaluate the model performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aZpwvWp4fC_-",
    "outputId": "b9c6b44a-bde3-49a4-eac7-58c79611df34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 31us/step - loss: 2.5374 - accuracy: 0.1065\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4210 - accuracy: 0.1355\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3345 - accuracy: 0.1601\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2640 - accuracy: 0.1838\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.2034 - accuracy: 0.2083\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.1495 - accuracy: 0.2285\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.1007 - accuracy: 0.2500\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.0578 - accuracy: 0.2684\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.0183 - accuracy: 0.2876\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9805 - accuracy: 0.3070\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9480 - accuracy: 0.3208\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.9165 - accuracy: 0.3373\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.8867 - accuracy: 0.3530\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.8580 - accuracy: 0.3682\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.8308 - accuracy: 0.3820\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.8051 - accuracy: 0.3972\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.7802 - accuracy: 0.4091\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.7575 - accuracy: 0.4208\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7329 - accuracy: 0.4335\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7128 - accuracy: 0.4452\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.6914 - accuracy: 0.4585\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.6707 - accuracy: 0.4668\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.6502 - accuracy: 0.4799\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.6329 - accuracy: 0.4881\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.6140 - accuracy: 0.4991\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5958 - accuracy: 0.5074\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5777 - accuracy: 0.5170\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5610 - accuracy: 0.5256\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5442 - accuracy: 0.5347\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.5282 - accuracy: 0.5429\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5110 - accuracy: 0.5515\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4970 - accuracy: 0.5593\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4814 - accuracy: 0.5674\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4669 - accuracy: 0.5750\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4526 - accuracy: 0.5810\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4379 - accuracy: 0.5887\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4241 - accuracy: 0.5955\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.4113 - accuracy: 0.6028\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3971 - accuracy: 0.6100\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3839 - accuracy: 0.6149\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3716 - accuracy: 0.6216\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3583 - accuracy: 0.6272\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3468 - accuracy: 0.6341\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3337 - accuracy: 0.6395\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3221 - accuracy: 0.6460\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3099 - accuracy: 0.6516\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2990 - accuracy: 0.6569\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2875 - accuracy: 0.6599\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2760 - accuracy: 0.6650\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.2657 - accuracy: 0.6686\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2541 - accuracy: 0.6749\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2434 - accuracy: 0.6802\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2335 - accuracy: 0.6847\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.2221 - accuracy: 0.6884\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2122 - accuracy: 0.6921\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2024 - accuracy: 0.6968\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 1.1931 - accuracy: 0.7016\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1826 - accuracy: 0.7054\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1725 - accuracy: 0.7093\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1629 - accuracy: 0.7127\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1548 - accuracy: 0.7155\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1449 - accuracy: 0.7203\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1363 - accuracy: 0.7232\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1272 - accuracy: 0.7266\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1173 - accuracy: 0.7313\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.1081 - accuracy: 0.7347\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0990 - accuracy: 0.7372\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0901 - accuracy: 0.7413\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0821 - accuracy: 0.7434\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0733 - accuracy: 0.7474\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0652 - accuracy: 0.7502\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0570 - accuracy: 0.7517\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0495 - accuracy: 0.7550\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0416 - accuracy: 0.7574\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0322 - accuracy: 0.7626\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0241 - accuracy: 0.7652\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0167 - accuracy: 0.7676\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0089 - accuracy: 0.7705\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.0005 - accuracy: 0.7718\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.9922 - accuracy: 0.7751\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9861 - accuracy: 0.7789\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9781 - accuracy: 0.7793\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.9707 - accuracy: 0.7829\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9634 - accuracy: 0.7861\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9566 - accuracy: 0.7881\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9485 - accuracy: 0.7908\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9429 - accuracy: 0.7916\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9345 - accuracy: 0.7956\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9282 - accuracy: 0.7965\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9211 - accuracy: 0.7985\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9144 - accuracy: 0.8011\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.9069 - accuracy: 0.8045\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8992 - accuracy: 0.8080\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8923 - accuracy: 0.8088\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8866 - accuracy: 0.8104\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8788 - accuracy: 0.8131\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8742 - accuracy: 0.8147\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8660 - accuracy: 0.8182\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8603 - accuracy: 0.8188\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8532 - accuracy: 0.8200\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8474 - accuracy: 0.8219\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8405 - accuracy: 0.8249\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8351 - accuracy: 0.8266\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8290 - accuracy: 0.8276\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8229 - accuracy: 0.8292\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8152 - accuracy: 0.8325\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8110 - accuracy: 0.8324\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.8055 - accuracy: 0.8344\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7980 - accuracy: 0.8354\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7923 - accuracy: 0.8381\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7872 - accuracy: 0.8392\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7815 - accuracy: 0.8402\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7745 - accuracy: 0.8445\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7697 - accuracy: 0.8452\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7642 - accuracy: 0.8460\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7587 - accuracy: 0.8473\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7526 - accuracy: 0.8493\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7483 - accuracy: 0.8493\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7405 - accuracy: 0.8530\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7358 - accuracy: 0.8541\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7301 - accuracy: 0.8559\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7246 - accuracy: 0.8570\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7193 - accuracy: 0.8590\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7155 - accuracy: 0.8595\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7093 - accuracy: 0.8612\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.7049 - accuracy: 0.8628\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6993 - accuracy: 0.8633\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6935 - accuracy: 0.8665\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6882 - accuracy: 0.8672\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6848 - accuracy: 0.8685\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6802 - accuracy: 0.8699\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6735 - accuracy: 0.8711\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6691 - accuracy: 0.8718\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6633 - accuracy: 0.8730\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6578 - accuracy: 0.8763\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6540 - accuracy: 0.8760\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6486 - accuracy: 0.8785\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6442 - accuracy: 0.8784\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6386 - accuracy: 0.8802\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6332 - accuracy: 0.8840\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6299 - accuracy: 0.8823\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6269 - accuracy: 0.8832\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.6193 - accuracy: 0.8855\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.6167 - accuracy: 0.8872\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6126 - accuracy: 0.8884\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6071 - accuracy: 0.8898\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.6038 - accuracy: 0.8889\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5979 - accuracy: 0.8914\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5936 - accuracy: 0.8932\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5893 - accuracy: 0.8927\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 0.5844 - accuracy: 0.8951\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5805 - accuracy: 0.8962\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5762 - accuracy: 0.8960\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5726 - accuracy: 0.8978\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5682 - accuracy: 0.8977\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5621 - accuracy: 0.9002\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5597 - accuracy: 0.9013\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5538 - accuracy: 0.9025\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5509 - accuracy: 0.9038\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5460 - accuracy: 0.9044\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5427 - accuracy: 0.9050\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5383 - accuracy: 0.9064\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5347 - accuracy: 0.9082\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5307 - accuracy: 0.9087\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5273 - accuracy: 0.9094\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5222 - accuracy: 0.9100\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5191 - accuracy: 0.9116\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5144 - accuracy: 0.9135\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5092 - accuracy: 0.9144\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5067 - accuracy: 0.9140\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.5024 - accuracy: 0.9153\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.4977 - accuracy: 0.9166\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4953 - accuracy: 0.9175\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4902 - accuracy: 0.9190\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4873 - accuracy: 0.9197\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4842 - accuracy: 0.9204\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4811 - accuracy: 0.9203\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4765 - accuracy: 0.9224\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4726 - accuracy: 0.9241\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4711 - accuracy: 0.9232\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4658 - accuracy: 0.9243\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4613 - accuracy: 0.9258\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4588 - accuracy: 0.9274\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4550 - accuracy: 0.9271\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4525 - accuracy: 0.9283\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4484 - accuracy: 0.9286\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4449 - accuracy: 0.9306\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4416 - accuracy: 0.9298\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4375 - accuracy: 0.9318\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4348 - accuracy: 0.9324\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4312 - accuracy: 0.9331\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4287 - accuracy: 0.9330\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4244 - accuracy: 0.9342\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4215 - accuracy: 0.9353\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4180 - accuracy: 0.9360\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4144 - accuracy: 0.9363\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4102 - accuracy: 0.9379\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4098 - accuracy: 0.9379\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4054 - accuracy: 0.9388\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.4016 - accuracy: 0.9403\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.00001)\n",
    "model_bn.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history_bn_adam = model_bn.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sJk-vbpMfDAc",
    "outputId": "e385cbdb-b3e0-4cf1-e49c-ac4d495fc3ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 93us/step\n",
      "Validation accuracy:  0.880466639995575\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bt_ad = model_bn.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bt_ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BgukrlxxzTi"
   },
   "source": [
    "##### Inference on the above steps:\n",
    "1. Above the Neural Network model was created as said initially.\n",
    "2. The performance of the model when using SGD optimizer was very low on training data but on validation data it was little better still the performance is just 14.9%.\n",
    "2. The performance of the model when using Adam optimizer was high on training data but on validation data it was around 88.04% only this may be due to overfitting of the model during training so some regularization need to be done further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-vUoa6Oxy25"
   },
   "source": [
    "    Further, let us try improving the above four models by doing regularization - dropout. A 50% drop-out is performed on the hidden Layers during training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uw-wcivv44_o"
   },
   "source": [
    "#### Model - 4 :Batch Normalization and Dropout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model - 4: (Trial -1):\n",
    "    Here a Sequential Neural Network model is built by adding the 50% Dropout, BatchNormalization Layer with scaling and shifting parameters turned on, this model is given a selu activation with 'He-normal' weight iniitialization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNuh_55y44_u"
   },
   "outputs": [],
   "source": [
    "model_bd = Sequential()\n",
    "\n",
    "model_bd.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True))\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(10, name ='Output_Layer'))\n",
    "model_bd.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dX8aNh2e44_6",
    "outputId": "98d610c8-4687-406d-8679-d749009ccc36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 3.3794 - accuracy: 0.1006\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3802 - accuracy: 0.0977\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3725 - accuracy: 0.0980\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3739 - accuracy: 0.0999\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3691 - accuracy: 0.1000\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3817 - accuracy: 0.0985\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3746 - accuracy: 0.1019\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3640 - accuracy: 0.1014\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3513 - accuracy: 0.1017\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3749 - accuracy: 0.0980\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3642 - accuracy: 0.1010\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3708 - accuracy: 0.0977\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.3736 - accuracy: 0.0984\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3658 - accuracy: 0.0984\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3537 - accuracy: 0.0996\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3571 - accuracy: 0.1011\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3475 - accuracy: 0.0998\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3612 - accuracy: 0.0986\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3509 - accuracy: 0.0982\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3659 - accuracy: 0.0992\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3570 - accuracy: 0.1027\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3749 - accuracy: 0.0974\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3481 - accuracy: 0.1005\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3653 - accuracy: 0.0979\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.3556 - accuracy: 0.0999\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3390 - accuracy: 0.1007\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.3386 - accuracy: 0.1006\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3470 - accuracy: 0.1015\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3568 - accuracy: 0.0991\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3452 - accuracy: 0.1004\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3484 - accuracy: 0.1007\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3554 - accuracy: 0.0984\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3500 - accuracy: 0.0998\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3429 - accuracy: 0.1006\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3465 - accuracy: 0.1001\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3640 - accuracy: 0.0969\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3411 - accuracy: 0.0995\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3597 - accuracy: 0.0975\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3407 - accuracy: 0.1000\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3282 - accuracy: 0.1012\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3393 - accuracy: 0.0992\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3322 - accuracy: 0.1017\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3304 - accuracy: 0.1014\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3461 - accuracy: 0.0971\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3289 - accuracy: 0.0989\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3423 - accuracy: 0.1001\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3463 - accuracy: 0.0993\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3291 - accuracy: 0.1002\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3395 - accuracy: 0.0978\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3325 - accuracy: 0.0980\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3332 - accuracy: 0.0968\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3249 - accuracy: 0.0985\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3265 - accuracy: 0.1011\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3111 - accuracy: 0.1014\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3380 - accuracy: 0.0974\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3291 - accuracy: 0.0983\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3354 - accuracy: 0.0992\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3280 - accuracy: 0.1007\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3259 - accuracy: 0.1005\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3268 - accuracy: 0.0997\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3243 - accuracy: 0.0998\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3263 - accuracy: 0.0976\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3334 - accuracy: 0.0978\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3339 - accuracy: 0.0986\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3175 - accuracy: 0.1016\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3191 - accuracy: 0.0999\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3166 - accuracy: 0.0997\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3179 - accuracy: 0.1025\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3105 - accuracy: 0.1007\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3215 - accuracy: 0.0997\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3313 - accuracy: 0.0982\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3020 - accuracy: 0.0993\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3159 - accuracy: 0.1022\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2960 - accuracy: 0.1011\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3078 - accuracy: 0.1023\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3054 - accuracy: 0.1001\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3326 - accuracy: 0.0998\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2904 - accuracy: 0.1023\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3090 - accuracy: 0.0983\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2845 - accuracy: 0.1006\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3163 - accuracy: 0.0984\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3060 - accuracy: 0.1009\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3048 - accuracy: 0.0998\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3065 - accuracy: 0.1004\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.3052 - accuracy: 0.0974\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2831 - accuracy: 0.1015\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2980 - accuracy: 0.0990\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3019 - accuracy: 0.1003\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.3026 - accuracy: 0.0966\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2921 - accuracy: 0.1006\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2972 - accuracy: 0.1007\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3012 - accuracy: 0.0983\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.3066 - accuracy: 0.0971\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2883 - accuracy: 0.1005\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2794 - accuracy: 0.1016\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2851 - accuracy: 0.1012\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2889 - accuracy: 0.1018\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2836 - accuracy: 0.1018\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2867 - accuracy: 0.1017\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2868 - accuracy: 0.1003\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2761 - accuracy: 0.1012\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2874 - accuracy: 0.1003\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2845 - accuracy: 0.1005\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2962 - accuracy: 0.0956\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2884 - accuracy: 0.0988\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2861 - accuracy: 0.0966\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2784 - accuracy: 0.0995\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2828 - accuracy: 0.0986\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2768 - accuracy: 0.1007\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2845 - accuracy: 0.0995\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2711 - accuracy: 0.1014\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2758 - accuracy: 0.1016\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2844 - accuracy: 0.0970\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2895 - accuracy: 0.0997\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2767 - accuracy: 0.1004\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2699 - accuracy: 0.1013\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2671 - accuracy: 0.0995\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2823 - accuracy: 0.0990\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2758 - accuracy: 0.0986\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2675 - accuracy: 0.0998\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2757 - accuracy: 0.0999\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2667 - accuracy: 0.0988\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2753 - accuracy: 0.0989\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2748 - accuracy: 0.0992\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2674 - accuracy: 0.0983\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2641 - accuracy: 0.0994\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2662 - accuracy: 0.1015\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2744 - accuracy: 0.0995\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2661 - accuracy: 0.0994\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2654 - accuracy: 0.1001\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2728 - accuracy: 0.0975\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2572 - accuracy: 0.1011\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2540 - accuracy: 0.0999\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2638 - accuracy: 0.1014\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2603 - accuracy: 0.0999\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2550 - accuracy: 0.0999\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2545 - accuracy: 0.0987\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2637 - accuracy: 0.0992\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2555 - accuracy: 0.1005\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2529 - accuracy: 0.1012\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2586 - accuracy: 0.1012\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2568 - accuracy: 0.0997\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2487 - accuracy: 0.1005\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2505 - accuracy: 0.0970\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2522 - accuracy: 0.1009\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2547 - accuracy: 0.0989\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2541 - accuracy: 0.1005\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2459 - accuracy: 0.0986\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2530 - accuracy: 0.0985\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2587 - accuracy: 0.1001\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2483 - accuracy: 0.0984\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2397 - accuracy: 0.0987\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2496 - accuracy: 0.1004\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2553 - accuracy: 0.0966\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2455 - accuracy: 0.0996\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2396 - accuracy: 0.0986\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2463 - accuracy: 0.0997\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2337 - accuracy: 0.0998\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2394 - accuracy: 0.1005\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2240 - accuracy: 0.1002\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2302 - accuracy: 0.1002\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2342 - accuracy: 0.0986\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2264 - accuracy: 0.1008\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2280 - accuracy: 0.1012\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2568 - accuracy: 0.1000\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2418 - accuracy: 0.0979\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2386 - accuracy: 0.0988\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2457 - accuracy: 0.0985\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2182 - accuracy: 0.1023\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2241 - accuracy: 0.0996\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2221 - accuracy: 0.1010\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2270 - accuracy: 0.0986\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2298 - accuracy: 0.1002\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2362 - accuracy: 0.0988\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2398 - accuracy: 0.0988\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2257 - accuracy: 0.1023\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2296 - accuracy: 0.0998\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2150 - accuracy: 0.1015\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2225 - accuracy: 0.0999\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2178 - accuracy: 0.0998\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2228 - accuracy: 0.1002\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2340 - accuracy: 0.0987\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2135 - accuracy: 0.1014\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2268 - accuracy: 0.1011\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2155 - accuracy: 0.0995\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2260 - accuracy: 0.0988\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2215 - accuracy: 0.1005\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2133 - accuracy: 0.0995\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2195 - accuracy: 0.0992\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2046 - accuracy: 0.1016\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2083 - accuracy: 0.1006\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2181 - accuracy: 0.0989\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2155 - accuracy: 0.1020\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2168 - accuracy: 0.0983\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2044 - accuracy: 0.1018\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2100 - accuracy: 0.0980\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2111 - accuracy: 0.1008\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2139 - accuracy: 0.1010\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2187 - accuracy: 0.0993\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2048 - accuracy: 0.1014\n"
     ]
    }
   ],
   "source": [
    "model_bd.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_bd = model_bd.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "r60pI0YD45AE",
    "outputId": "052958b1-31af-430a-9ab6-09e6265f0a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 96us/step\n",
      "Validation accuracy:  0.09764999896287918\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bd = model_bd.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bd[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us also try optimizing the model with Adam optimizer then configure the model with loss function and metrices, train the modela and evaluate the model performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nxOW16dN9y30",
    "outputId": "4d7f2529-4afa-43f0-fd0b-9f88cc57501b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 35us/step - loss: 3.4428 - accuracy: 0.1003\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.4420 - accuracy: 0.0995\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.4236 - accuracy: 0.1001\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.4183 - accuracy: 0.1002\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3919 - accuracy: 0.1002\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3958 - accuracy: 0.1006\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3816 - accuracy: 0.1017\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3812 - accuracy: 0.0985\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3735 - accuracy: 0.1021\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3664 - accuracy: 0.1011\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3641 - accuracy: 0.0991\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3529 - accuracy: 0.1002\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3245 - accuracy: 0.1004\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3263 - accuracy: 0.1030\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3263 - accuracy: 0.0998\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3158 - accuracy: 0.1011\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3121 - accuracy: 0.1008\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2967 - accuracy: 0.1013\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2845 - accuracy: 0.1052\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3026 - accuracy: 0.1016\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2869 - accuracy: 0.1010\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2684 - accuracy: 0.1010\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.2610 - accuracy: 0.1016\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2549 - accuracy: 0.1031\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2505 - accuracy: 0.1036\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2250 - accuracy: 0.1058\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2438 - accuracy: 0.1034\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2276 - accuracy: 0.1021\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2328 - accuracy: 0.1007\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2237 - accuracy: 0.1045\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1974 - accuracy: 0.1049\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2059 - accuracy: 0.1036\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2166 - accuracy: 0.1020\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.2024 - accuracy: 0.1043\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1932 - accuracy: 0.1054\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.1789 - accuracy: 0.1011\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1729 - accuracy: 0.1035\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1723 - accuracy: 0.1056\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.1687 - accuracy: 0.1029\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1586 - accuracy: 0.1032\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1514 - accuracy: 0.1029\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1483 - accuracy: 0.1044\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.1324 - accuracy: 0.1056\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1296 - accuracy: 0.1052\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1369 - accuracy: 0.1050\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.1269 - accuracy: 0.1061\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1181 - accuracy: 0.1057\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.1195 - accuracy: 0.1031\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1075 - accuracy: 0.1019\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1074 - accuracy: 0.1035\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1147 - accuracy: 0.1028\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1082 - accuracy: 0.1042\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0804 - accuracy: 0.1065\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0855 - accuracy: 0.1067\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0820 - accuracy: 0.1071\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0681 - accuracy: 0.1050\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0742 - accuracy: 0.1056\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0797 - accuracy: 0.1048\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0694 - accuracy: 0.1065\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0706 - accuracy: 0.1064\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0569 - accuracy: 0.1035\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0556 - accuracy: 0.1050\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0440 - accuracy: 0.1062\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0533 - accuracy: 0.1055\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0363 - accuracy: 0.1070\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.0325 - accuracy: 0.1061\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0306 - accuracy: 0.1063\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0295 - accuracy: 0.1051\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0289 - accuracy: 0.1060\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.0164 - accuracy: 0.1070\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0116 - accuracy: 0.1080\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0153 - accuracy: 0.1045\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9983 - accuracy: 0.1066\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9965 - accuracy: 0.1060\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.0018 - accuracy: 0.1054\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9905 - accuracy: 0.1080\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9888 - accuracy: 0.1055\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9872 - accuracy: 0.1075\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9790 - accuracy: 0.1052\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9886 - accuracy: 0.1035\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9707 - accuracy: 0.1069\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9602 - accuracy: 0.1081\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9690 - accuracy: 0.1084\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9617 - accuracy: 0.1093\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9572 - accuracy: 0.1086\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9535 - accuracy: 0.1064\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9553 - accuracy: 0.1050\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9470 - accuracy: 0.1078\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9539 - accuracy: 0.1060\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9481 - accuracy: 0.1074\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9232 - accuracy: 0.1120\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9334 - accuracy: 0.1084\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9339 - accuracy: 0.1075\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9309 - accuracy: 0.1085\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9260 - accuracy: 0.1067\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9176 - accuracy: 0.1080\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9283 - accuracy: 0.1061\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9209 - accuracy: 0.1072\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9207 - accuracy: 0.1064\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9034 - accuracy: 0.1063\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9049 - accuracy: 0.1071\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9024 - accuracy: 0.1073\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8956 - accuracy: 0.1090\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9017 - accuracy: 0.1074\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8882 - accuracy: 0.1076\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8833 - accuracy: 0.1091\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8828 - accuracy: 0.1093\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8750 - accuracy: 0.1089\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8750 - accuracy: 0.1089\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8688 - accuracy: 0.1092\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8749 - accuracy: 0.1103\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8593 - accuracy: 0.1104\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8605 - accuracy: 0.1098\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8633 - accuracy: 0.1102\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8589 - accuracy: 0.1081\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8531 - accuracy: 0.1086\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8453 - accuracy: 0.1101\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8547 - accuracy: 0.1101\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8515 - accuracy: 0.1091\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8445 - accuracy: 0.1121\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8433 - accuracy: 0.1105\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8445 - accuracy: 0.1101\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8358 - accuracy: 0.1087\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8297 - accuracy: 0.1105\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8244 - accuracy: 0.1142\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8261 - accuracy: 0.1118\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8229 - accuracy: 0.1100\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8210 - accuracy: 0.1117\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8243 - accuracy: 0.1104\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8181 - accuracy: 0.1090\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8148 - accuracy: 0.1105\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8133 - accuracy: 0.1127\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8177 - accuracy: 0.1062\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8053 - accuracy: 0.1088\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7994 - accuracy: 0.1135\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8077 - accuracy: 0.1105\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8113 - accuracy: 0.1102\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7934 - accuracy: 0.1124\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7922 - accuracy: 0.1137\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7886 - accuracy: 0.1137\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7861 - accuracy: 0.1125\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7814 - accuracy: 0.1107\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7838 - accuracy: 0.1120\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7960 - accuracy: 0.1097\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7837 - accuracy: 0.1134\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7746 - accuracy: 0.1119\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7724 - accuracy: 0.1115\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7749 - accuracy: 0.1131\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7589 - accuracy: 0.1130\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7619 - accuracy: 0.1118\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7694 - accuracy: 0.1139\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7622 - accuracy: 0.1129\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7573 - accuracy: 0.1147\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7600 - accuracy: 0.1113\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7407 - accuracy: 0.1138\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7490 - accuracy: 0.1153\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7460 - accuracy: 0.1141\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7521 - accuracy: 0.1115\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7451 - accuracy: 0.1138\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7390 - accuracy: 0.1164\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7377 - accuracy: 0.1157\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7284 - accuracy: 0.1175\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7306 - accuracy: 0.1140\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7327 - accuracy: 0.1162\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7318 - accuracy: 0.1129\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7358 - accuracy: 0.1127\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7251 - accuracy: 0.1155\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7217 - accuracy: 0.1149\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7249 - accuracy: 0.1133\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7264 - accuracy: 0.1122\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7112 - accuracy: 0.1121\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7164 - accuracy: 0.1152\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7025 - accuracy: 0.1175\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7084 - accuracy: 0.1150\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7090 - accuracy: 0.1150\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7016 - accuracy: 0.1155\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6973 - accuracy: 0.1162\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7033 - accuracy: 0.1137\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7025 - accuracy: 0.1142\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6991 - accuracy: 0.1153\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6936 - accuracy: 0.1185\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6961 - accuracy: 0.1160\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6863 - accuracy: 0.1152\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6832 - accuracy: 0.1139\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6787 - accuracy: 0.1178\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6879 - accuracy: 0.1138\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6817 - accuracy: 0.1160\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6741 - accuracy: 0.1141\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6794 - accuracy: 0.1145\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6718 - accuracy: 0.1163\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6708 - accuracy: 0.1151\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6690 - accuracy: 0.1160\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6663 - accuracy: 0.1163\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6657 - accuracy: 0.1160\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6716 - accuracy: 0.1160\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6628 - accuracy: 0.1176\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6695 - accuracy: 0.1144\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6632 - accuracy: 0.1169\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6507 - accuracy: 0.1194\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6506 - accuracy: 0.1195\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.00001)\n",
    "model_bd.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history_bd_adam = model_bd.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hpJg_9rfUI1h",
    "outputId": "90b83669-1dcd-46bb-cbe3-465b52c939b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 95us/step\n",
      "Validation accuracy:  0.2468000054359436\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bd_ad = model_bd.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bd_ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kbBDVn4EWNb2"
   },
   "source": [
    "##### Inference on the above steps:\n",
    "1. Above the Neural Network model was created as said initially.\n",
    "2. The performance of the model when using SGD optimizer was very low on training data but on validation data it was little better still the performance is just 9.7%.\n",
    "2. The performance of the model when using Adam optimizer was very low on training data but on validation data it was around 24.6% only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ItdFc5tzGDV"
   },
   "source": [
    "##### Model - 4: (Trial -2):\n",
    "    Here a Sequential Neural Network model is built by adding the 50% Dropout, BatchNormalization Layer without scaling and shifting parameters turned on, this model is given a selu activation with 'He-normal' weight iniitialization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07Y5BkOizEAe"
   },
   "outputs": [],
   "source": [
    "model_bd = Sequential()\n",
    "\n",
    "model_bd.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "model_bd.add(BatchNormalization())\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "model_bd.add(BatchNormalization())\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "model_bd.add(BatchNormalization())\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "model_bd.add(BatchNormalization( ))\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "model_bd.add(BatchNormalization( ))\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "model_bd.add(BatchNormalization( ))\n",
    "model_bd.add(Activation('selu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(10, name ='Output_Layer'))\n",
    "model_bd.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rSH-EgZlzEAp",
    "outputId": "d73531e9-83a1-48da-a8b1-e64cbbd14b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 33us/step - loss: 3.3711 - accuracy: 0.0994\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3679 - accuracy: 0.0999\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3739 - accuracy: 0.1016\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3806 - accuracy: 0.0996\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3627 - accuracy: 0.1020\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3797 - accuracy: 0.1009\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3907 - accuracy: 0.0973\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3729 - accuracy: 0.0984\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3588 - accuracy: 0.1028\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3662 - accuracy: 0.0976\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3573 - accuracy: 0.1015\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3669 - accuracy: 0.0995\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3535 - accuracy: 0.1001\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3514 - accuracy: 0.1012\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3635 - accuracy: 0.0982\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3583 - accuracy: 0.1019\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3582 - accuracy: 0.0980\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3481 - accuracy: 0.0993\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3607 - accuracy: 0.0993\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3440 - accuracy: 0.0998\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3485 - accuracy: 0.0996\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3567 - accuracy: 0.0991\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3573 - accuracy: 0.1002\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3421 - accuracy: 0.1014\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3470 - accuracy: 0.0978\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3524 - accuracy: 0.0990\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3582 - accuracy: 0.0983\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3414 - accuracy: 0.0988\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3434 - accuracy: 0.1002\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3406 - accuracy: 0.1013\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3314 - accuracy: 0.1031\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3397 - accuracy: 0.1024\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3215 - accuracy: 0.1013\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3493 - accuracy: 0.0995\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3292 - accuracy: 0.1002\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3235 - accuracy: 0.1020\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3254 - accuracy: 0.1014\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3475 - accuracy: 0.0984\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3251 - accuracy: 0.1004\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3426 - accuracy: 0.0949\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3286 - accuracy: 0.1004\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3223 - accuracy: 0.1015\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3350 - accuracy: 0.0998\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3274 - accuracy: 0.0984\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3356 - accuracy: 0.0979\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3261 - accuracy: 0.1001\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3350 - accuracy: 0.0999\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3350 - accuracy: 0.0990\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3332 - accuracy: 0.0972\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3346 - accuracy: 0.0991\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3208 - accuracy: 0.1015\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3126 - accuracy: 0.1008\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3159 - accuracy: 0.1019\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3268 - accuracy: 0.0976\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3074 - accuracy: 0.0993\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3203 - accuracy: 0.1005\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3138 - accuracy: 0.0998\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3114 - accuracy: 0.1000\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3119 - accuracy: 0.1007\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3114 - accuracy: 0.1013\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3117 - accuracy: 0.1000\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3156 - accuracy: 0.1012\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3151 - accuracy: 0.0996\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3284 - accuracy: 0.0972\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3070 - accuracy: 0.0987\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3085 - accuracy: 0.0996\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3120 - accuracy: 0.1013\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3039 - accuracy: 0.0997\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3002 - accuracy: 0.0995\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2994 - accuracy: 0.1027\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2989 - accuracy: 0.1007\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3032 - accuracy: 0.1019\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2958 - accuracy: 0.0999\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3098 - accuracy: 0.1000\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3084 - accuracy: 0.0976\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3006 - accuracy: 0.0997\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.3094 - accuracy: 0.0999\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.3064 - accuracy: 0.0998\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.3107 - accuracy: 0.0999\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2941 - accuracy: 0.1009\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3006 - accuracy: 0.0998\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.3046 - accuracy: 0.1000\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2949 - accuracy: 0.0991\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2963 - accuracy: 0.1014\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2935 - accuracy: 0.0995\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2982 - accuracy: 0.1001\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2771 - accuracy: 0.1002\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2861 - accuracy: 0.1027\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2814 - accuracy: 0.0993\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2900 - accuracy: 0.0978\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2927 - accuracy: 0.1003\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2847 - accuracy: 0.1001\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2921 - accuracy: 0.0999\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2763 - accuracy: 0.0993\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2711 - accuracy: 0.1009\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2842 - accuracy: 0.1003\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2843 - accuracy: 0.1016\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2882 - accuracy: 0.1013\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2781 - accuracy: 0.1011\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2828 - accuracy: 0.0996\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2794 - accuracy: 0.1003\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2888 - accuracy: 0.0977\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2833 - accuracy: 0.0990\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2836 - accuracy: 0.0976\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2685 - accuracy: 0.1012\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2896 - accuracy: 0.0999\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2651 - accuracy: 0.1017\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2718 - accuracy: 0.1000\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2731 - accuracy: 0.1003\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2665 - accuracy: 0.1002\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2655 - accuracy: 0.0995\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2739 - accuracy: 0.1004\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2792 - accuracy: 0.0980\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2905 - accuracy: 0.0977\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2518 - accuracy: 0.1005\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2639 - accuracy: 0.1020\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2692 - accuracy: 0.1014\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2660 - accuracy: 0.1000\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2680 - accuracy: 0.0985\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2559 - accuracy: 0.1004\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2669 - accuracy: 0.1003\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2703 - accuracy: 0.0971\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2665 - accuracy: 0.1002\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2682 - accuracy: 0.1005\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2462 - accuracy: 0.1008\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2659 - accuracy: 0.1004\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2618 - accuracy: 0.1012\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2620 - accuracy: 0.0984\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2635 - accuracy: 0.0979\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2697 - accuracy: 0.0980\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2512 - accuracy: 0.1012\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2474 - accuracy: 0.1003\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2521 - accuracy: 0.0985\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2547 - accuracy: 0.0984\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2612 - accuracy: 0.0980\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2406 - accuracy: 0.1005\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2634 - accuracy: 0.1014\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2335 - accuracy: 0.1019\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2475 - accuracy: 0.1014\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2380 - accuracy: 0.0990\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2499 - accuracy: 0.1005\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2437 - accuracy: 0.1004\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2491 - accuracy: 0.0992\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2400 - accuracy: 0.1016\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2373 - accuracy: 0.0994\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2407 - accuracy: 0.1005\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2486 - accuracy: 0.0974\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2360 - accuracy: 0.0988\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2368 - accuracy: 0.0989\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2437 - accuracy: 0.0982\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2452 - accuracy: 0.0985\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2349 - accuracy: 0.0995\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2314 - accuracy: 0.1003\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2365 - accuracy: 0.1008\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2410 - accuracy: 0.1008\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2267 - accuracy: 0.0993\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2392 - accuracy: 0.0977\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2227 - accuracy: 0.1021\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2232 - accuracy: 0.1028\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2274 - accuracy: 0.1009\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2366 - accuracy: 0.0989\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2255 - accuracy: 0.1014\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2233 - accuracy: 0.1012\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2304 - accuracy: 0.0977\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2264 - accuracy: 0.1003\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2260 - accuracy: 0.0983\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2221 - accuracy: 0.1008\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2248 - accuracy: 0.1029\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2340 - accuracy: 0.1004\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2369 - accuracy: 0.1012\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2133 - accuracy: 0.1006\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2340 - accuracy: 0.1007\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2204 - accuracy: 0.0992\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2144 - accuracy: 0.1001\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2119 - accuracy: 0.1010\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2087 - accuracy: 0.1016\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2198 - accuracy: 0.0991\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2125 - accuracy: 0.1008\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2262 - accuracy: 0.1002\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2070 - accuracy: 0.1040\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2244 - accuracy: 0.0989\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2094 - accuracy: 0.1005\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2131 - accuracy: 0.1012\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2061 - accuracy: 0.1018\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 3.2094 - accuracy: 0.1007\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2201 - accuracy: 0.0986\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2055 - accuracy: 0.0987\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 3.2094 - accuracy: 0.1003\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2130 - accuracy: 0.1007\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2093 - accuracy: 0.0998\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.1937 - accuracy: 0.1010\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2060 - accuracy: 0.1000\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2124 - accuracy: 0.0997\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.1986 - accuracy: 0.1028\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.1925 - accuracy: 0.0990\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2086 - accuracy: 0.0988\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2059 - accuracy: 0.0986\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2018 - accuracy: 0.0986\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.1978 - accuracy: 0.1009\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 3.2011 - accuracy: 0.1004\n"
     ]
    }
   ],
   "source": [
    "model_bd.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_bd = model_bd.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YNCnGRz5zEA1",
    "outputId": "e82fa56a-ad81-48ac-b1e4-babf221efc04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 98us/step\n",
      "Validation accuracy:  0.1099499985575676\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bd = model_bd.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bd[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us also try optimizing the model with Adam optimizer then configure the model with loss function and metrices, train the modela and evaluate the model performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aiWiftpazEA9",
    "outputId": "781aa1f5-4044-4150-8858-1b752a516319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 2s 37us/step - loss: 3.3609 - accuracy: 0.0999\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.3529 - accuracy: 0.1008\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.3607 - accuracy: 0.0994\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.3334 - accuracy: 0.1020\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.3504 - accuracy: 0.0984\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.3361 - accuracy: 0.1018\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.3264 - accuracy: 0.0991\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3190 - accuracy: 0.1025\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3092 - accuracy: 0.1021\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3012 - accuracy: 0.1022\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2988 - accuracy: 0.1029\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2917 - accuracy: 0.1042\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2860 - accuracy: 0.1025\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2760 - accuracy: 0.1041\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2763 - accuracy: 0.1013\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2597 - accuracy: 0.1016\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2485 - accuracy: 0.1060\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2491 - accuracy: 0.1039\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2411 - accuracy: 0.1026\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2324 - accuracy: 0.1026\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2206 - accuracy: 0.1048\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2130 - accuracy: 0.1040\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2136 - accuracy: 0.1041\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2014 - accuracy: 0.1030\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2111 - accuracy: 0.1025\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1966 - accuracy: 0.1009\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1869 - accuracy: 0.1050\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1812 - accuracy: 0.1054\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1731 - accuracy: 0.1064\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1789 - accuracy: 0.1035\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1593 - accuracy: 0.1035\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1565 - accuracy: 0.1047\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1644 - accuracy: 0.1050\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1361 - accuracy: 0.1057\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1366 - accuracy: 0.1050\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1259 - accuracy: 0.1055\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1368 - accuracy: 0.1042\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1168 - accuracy: 0.1069\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1233 - accuracy: 0.1060\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1064 - accuracy: 0.1056\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1128 - accuracy: 0.1067\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1032 - accuracy: 0.1044\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1092 - accuracy: 0.1047\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0896 - accuracy: 0.1067\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0968 - accuracy: 0.1064\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0914 - accuracy: 0.1057\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0712 - accuracy: 0.1091\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0698 - accuracy: 0.1061\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0760 - accuracy: 0.1051\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.0519 - accuracy: 0.1065\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0631 - accuracy: 0.1058\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0558 - accuracy: 0.1066\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0420 - accuracy: 0.1066\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0418 - accuracy: 0.1074\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0380 - accuracy: 0.1085\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0307 - accuracy: 0.1087\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0363 - accuracy: 0.1063\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0227 - accuracy: 0.1062\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0304 - accuracy: 0.1077\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0248 - accuracy: 0.1081\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0090 - accuracy: 0.1074\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.0049 - accuracy: 0.1101\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0021 - accuracy: 0.1074\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0055 - accuracy: 0.1057\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0009 - accuracy: 0.1108\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9969 - accuracy: 0.1056\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9990 - accuracy: 0.1066\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9761 - accuracy: 0.1092\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9840 - accuracy: 0.1070\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9687 - accuracy: 0.1069\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9687 - accuracy: 0.1077\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9670 - accuracy: 0.1078\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9681 - accuracy: 0.1078\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9573 - accuracy: 0.1114\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9548 - accuracy: 0.1077\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9635 - accuracy: 0.1072\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9525 - accuracy: 0.1087\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9452 - accuracy: 0.1082\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9245 - accuracy: 0.1094\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9411 - accuracy: 0.1100\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9314 - accuracy: 0.1089\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9314 - accuracy: 0.1089\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9197 - accuracy: 0.1120\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9174 - accuracy: 0.1114\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9194 - accuracy: 0.1105\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9137 - accuracy: 0.1088\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9087 - accuracy: 0.1098\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9015 - accuracy: 0.1105\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8913 - accuracy: 0.1117\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9090 - accuracy: 0.1087\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8830 - accuracy: 0.1117\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8826 - accuracy: 0.1145\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8879 - accuracy: 0.1103\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8867 - accuracy: 0.1120\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8827 - accuracy: 0.1114\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8784 - accuracy: 0.1135\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8747 - accuracy: 0.1116\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8798 - accuracy: 0.1086\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8734 - accuracy: 0.1091\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8740 - accuracy: 0.1111\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8654 - accuracy: 0.1101\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8544 - accuracy: 0.1085\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8443 - accuracy: 0.1109\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8607 - accuracy: 0.1116\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8430 - accuracy: 0.1135\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8461 - accuracy: 0.1121\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8323 - accuracy: 0.1124\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8382 - accuracy: 0.1135\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8246 - accuracy: 0.1138\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8317 - accuracy: 0.1119\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8221 - accuracy: 0.1158\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8295 - accuracy: 0.1118\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8314 - accuracy: 0.1108\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8184 - accuracy: 0.1121\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8272 - accuracy: 0.1091\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8101 - accuracy: 0.1136\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8104 - accuracy: 0.1120\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8121 - accuracy: 0.1112\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8110 - accuracy: 0.1107\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7961 - accuracy: 0.1132\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8018 - accuracy: 0.1143\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7910 - accuracy: 0.1175\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7852 - accuracy: 0.1150\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7889 - accuracy: 0.1156\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7865 - accuracy: 0.1160\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7855 - accuracy: 0.1119\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7748 - accuracy: 0.1155\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7784 - accuracy: 0.1149\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7785 - accuracy: 0.1138\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7794 - accuracy: 0.1128\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7646 - accuracy: 0.1144\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7673 - accuracy: 0.1145\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7645 - accuracy: 0.1153\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7617 - accuracy: 0.1138\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7611 - accuracy: 0.1142\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7644 - accuracy: 0.1129\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7551 - accuracy: 0.1170\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7529 - accuracy: 0.1159\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7537 - accuracy: 0.1120\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7472 - accuracy: 0.1166\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7409 - accuracy: 0.1168\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7411 - accuracy: 0.1159\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7288 - accuracy: 0.1171\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7399 - accuracy: 0.1171\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7305 - accuracy: 0.1148\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7240 - accuracy: 0.1193\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7323 - accuracy: 0.1154\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7246 - accuracy: 0.1156\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7217 - accuracy: 0.1165\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7184 - accuracy: 0.1170\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7257 - accuracy: 0.1115\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7168 - accuracy: 0.1156\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7170 - accuracy: 0.1164\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7083 - accuracy: 0.1161\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7046 - accuracy: 0.1158\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7132 - accuracy: 0.1145\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7034 - accuracy: 0.1150\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7008 - accuracy: 0.1190\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7065 - accuracy: 0.1169\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6949 - accuracy: 0.1168\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6868 - accuracy: 0.1158\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6898 - accuracy: 0.1177\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6934 - accuracy: 0.1170\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6835 - accuracy: 0.1164\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6857 - accuracy: 0.1184\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6827 - accuracy: 0.1176\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6778 - accuracy: 0.1179\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6827 - accuracy: 0.1163\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6796 - accuracy: 0.1155\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6792 - accuracy: 0.1198\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6731 - accuracy: 0.1165\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6699 - accuracy: 0.1183\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6695 - accuracy: 0.1203\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6612 - accuracy: 0.1177\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6657 - accuracy: 0.1174\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6590 - accuracy: 0.1163\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6582 - accuracy: 0.1181\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6550 - accuracy: 0.1172\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6538 - accuracy: 0.1172\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6483 - accuracy: 0.1192\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6509 - accuracy: 0.1176\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6409 - accuracy: 0.1193\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6461 - accuracy: 0.1191\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6418 - accuracy: 0.1195\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6495 - accuracy: 0.1194\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6316 - accuracy: 0.1187\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6359 - accuracy: 0.1194\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6355 - accuracy: 0.1201\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6320 - accuracy: 0.1201\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6213 - accuracy: 0.1226\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6376 - accuracy: 0.1178\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6231 - accuracy: 0.1195\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6279 - accuracy: 0.1210\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6262 - accuracy: 0.1175\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6234 - accuracy: 0.1182\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6210 - accuracy: 0.1191\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6162 - accuracy: 0.1216\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6129 - accuracy: 0.1220\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6158 - accuracy: 0.1171\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6089 - accuracy: 0.1206\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.00001)\n",
    "model_bd.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history_bd_adam = model_bd.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Twjd-NmXzEBE",
    "outputId": "fc0283e9-13f6-4b28-bc4f-54e860c9639b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 96us/step\n",
      "Validation accuracy:  0.2565166652202606\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bd_ad = model_bd.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bd_ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. Above the Neural Network model was created as said initially.\n",
    "2. The performance of the model when using SGD optimizer was very low on training data but on validation data it was little better still the performance is just 10.9%.\n",
    "2. The performance of the model when using Adam optimizer was very low on training data but on validation data it was around 25.65% only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wLBDVp_zdjd"
   },
   "source": [
    "##### Model - 4: (Trial -3):\n",
    "    Here a Sequential Neural Network model is built by adding the 50% Dropout, BatchNormalization Layer with scaling and shifting parameters turned on, this model is given a relu activation with 'He-normal' weight iniitialization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-H0Q_hz5zl-c"
   },
   "outputs": [],
   "source": [
    "model_bd = Sequential()\n",
    "\n",
    "model_bd.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True))\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "model_bd.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(10, name ='Output_Layer'))\n",
    "model_bd.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cwZG85swzl-n",
    "outputId": "042b7495-b482-4fcb-817f-aabaa7338d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 2.7465 - accuracy: 0.1019\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7366 - accuracy: 0.1022\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7402 - accuracy: 0.0987\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7321 - accuracy: 0.0991\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7415 - accuracy: 0.0988\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7350 - accuracy: 0.1025\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7386 - accuracy: 0.1021\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7478 - accuracy: 0.0983\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7270 - accuracy: 0.1026\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7346 - accuracy: 0.1011\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7302 - accuracy: 0.0996\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7437 - accuracy: 0.0992\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7439 - accuracy: 0.0996\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7376 - accuracy: 0.1010\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7440 - accuracy: 0.0995\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7353 - accuracy: 0.1010\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7368 - accuracy: 0.0995\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7307 - accuracy: 0.1010\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7311 - accuracy: 0.0971\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7418 - accuracy: 0.0993\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7256 - accuracy: 0.1014\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7319 - accuracy: 0.0998\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7332 - accuracy: 0.1023\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7337 - accuracy: 0.0998\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7408 - accuracy: 0.0994\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7335 - accuracy: 0.1009\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7354 - accuracy: 0.1021\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7412 - accuracy: 0.0983\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7331 - accuracy: 0.1014\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7413 - accuracy: 0.0981\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7318 - accuracy: 0.0991\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7384 - accuracy: 0.1004\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7245 - accuracy: 0.1008\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7323 - accuracy: 0.0997\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7419 - accuracy: 0.0979\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7415 - accuracy: 0.0998\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7494 - accuracy: 0.0960\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7377 - accuracy: 0.0983\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7309 - accuracy: 0.0993\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7276 - accuracy: 0.1013\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7338 - accuracy: 0.1000\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7305 - accuracy: 0.1001\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7246 - accuracy: 0.1016\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7321 - accuracy: 0.1006\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7456 - accuracy: 0.0979\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7359 - accuracy: 0.0965\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7272 - accuracy: 0.0996\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7509 - accuracy: 0.0952\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7279 - accuracy: 0.1008\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7295 - accuracy: 0.1000\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7297 - accuracy: 0.0976\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7341 - accuracy: 0.0999\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7312 - accuracy: 0.0984\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7288 - accuracy: 0.1010\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7263 - accuracy: 0.1003\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7285 - accuracy: 0.0979\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7295 - accuracy: 0.0990\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7275 - accuracy: 0.1002\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7319 - accuracy: 0.1000\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7341 - accuracy: 0.0990\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7167 - accuracy: 0.1001\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7402 - accuracy: 0.0979\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7303 - accuracy: 0.0985\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7348 - accuracy: 0.0995\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7286 - accuracy: 0.0989\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7260 - accuracy: 0.1000\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7221 - accuracy: 0.1020\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7325 - accuracy: 0.0987\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7337 - accuracy: 0.0980\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7295 - accuracy: 0.0990\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7256 - accuracy: 0.0998\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7137 - accuracy: 0.1023\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7235 - accuracy: 0.0994\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7241 - accuracy: 0.0977\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7251 - accuracy: 0.1001\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7237 - accuracy: 0.0985\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7155 - accuracy: 0.1008\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7210 - accuracy: 0.0978\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7190 - accuracy: 0.0987\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7230 - accuracy: 0.0987\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7279 - accuracy: 0.1009\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7250 - accuracy: 0.0965\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7214 - accuracy: 0.0978\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7264 - accuracy: 0.1009\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7325 - accuracy: 0.0979\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7248 - accuracy: 0.0979\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7149 - accuracy: 0.1008\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7215 - accuracy: 0.0983\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7206 - accuracy: 0.1012\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7270 - accuracy: 0.0979\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7228 - accuracy: 0.1029\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7193 - accuracy: 0.0986\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7181 - accuracy: 0.1002\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7243 - accuracy: 0.0975\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7221 - accuracy: 0.1014\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7153 - accuracy: 0.1004\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7217 - accuracy: 0.1015\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7199 - accuracy: 0.1007\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7118 - accuracy: 0.1002\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7133 - accuracy: 0.1000\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7132 - accuracy: 0.1021\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7280 - accuracy: 0.0980\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7227 - accuracy: 0.0975\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7133 - accuracy: 0.0978\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7144 - accuracy: 0.0994\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7230 - accuracy: 0.0992\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7066 - accuracy: 0.1003\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7118 - accuracy: 0.1009\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7208 - accuracy: 0.0980\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7122 - accuracy: 0.1013\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7172 - accuracy: 0.0992\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7199 - accuracy: 0.0997\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7093 - accuracy: 0.0989\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7197 - accuracy: 0.0990\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7167 - accuracy: 0.1004\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7171 - accuracy: 0.0994\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7089 - accuracy: 0.0980\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7161 - accuracy: 0.1017\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7141 - accuracy: 0.1000\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7069 - accuracy: 0.0996\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7153 - accuracy: 0.0991\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7159 - accuracy: 0.0996\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7169 - accuracy: 0.1006\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7034 - accuracy: 0.0978\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7073 - accuracy: 0.1042\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7143 - accuracy: 0.0990\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7104 - accuracy: 0.1018\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7136 - accuracy: 0.1003\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7108 - accuracy: 0.1000\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7112 - accuracy: 0.0987\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7107 - accuracy: 0.0971\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7050 - accuracy: 0.1017\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7173 - accuracy: 0.0961\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7026 - accuracy: 0.1014\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7012 - accuracy: 0.0985\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7064 - accuracy: 0.0979\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7093 - accuracy: 0.0995\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6944 - accuracy: 0.1028\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7057 - accuracy: 0.1004\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7106 - accuracy: 0.0983\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7089 - accuracy: 0.1010\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7138 - accuracy: 0.0993\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7102 - accuracy: 0.0965\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7065 - accuracy: 0.0982\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7181 - accuracy: 0.0962\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7095 - accuracy: 0.0989\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7078 - accuracy: 0.0976\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7005 - accuracy: 0.1000\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7053 - accuracy: 0.0980\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7075 - accuracy: 0.0992\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7063 - accuracy: 0.1008\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7068 - accuracy: 0.0997\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7054 - accuracy: 0.0985\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7078 - accuracy: 0.0993\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6990 - accuracy: 0.1017\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7040 - accuracy: 0.0975\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6995 - accuracy: 0.1006\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7052 - accuracy: 0.0975\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7049 - accuracy: 0.0987\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7057 - accuracy: 0.1009\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7049 - accuracy: 0.0989\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7006 - accuracy: 0.0985\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7004 - accuracy: 0.1017\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7098 - accuracy: 0.0993\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6965 - accuracy: 0.0993\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7044 - accuracy: 0.0985\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6992 - accuracy: 0.1015\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7050 - accuracy: 0.0996\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6977 - accuracy: 0.1010\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6977 - accuracy: 0.0993\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6900 - accuracy: 0.1018\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7025 - accuracy: 0.0997\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7013 - accuracy: 0.1013\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7032 - accuracy: 0.0982\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6997 - accuracy: 0.0993\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6993 - accuracy: 0.0991\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7015 - accuracy: 0.0985\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6968 - accuracy: 0.1000\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6945 - accuracy: 0.1013\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7077 - accuracy: 0.0974\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6949 - accuracy: 0.0998\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6919 - accuracy: 0.1005\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7016 - accuracy: 0.0993\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6903 - accuracy: 0.1034\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.6955 - accuracy: 0.0987\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6914 - accuracy: 0.1020\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7024 - accuracy: 0.0982\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7018 - accuracy: 0.0957\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6943 - accuracy: 0.1008\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7012 - accuracy: 0.1014\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6892 - accuracy: 0.1006\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7047 - accuracy: 0.0968\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6916 - accuracy: 0.1031\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7053 - accuracy: 0.1002\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6996 - accuracy: 0.0990\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6926 - accuracy: 0.0999\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6977 - accuracy: 0.1002\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.6943 - accuracy: 0.0997\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6930 - accuracy: 0.0993\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.6916 - accuracy: 0.1003\n"
     ]
    }
   ],
   "source": [
    "model_bd.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_bd = model_bd.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yRf1zuPEzl-u",
    "outputId": "9285601e-e9b2-4119-9600-51092721a4ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 97us/step\n",
      "Validation accuracy:  0.10353333503007889\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bd = model_bd.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bd[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us also try optimizing the model with Adam optimizer then configure the model with loss function and metrices, train the modela and evaluate the model performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QV5nm1Nazl-2",
    "outputId": "12374af3-73a5-41f7-fd62-d4d28afb5889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 33us/step - loss: 2.8968 - accuracy: 0.1009\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8899 - accuracy: 0.1003\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8694 - accuracy: 0.1004\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8706 - accuracy: 0.1009\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8770 - accuracy: 0.0994\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8633 - accuracy: 0.0989\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8541 - accuracy: 0.1008\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8396 - accuracy: 0.1032\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8470 - accuracy: 0.1018\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8367 - accuracy: 0.1020\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8329 - accuracy: 0.1021\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8299 - accuracy: 0.1015\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8240 - accuracy: 0.1015\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8186 - accuracy: 0.1006\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8037 - accuracy: 0.0994\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8052 - accuracy: 0.1011\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7906 - accuracy: 0.1060\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.7979 - accuracy: 0.1029\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7922 - accuracy: 0.0992\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7886 - accuracy: 0.0987\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7793 - accuracy: 0.1021\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7724 - accuracy: 0.1007\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7591 - accuracy: 0.1015\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7606 - accuracy: 0.1028\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7523 - accuracy: 0.1019\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7488 - accuracy: 0.1038\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7441 - accuracy: 0.1029\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7431 - accuracy: 0.1023\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7339 - accuracy: 0.1016\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7307 - accuracy: 0.1005\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7308 - accuracy: 0.1036\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7166 - accuracy: 0.1005\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7206 - accuracy: 0.1010\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7179 - accuracy: 0.0994\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7168 - accuracy: 0.1029\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7036 - accuracy: 0.1005\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7054 - accuracy: 0.0990\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6998 - accuracy: 0.1027\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7048 - accuracy: 0.1032\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6910 - accuracy: 0.1028\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6913 - accuracy: 0.1039\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6905 - accuracy: 0.1010\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6843 - accuracy: 0.0991\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6724 - accuracy: 0.1005\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6790 - accuracy: 0.1020\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6703 - accuracy: 0.1009\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6648 - accuracy: 0.0988\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6665 - accuracy: 0.1020\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6587 - accuracy: 0.1023\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6624 - accuracy: 0.1007\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6624 - accuracy: 0.1011\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6506 - accuracy: 0.1045\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6503 - accuracy: 0.1044\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6507 - accuracy: 0.1026\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6379 - accuracy: 0.1042\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6404 - accuracy: 0.1011\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6489 - accuracy: 0.1017\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6462 - accuracy: 0.0993\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6392 - accuracy: 0.1000\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6376 - accuracy: 0.1025\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6282 - accuracy: 0.1004\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.6347 - accuracy: 0.1016\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6189 - accuracy: 0.1039\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6271 - accuracy: 0.1006\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.6159 - accuracy: 0.1018\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6204 - accuracy: 0.1018\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6195 - accuracy: 0.1006\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6089 - accuracy: 0.1017\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6051 - accuracy: 0.1019\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6088 - accuracy: 0.1005\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6089 - accuracy: 0.1027\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6086 - accuracy: 0.1023\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5997 - accuracy: 0.1016\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5950 - accuracy: 0.1034\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5977 - accuracy: 0.1039\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5997 - accuracy: 0.1019\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6006 - accuracy: 0.1008\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5991 - accuracy: 0.1027\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5879 - accuracy: 0.1012\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5830 - accuracy: 0.1032\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5898 - accuracy: 0.1016\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5898 - accuracy: 0.1008\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5721 - accuracy: 0.1035\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.5783 - accuracy: 0.1008\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5886 - accuracy: 0.1003\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5721 - accuracy: 0.1025\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5759 - accuracy: 0.1056\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5715 - accuracy: 0.1018\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.5691 - accuracy: 0.1023\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5739 - accuracy: 0.1027\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5646 - accuracy: 0.1033\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5627 - accuracy: 0.1030\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5564 - accuracy: 0.1033\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5659 - accuracy: 0.1037\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5575 - accuracy: 0.1023\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5576 - accuracy: 0.1041\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5499 - accuracy: 0.1012\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5589 - accuracy: 0.1039\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5506 - accuracy: 0.1036\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5507 - accuracy: 0.1002\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5556 - accuracy: 0.1012\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5502 - accuracy: 0.1018\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5523 - accuracy: 0.0999\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.5457 - accuracy: 0.1016\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5439 - accuracy: 0.1025\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5372 - accuracy: 0.1015\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5438 - accuracy: 0.1020\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5388 - accuracy: 0.1022\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5401 - accuracy: 0.1015\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5272 - accuracy: 0.1031\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5295 - accuracy: 0.1037\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5338 - accuracy: 0.1045\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5301 - accuracy: 0.1030\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5257 - accuracy: 0.1057\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5304 - accuracy: 0.1043\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5296 - accuracy: 0.1025\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5277 - accuracy: 0.1032\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5196 - accuracy: 0.1046\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5231 - accuracy: 0.1039\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5149 - accuracy: 0.1025\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5286 - accuracy: 0.1053\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5123 - accuracy: 0.1042\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5132 - accuracy: 0.1033\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5135 - accuracy: 0.1043\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5073 - accuracy: 0.1045\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5160 - accuracy: 0.1007\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5077 - accuracy: 0.1030\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5082 - accuracy: 0.1060\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5084 - accuracy: 0.1016\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4975 - accuracy: 0.1024\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5008 - accuracy: 0.1043\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5027 - accuracy: 0.1035\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4976 - accuracy: 0.1056\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4966 - accuracy: 0.1074\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5018 - accuracy: 0.1024\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5039 - accuracy: 0.1040\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4931 - accuracy: 0.1008\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4951 - accuracy: 0.1043\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4952 - accuracy: 0.1028\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4910 - accuracy: 0.1031\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4917 - accuracy: 0.1052\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4875 - accuracy: 0.1031\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4840 - accuracy: 0.1020\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4908 - accuracy: 0.1037\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4917 - accuracy: 0.0995\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4921 - accuracy: 0.1025\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4912 - accuracy: 0.1034\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4812 - accuracy: 0.1044\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4804 - accuracy: 0.1035\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4840 - accuracy: 0.1028\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4850 - accuracy: 0.1027\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4764 - accuracy: 0.1063\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4773 - accuracy: 0.1043\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4706 - accuracy: 0.1056\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4779 - accuracy: 0.1065\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4768 - accuracy: 0.1034\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4719 - accuracy: 0.1053\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4754 - accuracy: 0.1027\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4688 - accuracy: 0.1031\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4723 - accuracy: 0.1036\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4661 - accuracy: 0.1030\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4704 - accuracy: 0.1030\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4658 - accuracy: 0.1051\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4672 - accuracy: 0.1051\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4658 - accuracy: 0.1058\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4591 - accuracy: 0.1045\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4668 - accuracy: 0.1026\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4644 - accuracy: 0.1029\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4554 - accuracy: 0.1036\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4552 - accuracy: 0.1044\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4557 - accuracy: 0.1057\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4554 - accuracy: 0.1060\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4520 - accuracy: 0.1035\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4528 - accuracy: 0.1049\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4560 - accuracy: 0.1045\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4523 - accuracy: 0.1074\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4490 - accuracy: 0.1049\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4509 - accuracy: 0.1045\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4475 - accuracy: 0.1042\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4527 - accuracy: 0.1042\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4461 - accuracy: 0.1058\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4481 - accuracy: 0.1039\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4450 - accuracy: 0.1068\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4451 - accuracy: 0.1077\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4493 - accuracy: 0.1050\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4369 - accuracy: 0.1069\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4379 - accuracy: 0.1058\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4399 - accuracy: 0.1050\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4393 - accuracy: 0.1053\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4388 - accuracy: 0.1065\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4397 - accuracy: 0.1049\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4320 - accuracy: 0.1061\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4305 - accuracy: 0.1038\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4337 - accuracy: 0.1043\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4313 - accuracy: 0.1044\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4405 - accuracy: 0.1038\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4290 - accuracy: 0.1062\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4251 - accuracy: 0.1041\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4259 - accuracy: 0.1091\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4302 - accuracy: 0.1065\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.00001)\n",
    "model_bd.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history_bd_adam = model_bd.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7-7A7hWRzl_C",
    "outputId": "9d440a3e-3f3d-4dfd-b3ce-895f0cb042fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 101us/step\n",
      "Validation accuracy:  0.13003332912921906\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bd_ad = model_bd.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bd_ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. Above the Neural Network model was created as said initially.\n",
    "2. The performance of the model when using SGD optimizer was very low on training data but on validation data it was little better still the performance is just 10.35%.\n",
    "2. The performance of the model when using Adam optimizer was very low on training data but on validation data it was around 13.003% only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lr6vf1ps0cp8"
   },
   "source": [
    "##### Model - 4: (Trial -4):\n",
    "    Here a Sequential Neural Network model is built by adding the 50% Dropout, BatchNormalization Layer without scaling and shifting parameters turned on, this model is given a relu activation with 'He-normal' weight iniitialization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTyYfq1m0cqG"
   },
   "outputs": [],
   "source": [
    "model_bd = Sequential()\n",
    "\n",
    "model_bd.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "model_bd.add(BatchNormalization())\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "model_bd.add(BatchNormalization( ))\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "model_bd.add(BatchNormalization())\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "model_bd.add(BatchNormalization())\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "model_bd.add(BatchNormalization())\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "model_bd.add(BatchNormalization( ))\n",
    "model_bd.add(Activation('relu'))\n",
    "model_bd.add(Dropout(0.5))\n",
    "\n",
    "model_bd.add(Dense(10, name ='Output_Layer'))\n",
    "model_bd.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "b0tmb-h00cqP",
    "outputId": "6c85f3cd-86bf-4976-aecf-2878d3d6f8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 2.8023 - accuracy: 0.1015\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8062 - accuracy: 0.0996\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7952 - accuracy: 0.1013\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.8032 - accuracy: 0.1000\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.8013 - accuracy: 0.1020\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8104 - accuracy: 0.1000\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8049 - accuracy: 0.1011\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7973 - accuracy: 0.1027\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8072 - accuracy: 0.1007\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8024 - accuracy: 0.0996\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8049 - accuracy: 0.1000\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8108 - accuracy: 0.0977\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8031 - accuracy: 0.1018\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8033 - accuracy: 0.0986\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8082 - accuracy: 0.0992\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7997 - accuracy: 0.1010\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7936 - accuracy: 0.0993\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.8047 - accuracy: 0.0992\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7933 - accuracy: 0.1021\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.8011 - accuracy: 0.0992\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8113 - accuracy: 0.0973\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7901 - accuracy: 0.0994\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.8075 - accuracy: 0.0997\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7935 - accuracy: 0.1024\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7944 - accuracy: 0.0981\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7937 - accuracy: 0.1024\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7945 - accuracy: 0.1003\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7933 - accuracy: 0.0987\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8022 - accuracy: 0.0993\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7951 - accuracy: 0.1011\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8004 - accuracy: 0.0972\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7926 - accuracy: 0.1017\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7940 - accuracy: 0.1007\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7974 - accuracy: 0.1008\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7877 - accuracy: 0.1004\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7909 - accuracy: 0.0991\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7940 - accuracy: 0.0993\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7941 - accuracy: 0.0990\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7991 - accuracy: 0.1005\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.8001 - accuracy: 0.0996\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7962 - accuracy: 0.0982\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7898 - accuracy: 0.1010\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7920 - accuracy: 0.1018\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7978 - accuracy: 0.1002\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7895 - accuracy: 0.1004\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7927 - accuracy: 0.0995\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7832 - accuracy: 0.0991\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7899 - accuracy: 0.0989\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7892 - accuracy: 0.1016\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7845 - accuracy: 0.1003\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7923 - accuracy: 0.1004\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7805 - accuracy: 0.1012\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7905 - accuracy: 0.1006\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7922 - accuracy: 0.0982\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7963 - accuracy: 0.1000\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7917 - accuracy: 0.0991\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7952 - accuracy: 0.0976\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7852 - accuracy: 0.0985\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7916 - accuracy: 0.0995\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7867 - accuracy: 0.0994\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7814 - accuracy: 0.1012\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7759 - accuracy: 0.1023\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7978 - accuracy: 0.1016\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7893 - accuracy: 0.0984\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7838 - accuracy: 0.0994\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7885 - accuracy: 0.0961\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7863 - accuracy: 0.0994\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7885 - accuracy: 0.0976\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7815 - accuracy: 0.0994\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7853 - accuracy: 0.0984\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7854 - accuracy: 0.0995\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7819 - accuracy: 0.1017\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7907 - accuracy: 0.0977\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7807 - accuracy: 0.0993\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7861 - accuracy: 0.1008\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7740 - accuracy: 0.1020\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7762 - accuracy: 0.1001\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7723 - accuracy: 0.1025\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7840 - accuracy: 0.0969\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7797 - accuracy: 0.0989\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7790 - accuracy: 0.0998\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7875 - accuracy: 0.1010\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7700 - accuracy: 0.1027\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7798 - accuracy: 0.1012\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7830 - accuracy: 0.0997\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7869 - accuracy: 0.0996\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7832 - accuracy: 0.1000\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7752 - accuracy: 0.0968\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7750 - accuracy: 0.1023\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7737 - accuracy: 0.0984\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7700 - accuracy: 0.1019\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7668 - accuracy: 0.1000\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7737 - accuracy: 0.1014\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7706 - accuracy: 0.1006\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7754 - accuracy: 0.1006\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7746 - accuracy: 0.1025\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7767 - accuracy: 0.0996\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7708 - accuracy: 0.0979\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7723 - accuracy: 0.0998\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7674 - accuracy: 0.0995\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7814 - accuracy: 0.1017\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7782 - accuracy: 0.1014\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7636 - accuracy: 0.1000\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7709 - accuracy: 0.0994\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7731 - accuracy: 0.0985\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7724 - accuracy: 0.1011\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7681 - accuracy: 0.1014\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7735 - accuracy: 0.1008\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7757 - accuracy: 0.1017\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7602 - accuracy: 0.0968\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7671 - accuracy: 0.1004\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7714 - accuracy: 0.0988\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7775 - accuracy: 0.1005\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7728 - accuracy: 0.0990\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7736 - accuracy: 0.1001\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7634 - accuracy: 0.0992\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7689 - accuracy: 0.1014\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7635 - accuracy: 0.1008\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7693 - accuracy: 0.1015\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7734 - accuracy: 0.0992\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7741 - accuracy: 0.0984\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7620 - accuracy: 0.0998\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7618 - accuracy: 0.1004\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7559 - accuracy: 0.1014\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7596 - accuracy: 0.1017\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7636 - accuracy: 0.1000\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7618 - accuracy: 0.1009\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7661 - accuracy: 0.1000\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7646 - accuracy: 0.1012\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7621 - accuracy: 0.0995\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7697 - accuracy: 0.0973\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7601 - accuracy: 0.1010\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7717 - accuracy: 0.0974\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7621 - accuracy: 0.0995\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7628 - accuracy: 0.1000\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7564 - accuracy: 0.0990\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7599 - accuracy: 0.0996\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7537 - accuracy: 0.1014\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7723 - accuracy: 0.0969\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7621 - accuracy: 0.0988\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7637 - accuracy: 0.0979\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7594 - accuracy: 0.1014\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7616 - accuracy: 0.0983\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7599 - accuracy: 0.0997\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7591 - accuracy: 0.0994\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7548 - accuracy: 0.1002\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7607 - accuracy: 0.1014\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7602 - accuracy: 0.0998\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7603 - accuracy: 0.0986\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7503 - accuracy: 0.1021\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7501 - accuracy: 0.1003\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7583 - accuracy: 0.1011\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7580 - accuracy: 0.0985\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7533 - accuracy: 0.1012\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7528 - accuracy: 0.0983\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7573 - accuracy: 0.0983\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7588 - accuracy: 0.0997\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7587 - accuracy: 0.0988\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7577 - accuracy: 0.0997\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7546 - accuracy: 0.0977\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7513 - accuracy: 0.0975\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7415 - accuracy: 0.1020\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7491 - accuracy: 0.0992\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7445 - accuracy: 0.1001\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7519 - accuracy: 0.1007\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7528 - accuracy: 0.0978\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7554 - accuracy: 0.1004\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7423 - accuracy: 0.0994\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7524 - accuracy: 0.1025\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7471 - accuracy: 0.1034\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7573 - accuracy: 0.1013\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7494 - accuracy: 0.0995\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7457 - accuracy: 0.1027\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7455 - accuracy: 0.1025\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7479 - accuracy: 0.1006\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7485 - accuracy: 0.0995\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7478 - accuracy: 0.0995\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7494 - accuracy: 0.0994\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7533 - accuracy: 0.0996\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7567 - accuracy: 0.1000\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7478 - accuracy: 0.0995\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7370 - accuracy: 0.1012\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7414 - accuracy: 0.1009\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7469 - accuracy: 0.0975\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7563 - accuracy: 0.0985\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7472 - accuracy: 0.0989\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7371 - accuracy: 0.1004\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7401 - accuracy: 0.0992\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7548 - accuracy: 0.0966\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7488 - accuracy: 0.0986\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7426 - accuracy: 0.1018\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7361 - accuracy: 0.0998\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7564 - accuracy: 0.1002\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7401 - accuracy: 0.1003\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7507 - accuracy: 0.0978\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 2.7351 - accuracy: 0.1016\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 2.7412 - accuracy: 0.0997\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7462 - accuracy: 0.1008\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.7399 - accuracy: 0.0987\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7440 - accuracy: 0.0995\n"
     ]
    }
   ],
   "source": [
    "model_bd.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history_bd = model_bd.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VtoWD4Wa0cqV",
    "outputId": "185ce540-8755-49ba-97b1-e8428cbc8000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 93us/step\n",
      "Validation accuracy:  0.09748333692550659\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bd = model_bd.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bd[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us also try optimizing the model with Adam optimizer then configure the model with loss function and metrices, train the modela and evaluate the model performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "O7AbtwdP0cqa",
    "outputId": "48b01062-ca44-4e0f-b680-be79c22466f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 2s 38us/step - loss: 2.9515 - accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9502 - accuracy: 0.1016\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.9436 - accuracy: 0.0998\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.9322 - accuracy: 0.1016\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9235 - accuracy: 0.0982\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9022 - accuracy: 0.1007\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9044 - accuracy: 0.1006\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9097 - accuracy: 0.0983\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9056 - accuracy: 0.1007\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8758 - accuracy: 0.1016\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8763 - accuracy: 0.0996\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8701 - accuracy: 0.1007\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8465 - accuracy: 0.0986\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8349 - accuracy: 0.1021\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8239 - accuracy: 0.1032\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8229 - accuracy: 0.1005\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8166 - accuracy: 0.1022\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.8101 - accuracy: 0.1004\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7972 - accuracy: 0.1016\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7814 - accuracy: 0.1019\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7979 - accuracy: 0.1026\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7840 - accuracy: 0.1013\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7792 - accuracy: 0.1015\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7703 - accuracy: 0.1000\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7626 - accuracy: 0.1026\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7583 - accuracy: 0.1000\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7582 - accuracy: 0.1010\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7422 - accuracy: 0.1012\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7497 - accuracy: 0.1000\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.7258 - accuracy: 0.0994\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7308 - accuracy: 0.0987\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7219 - accuracy: 0.1019\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7134 - accuracy: 0.1015\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7124 - accuracy: 0.1008\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7137 - accuracy: 0.1026\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7163 - accuracy: 0.1003\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7076 - accuracy: 0.1001\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6944 - accuracy: 0.1009\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6877 - accuracy: 0.1028\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6844 - accuracy: 0.1021\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6831 - accuracy: 0.1001\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6838 - accuracy: 0.0999\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6770 - accuracy: 0.1004\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6790 - accuracy: 0.1006\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6578 - accuracy: 0.1011\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6636 - accuracy: 0.1007\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6547 - accuracy: 0.1003\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6447 - accuracy: 0.1017\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6420 - accuracy: 0.1020\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6528 - accuracy: 0.1001\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6478 - accuracy: 0.1015\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6477 - accuracy: 0.1021\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6339 - accuracy: 0.1020\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6355 - accuracy: 0.0992\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.6393 - accuracy: 0.1011\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6331 - accuracy: 0.1024\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6304 - accuracy: 0.0998\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.6268 - accuracy: 0.1009\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.6171 - accuracy: 0.0999\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6148 - accuracy: 0.1030\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6194 - accuracy: 0.1022\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6158 - accuracy: 0.1016\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6194 - accuracy: 0.1010\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6090 - accuracy: 0.1017\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.6032 - accuracy: 0.1015\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6071 - accuracy: 0.1031\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5990 - accuracy: 0.1029\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5910 - accuracy: 0.1002\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5911 - accuracy: 0.1001\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5969 - accuracy: 0.0986\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5889 - accuracy: 0.0998\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5868 - accuracy: 0.0995\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5887 - accuracy: 0.0996\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.5775 - accuracy: 0.1002\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5783 - accuracy: 0.1009\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5763 - accuracy: 0.1015\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5784 - accuracy: 0.0995\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5810 - accuracy: 0.0992\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.5672 - accuracy: 0.1016\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.5747 - accuracy: 0.1003\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5660 - accuracy: 0.0992\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5623 - accuracy: 0.1024\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5596 - accuracy: 0.1015\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5602 - accuracy: 0.1033\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5583 - accuracy: 0.1000\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5505 - accuracy: 0.1022\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5588 - accuracy: 0.1007\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5515 - accuracy: 0.1010\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5509 - accuracy: 0.1017\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5474 - accuracy: 0.1026\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.5469 - accuracy: 0.1015\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5400 - accuracy: 0.0993\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5438 - accuracy: 0.0993\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5361 - accuracy: 0.1014\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5348 - accuracy: 0.0990\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5258 - accuracy: 0.1030\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5280 - accuracy: 0.1028\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5292 - accuracy: 0.1020\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5340 - accuracy: 0.0990\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5215 - accuracy: 0.1019\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5274 - accuracy: 0.1005\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5176 - accuracy: 0.1007\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5180 - accuracy: 0.0976\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5258 - accuracy: 0.1005\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.5211 - accuracy: 0.1004\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5175 - accuracy: 0.1027\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5180 - accuracy: 0.1007\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.5202 - accuracy: 0.1007\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5103 - accuracy: 0.1007\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5104 - accuracy: 0.1012\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5108 - accuracy: 0.0995\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5007 - accuracy: 0.1036\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5008 - accuracy: 0.1018\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5042 - accuracy: 0.1043\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5044 - accuracy: 0.1014\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4993 - accuracy: 0.1017\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5043 - accuracy: 0.0984\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4979 - accuracy: 0.1017\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4963 - accuracy: 0.1005\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5045 - accuracy: 0.0995\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4942 - accuracy: 0.1025\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4927 - accuracy: 0.1010\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4898 - accuracy: 0.1012\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4938 - accuracy: 0.1021\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4841 - accuracy: 0.1042\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4848 - accuracy: 0.1010\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4878 - accuracy: 0.1007\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4808 - accuracy: 0.1019\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4906 - accuracy: 0.1019\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4835 - accuracy: 0.1022\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4781 - accuracy: 0.1016\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4863 - accuracy: 0.1004\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4752 - accuracy: 0.1019\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4798 - accuracy: 0.0990\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4803 - accuracy: 0.1038\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4695 - accuracy: 0.1016\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4734 - accuracy: 0.1004\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4704 - accuracy: 0.1012\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4833 - accuracy: 0.1015\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4678 - accuracy: 0.1037\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4723 - accuracy: 0.1018\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4621 - accuracy: 0.1030\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4622 - accuracy: 0.1021\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4643 - accuracy: 0.1021\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4693 - accuracy: 0.1005\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4607 - accuracy: 0.1030\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4564 - accuracy: 0.1047\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4692 - accuracy: 0.0990\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4624 - accuracy: 0.1035\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4631 - accuracy: 0.1000\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4562 - accuracy: 0.1026\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4544 - accuracy: 0.1013\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4549 - accuracy: 0.1031\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4533 - accuracy: 0.1016\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4530 - accuracy: 0.1013\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4504 - accuracy: 0.1037\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4447 - accuracy: 0.1037\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4504 - accuracy: 0.1022\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4512 - accuracy: 0.1044\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4468 - accuracy: 0.1006\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4507 - accuracy: 0.1010\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4456 - accuracy: 0.1050\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4446 - accuracy: 0.1033\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4455 - accuracy: 0.1010\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4425 - accuracy: 0.1011\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4425 - accuracy: 0.1015\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4407 - accuracy: 0.1018\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4398 - accuracy: 0.1040\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4417 - accuracy: 0.1027\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4364 - accuracy: 0.1032\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4412 - accuracy: 0.1007\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4427 - accuracy: 0.1025\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4353 - accuracy: 0.1023\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4375 - accuracy: 0.1000\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4372 - accuracy: 0.1034\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4291 - accuracy: 0.1011\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4320 - accuracy: 0.1018\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4320 - accuracy: 0.1035\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4308 - accuracy: 0.1020\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4249 - accuracy: 0.1023\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4272 - accuracy: 0.1008\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4283 - accuracy: 0.1023\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4310 - accuracy: 0.1015\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4311 - accuracy: 0.1017\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4225 - accuracy: 0.1025\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4278 - accuracy: 0.1014\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4272 - accuracy: 0.0998\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4230 - accuracy: 0.1020\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4240 - accuracy: 0.1034\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4217 - accuracy: 0.1021\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4256 - accuracy: 0.1036\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4160 - accuracy: 0.1015\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4152 - accuracy: 0.1035\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4212 - accuracy: 0.1027\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4196 - accuracy: 0.1005\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4183 - accuracy: 0.0988\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4177 - accuracy: 0.1015\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.4091 - accuracy: 0.1038\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4092 - accuracy: 0.1020\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 16us/step - loss: 2.4113 - accuracy: 0.0996\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.00001)\n",
    "model_bd.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history_bd_adam = model_bd.fit(X_train, y_train, batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uVB_LO0f0cqq",
    "outputId": "61dabc64-00f1-4ef5-c2fa-6818597e6fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 91us/step\n",
      "Validation accuracy:  0.10418333113193512\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bd_ad = model_bd.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: ', evaluation_val_bd_ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above steps:\n",
    "1. Above the Neural Network model was created as said initially.\n",
    "2. The performance of the model when using SGD optimizer was very low on training data but on validation data it was little better still the performance is just 9.7%.\n",
    "2. The performance of the model when using Adam optimizer was very low on training data but on validation data it was around 10.4% only.\n",
    "\n",
    "#### Note:\n",
    "1. In the above Model 4 it can be observwd that combination of having BatchNormalization Dropout is not giving good performance results in classifying the digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Improving the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "\n",
    "1. Further, upon building the above models it can be found that NN model optimized using the adam optimizer in the Trial - 4 of Model 3 gave good performance where in that after training the model with the training data the model was capable of classifying at ~94% accuracy and on validation data it gave around ~88.27% accuracy. Therefore, we can try to improve this model by regularizing it or Hyperparmeter tuning.\n",
    "        \n",
    "2. Also, among the models built with SGD optimizer the model that was built in the Trial - 1 of Model - 3 we can also try to improve the model by doing some Hyperparameter Tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning the Model - 3 (Trial -1):\n",
    "\n",
    "   This model is a 21 Layered NN model with 'selu' activation and fine batch normalzation turned on ((i.e) scaling and shifting turned on). Let us try improving the models performance by adjusting the learning rate and lambda of the Ridge Regularization(L2). Then, test the model on the Validation data to have some idea on the performance of the model on production data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F78a1KALOloo"
   },
   "source": [
    "#### Step a: Creating a mini dataset and labels:\n",
    "  Here, we create a mini dataset from the original dataset to test the architecture of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Stujh5zBTDXq"
   },
   "outputs": [],
   "source": [
    "#Creating mini image train, test and validation dataset:\n",
    "X_train_mini = X_train[0:20]\n",
    "X_test_mini = X_test[0:20]\n",
    "X_val_mini = X_val[0:20]\n",
    "\n",
    "#Creating mini label train, test and validation dataset:\n",
    "y_train_mini = y_train[0:20]\n",
    "y_test_mini = y_test[0:20]\n",
    "y_val_mini = y_val[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "V6OKX19HVLac",
    "outputId": "fd3d57e3-e6e7-4ce2-d97b-9e92d8dd61c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_mini_shape: (20, 1024)\n",
      "X_test_mini_shape: (20, 1024)\n",
      "X_val_mini_shape: (20, 1024)\n"
     ]
    }
   ],
   "source": [
    "#Understanding the shape of the mini image datasets:\n",
    "print('X_train_mini_shape:',X_train_mini.shape)\n",
    "print('X_test_mini_shape:',X_test_mini.shape)\n",
    "print('X_val_mini_shape:',X_val_mini.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "hfhOPQ1sWIQb",
    "outputId": "2defa608-01f3-4efc-8632-37fc0cca4670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_mini_shape: (20, 10)\n",
      "y_test_mini_shape: (20, 10)\n",
      "y_val_mini_shape: (20, 10)\n"
     ]
    }
   ],
   "source": [
    "#Understanding the shape of the mini label datasets:\n",
    "print('y_train_mini_shape:',y_train_mini.shape)\n",
    "print('y_test_mini_shape:',y_test_mini.shape)\n",
    "print('y_val_mini_shape:',y_val_mini.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. In the above cells, mini image and label dataset was created which contains twenty images in training, testing and validation.\n",
    "2. With this dataset we will check, how good the architecture is?, in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F78a1KALOloo"
   },
   "source": [
    "#### Step b: Checking the architecture of the model:\n",
    "  Here, the architecture of the model is checked by making the model to overfit on some small portion of the orginal data, if we get performance of the model ~100% then the model architecture is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sIDKc4sVUoG"
   },
   "outputs": [],
   "source": [
    "def improving_model_mini(learning_rate, Lambda, epochs, verb=True):\n",
    "    \n",
    "    #Building a Keras Sequential Model:\n",
    "    model_bn = Sequential()\n",
    "    \n",
    "    #Adding Hidden Layers: \n",
    "    model_bn.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True)) #BatchNormalization Layer.\n",
    "    model_bn.add(Activation('selu')) #Activation Layer.\n",
    "\n",
    "    model_bn.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('selu'))\n",
    "\n",
    "    model_bn.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('selu'))\n",
    "\n",
    "    model_bn.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('selu'))\n",
    "\n",
    "    model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('selu'))\n",
    "\n",
    "    model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('selu'))\n",
    "\n",
    "    model_bn.add(Dense(10, name ='Output_Layer', kernel_regularizer = l2(Lambda)))\n",
    "    model_bn.add(Activation('softmax'))\n",
    "    \n",
    "    #Setting the Optimizing:\n",
    "    sgd = SGD(lr = learning_rate, decay = learning_rate/epochs, momentum = 0.8, nesterov=True )\n",
    "    \n",
    "    #Configuring the model with the optimizer, cost function and metrices:\n",
    "    model_bn.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    #Training the model:\n",
    "    history_bn = model_bn.fit(X_train_mini, y_train_mini, batch_size = 1000, epochs = epochs, verbose = 1)\n",
    "    \n",
    "    #Evaluating the model on validation Data:\n",
    "    evaluation_val_bt = model_bn.evaluate(X_val_mini, y_val_mini)\n",
    "    print('Validation accuracy: ', evaluation_val_bt[1])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eyF2SQNGXKdZ",
    "outputId": "2178c164-ddda-481f-bb4b-5f7cf29b86aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 3.2585 - accuracy: 0.0500\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 727us/step - loss: 2.7426 - accuracy: 0.1000\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 631us/step - loss: 2.2738 - accuracy: 0.2000\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 587us/step - loss: 1.9093 - accuracy: 0.2000\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 534us/step - loss: 1.6293 - accuracy: 0.3000\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 605us/step - loss: 1.4032 - accuracy: 0.4000\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 615us/step - loss: 1.2248 - accuracy: 0.6000\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 542us/step - loss: 1.0735 - accuracy: 0.6500\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 528us/step - loss: 0.9454 - accuracy: 0.7500\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 562us/step - loss: 0.8368 - accuracy: 0.8500\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 554us/step - loss: 0.7527 - accuracy: 0.8500\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 588us/step - loss: 0.6794 - accuracy: 0.9000\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 573us/step - loss: 0.6167 - accuracy: 0.9500\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 576us/step - loss: 0.5640 - accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 641us/step - loss: 0.5184 - accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 713us/step - loss: 0.4798 - accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 760us/step - loss: 0.4458 - accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 732us/step - loss: 0.4139 - accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 751us/step - loss: 0.3864 - accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 539us/step - loss: 0.3618 - accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 593us/step - loss: 0.3395 - accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 685us/step - loss: 0.3210 - accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 673us/step - loss: 0.3040 - accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 562us/step - loss: 0.2889 - accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 563us/step - loss: 0.2757 - accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 544us/step - loss: 0.2639 - accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 895us/step - loss: 0.2534 - accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 736us/step - loss: 0.2437 - accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 676us/step - loss: 0.2348 - accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 762us/step - loss: 0.2267 - accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 661us/step - loss: 0.2191 - accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 646us/step - loss: 0.2121 - accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 588us/step - loss: 0.2055 - accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 713us/step - loss: 0.1995 - accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 611us/step - loss: 0.1938 - accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 825us/step - loss: 0.1886 - accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 643us/step - loss: 0.1836 - accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 999us/step - loss: 0.1704 - accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 634us/step - loss: 0.1666 - accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 740us/step - loss: 0.1629 - accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 613us/step - loss: 0.1594 - accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 708us/step - loss: 0.1530 - accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 586us/step - loss: 0.1500 - accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 710us/step - loss: 0.1471 - accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 699us/step - loss: 0.1443 - accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 556us/step - loss: 0.1417 - accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 677us/step - loss: 0.1392 - accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 613us/step - loss: 0.1368 - accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 563us/step - loss: 0.1344 - accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 676us/step - loss: 0.1322 - accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 615us/step - loss: 0.1300 - accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 672us/step - loss: 0.1279 - accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 825us/step - loss: 0.1259 - accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 642us/step - loss: 0.1240 - accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 705us/step - loss: 0.1222 - accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 598us/step - loss: 0.1205 - accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 562us/step - loss: 0.1188 - accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 586us/step - loss: 0.1172 - accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 581us/step - loss: 0.1156 - accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 685us/step - loss: 0.1140 - accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 634us/step - loss: 0.1125 - accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 679us/step - loss: 0.1111 - accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 695us/step - loss: 0.1097 - accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 660us/step - loss: 0.1083 - accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 620us/step - loss: 0.1070 - accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 574us/step - loss: 0.1056 - accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 647us/step - loss: 0.1044 - accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 625us/step - loss: 0.1031 - accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 924us/step - loss: 0.1019 - accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 690us/step - loss: 0.1008 - accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 727us/step - loss: 0.0996 - accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 693us/step - loss: 0.0985 - accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 732us/step - loss: 0.0974 - accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 603us/step - loss: 0.0963 - accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 744us/step - loss: 0.0952 - accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 656us/step - loss: 0.0942 - accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 689us/step - loss: 0.0932 - accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 791us/step - loss: 0.0922 - accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 689us/step - loss: 0.0913 - accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 707us/step - loss: 0.0903 - accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 620us/step - loss: 0.0894 - accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 704us/step - loss: 0.0885 - accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 692us/step - loss: 0.0876 - accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 845us/step - loss: 0.0868 - accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 782us/step - loss: 0.0859 - accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 704us/step - loss: 0.0851 - accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 558us/step - loss: 0.0843 - accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 697us/step - loss: 0.0835 - accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 529us/step - loss: 0.0827 - accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 649us/step - loss: 0.0819 - accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 658us/step - loss: 0.0812 - accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 678us/step - loss: 0.0804 - accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 675us/step - loss: 0.0797 - accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 797us/step - loss: 0.0789 - accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 660us/step - loss: 0.0782 - accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 854us/step - loss: 0.0775 - accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 718us/step - loss: 0.0769 - accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 554us/step - loss: 0.0755 - accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 675us/step - loss: 0.0749 - accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 625us/step - loss: 0.0743 - accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.0737 - accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 697us/step - loss: 0.0731 - accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 621us/step - loss: 0.0725 - accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 602us/step - loss: 0.0719 - accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 610us/step - loss: 0.0714 - accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 663us/step - loss: 0.0708 - accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 668us/step - loss: 0.0703 - accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 630us/step - loss: 0.0698 - accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 706us/step - loss: 0.0693 - accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 592us/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 707us/step - loss: 0.0682 - accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 506us/step - loss: 0.0678 - accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 581us/step - loss: 0.0673 - accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 549us/step - loss: 0.0668 - accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 632us/step - loss: 0.0663 - accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 723us/step - loss: 0.0659 - accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 604us/step - loss: 0.0654 - accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 636us/step - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 546us/step - loss: 0.0645 - accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 701us/step - loss: 0.0641 - accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.0637 - accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 570us/step - loss: 0.0633 - accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 779us/step - loss: 0.0628 - accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 599us/step - loss: 0.0624 - accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 762us/step - loss: 0.0620 - accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 588us/step - loss: 0.0616 - accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0613 - accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 663us/step - loss: 0.0609 - accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 566us/step - loss: 0.0605 - accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 835us/step - loss: 0.0601 - accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 677us/step - loss: 0.0597 - accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 639us/step - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 673us/step - loss: 0.0590 - accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 718us/step - loss: 0.0586 - accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 639us/step - loss: 0.0583 - accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 697us/step - loss: 0.0579 - accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 627us/step - loss: 0.0575 - accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 780us/step - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 865us/step - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 813us/step - loss: 0.0565 - accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 625us/step - loss: 0.0562 - accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 627us/step - loss: 0.0558 - accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 660us/step - loss: 0.0555 - accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 733us/step - loss: 0.0552 - accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 606us/step - loss: 0.0549 - accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 736us/step - loss: 0.0542 - accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 674us/step - loss: 0.0539 - accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 839us/step - loss: 0.0536 - accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 729us/step - loss: 0.0533 - accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 761us/step - loss: 0.0530 - accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 642us/step - loss: 0.0527 - accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 664us/step - loss: 0.0524 - accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 685us/step - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 673us/step - loss: 0.0519 - accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 715us/step - loss: 0.0516 - accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 706us/step - loss: 0.0513 - accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 606us/step - loss: 0.0510 - accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 988us/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 729us/step - loss: 0.0503 - accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 602us/step - loss: 0.0500 - accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 619us/step - loss: 0.0498 - accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 763us/step - loss: 0.0495 - accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 601us/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0490 - accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 634us/step - loss: 0.0488 - accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 640us/step - loss: 0.0486 - accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 624us/step - loss: 0.0483 - accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 629us/step - loss: 0.0481 - accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 546us/step - loss: 0.0479 - accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 675us/step - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 656us/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 655us/step - loss: 0.0472 - accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 751us/step - loss: 0.0470 - accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 735us/step - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 763us/step - loss: 0.0465 - accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 736us/step - loss: 0.0463 - accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 699us/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 696us/step - loss: 0.0459 - accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 706us/step - loss: 0.0455 - accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 769us/step - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 711us/step - loss: 0.0451 - accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 753us/step - loss: 0.0448 - accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 636us/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 702us/step - loss: 0.0444 - accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 703us/step - loss: 0.0443 - accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 689us/step - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 719us/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 682us/step - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 613us/step - loss: 0.0435 - accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0433 - accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 701us/step - loss: 0.0431 - accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 676us/step - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 658us/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 824us/step - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 979us/step - loss: 0.0423 - accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 760us/step - loss: 0.0421 - accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 554us/step - loss: 0.0420 - accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 508us/step - loss: 0.0418 - accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 546us/step - loss: 0.0416 - accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 876us/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 580us/step - loss: 0.0413 - accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 721us/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 689us/step - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 677us/step - loss: 0.0408 - accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 670us/step - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 715us/step - loss: 0.0404 - accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 530us/step - loss: 0.0403 - accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 712us/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 717us/step - loss: 0.0400 - accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 755us/step - loss: 0.0398 - accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 695us/step - loss: 0.0397 - accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 694us/step - loss: 0.0395 - accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 638us/step - loss: 0.0394 - accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 666us/step - loss: 0.0392 - accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 707us/step - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 627us/step - loss: 0.0389 - accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 880us/step - loss: 0.0388 - accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 885us/step - loss: 0.0386 - accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 695us/step - loss: 0.0385 - accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "20/20 [==============================] - 0s 632us/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 800us/step - loss: 0.0382 - accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 644us/step - loss: 0.0381 - accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 711us/step - loss: 0.0380 - accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 717us/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 708us/step - loss: 0.0377 - accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 621us/step - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 634us/step - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 680us/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0372 - accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 681us/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 713us/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.0368 - accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 701us/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 707us/step - loss: 0.0366 - accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 730us/step - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 645us/step - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 682us/step - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 719us/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 727us/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 633us/step - loss: 0.0358 - accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 629us/step - loss: 0.0357 - accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 735us/step - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 813us/step - loss: 0.0354 - accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 735us/step - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 521us/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 735us/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 636us/step - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 716us/step - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 624us/step - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 609us/step - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 734us/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 669us/step - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 574us/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 694us/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 661us/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 586us/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 716us/step - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 828us/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 706us/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 707us/step - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 691us/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 621us/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 626us/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 599us/step - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 691us/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 601us/step - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 635us/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 695us/step - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 573us/step - loss: 0.0327 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 756us/step - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 761us/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 629us/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 738us/step - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 572us/step - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 707us/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 927us/step - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 726us/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 748us/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 561us/step - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 806us/step - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 593us/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 726us/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 824us/step - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 694us/step - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 626us/step - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 655us/step - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 937us/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 622us/step - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 756us/step - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 904us/step - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 817us/step - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 743us/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 730us/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 709us/step - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 681us/step - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 756us/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 684us/step - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 638us/step - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 710us/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 687us/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 608us/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 638us/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 775us/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 824us/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 585us/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 784us/step - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 754us/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 657us/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 673us/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 627us/step - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 838us/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 535us/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 548us/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 866us/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 691us/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 659us/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 579us/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 726us/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 720us/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 951us/step - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 592us/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 634us/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 660us/step - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 707us/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 661us/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 691us/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 789us/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 712us/step - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 784us/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 579us/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 691us/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 712us/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 702us/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 663us/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 715us/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 728us/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 678us/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 656us/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 706us/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 659us/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 629us/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 691us/step - loss: 0.0273 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 697us/step - loss: 0.0273 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 705us/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 727us/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 585us/step - loss: 0.0271 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 597us/step - loss: 0.0271 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 682us/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 769us/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 710us/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 732us/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 743us/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 805us/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 758us/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 719us/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 653us/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 616us/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 657us/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 631us/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 804us/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 776us/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 653us/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 701us/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 661us/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "20/20 [==============================] - 0s 612us/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 783us/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 690us/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 680us/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 829us/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 681us/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 677us/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 544us/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 653us/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 720us/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 661us/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 759us/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 709us/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 663us/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 996us/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 527us/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 566us/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 625us/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 670us/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 623us/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 578us/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 682us/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 768us/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 598us/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 549us/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 607us/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 656us/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 576us/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 869us/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 917us/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 931us/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 703us/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 633us/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 671us/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 724us/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 662us/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 569us/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 659us/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 561us/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 592us/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 727us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 707us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 660us/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 736us/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 912us/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 728us/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 720us/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 719us/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 783us/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 672us/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 744us/step - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 698us/step - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 693us/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 686us/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 624us/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 739us/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 621us/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 610us/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 714us/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 741us/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 687us/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 645us/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 682us/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 727us/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 746us/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 677us/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 732us/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 709us/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 686us/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 713us/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 699us/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 667us/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 714us/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 699us/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 623us/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 596us/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 718us/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 651us/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 730us/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 647us/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 634us/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 572us/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 620us/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 599us/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 675us/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 538us/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 581us/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 621us/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 587us/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 598us/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 747us/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 696us/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 577us/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 621us/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 738us/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 601us/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 626us/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 771us/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 691us/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 678us/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 886us/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 734us/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 749us/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 727us/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 802us/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 610us/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 611us/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 719us/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 664us/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 590us/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 769us/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 711us/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 611us/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 786us/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 736us/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 857us/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 619us/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 740us/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 709us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 614us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 554us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 644us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "20/20 [==============================] - 0s 7ms/step\n",
      "Validation accuracy:  0.20000000298023224\n"
     ]
    }
   ],
   "source": [
    "improving_model_mini(learning_rate = 0.001, Lambda = 0, epochs = 500, verb=True) #Calling the function with the mentioned learning rates and Lanbda to overfit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. It can be found that the model have very good architecture becuse it is capable of overfitting on the training dataset and 100% accurately classifies the training dataset.\n",
    "\n",
    "    Further, let us try improving the model on the orginal trining dataset by Hyperparameter tunining the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cGW8wLbo1dB"
   },
   "source": [
    "#### Step c: Tuning the Learning Rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trial - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "uSAq7UADXXat",
    "outputId": "fe2f7859-7e57-4b12-a735-6b6ffe77c8b5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 2s 41us/step - loss: 2.8719 - accuracy: 0.0954\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.8719 - accuracy: 0.0954\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8709 - accuracy: 0.0963\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8712 - accuracy: 0.0958\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8710 - accuracy: 0.0957\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8705 - accuracy: 0.0958\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8698 - accuracy: 0.0956\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8702 - accuracy: 0.0964\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8685 - accuracy: 0.0956\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8694 - accuracy: 0.0957\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8690 - accuracy: 0.0950\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8687 - accuracy: 0.0962\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8688 - accuracy: 0.0961\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8690 - accuracy: 0.0955\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8681 - accuracy: 0.0956\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8687 - accuracy: 0.0950\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8674 - accuracy: 0.0954\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8666 - accuracy: 0.0961\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8662 - accuracy: 0.0954\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8673 - accuracy: 0.0945\n",
      "60000/60000 [==============================] - 9s 149us/step\n",
      "Validation accuracy:  0.09548333287239075\n"
     ]
    }
   ],
   "source": [
    "improving_model(learning_rate = 1e-7, Lambda = 1e-7, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. It can be found that the model with the above learning rate gives very poor performance on training data which is around 9.455 only and on validation data 9.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trial - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "VfKFXJk4y85t",
    "outputId": "b9fc9263-20cb-4b9b-e975-9432e56aef01",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 2s 42us/step - loss: 4243099074815903.0000 - accuracy: 0.0995\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 37362755174400.0000 - accuracy: 0.0997\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 37393899579294.4766 - accuracy: 0.0997\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37362464968508.9531 - accuracy: 0.0997\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37362155788385.5234 - accuracy: 0.0997\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361852899718.0938 - accuracy: 0.0997\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361550310643.8047 - accuracy: 0.0997\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361314630704.7578 - accuracy: 0.0997\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361211470799.2422 - accuracy: 0.0997\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 37361129981464.3828 - accuracy: 0.0997\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361093530965.3281 - accuracy: 0.0997\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361087638966.8516 - accuracy: 0.0997\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361084443306.6719 - accuracy: 0.0997\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361083045205.3281 - accuracy: 0.0997\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361083344798.4766 - accuracy: 0.0997\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361083145069.7188 - accuracy: 0.0997\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37361083444662.8516 - accuracy: 0.0997\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 37361083744256.0000 - accuracy: 0.0997\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 37361083544527.2422 - accuracy: 0.0997\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 37369055917787.4297 - accuracy: 0.0997\n",
      "60000/60000 [==============================] - 10s 160us/step\n",
      "Validation accuracy:  0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "improving_model(learning_rate = 1e8, Lambda = 1e-7, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. It can be found that the model with the above learning rate gives very poor performance on training data which is around 9.97% only and on validation data 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trial - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "Mgg9FOthzQok",
    "outputId": "a8c623b7-8aa5-4634-9e6c-8283c3606349",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 2s 42us/step - loss: 23064438.4017 - accuracy: 0.0995\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 5174425.4405 - accuracy: 0.0992\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 5140557.0238 - accuracy: 0.0991\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 5060563.2500 - accuracy: 0.0989\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 4899517.7262 - accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2747048.1488 - accuracy: 0.1033\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1440094.5699 - accuracy: 0.1020\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1208986.6801 - accuracy: 0.1014\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 968292.8140 - accuracy: 0.0995\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 834955.6086 - accuracy: 0.1025\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 650202.5982 - accuracy: 0.1003\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 486399.6711 - accuracy: 0.0998\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 416735.3478 - accuracy: 0.1011\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 359934.8430 - accuracy: 0.1010\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 389601.9141 - accuracy: 0.1004\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 346818.3731 - accuracy: 0.0981\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 363348.8590 - accuracy: 0.1003\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 317996.8151 - accuracy: 0.1016\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 320469.4561 - accuracy: 0.1008\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 315634.2939 - accuracy: 0.1019\n",
      "60000/60000 [==============================] - 9s 152us/step\n",
      "Validation accuracy:  0.10003333538770676\n"
     ]
    }
   ],
   "source": [
    "improving_model(learning_rate = 1e4, Lambda = 1e-7, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. It can be found that the model with the above learning rate gives very poor performance on training data which is around 10.19% only and on validation data 10.03%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trial - 4 : Coarse Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JjYVp8E5zb4Y",
    "outputId": "e2d9d06c-082b-4bc6-e449-c70ae09c330d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 41us/step - loss: 2.7826 - accuracy: 0.1001\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7039 - accuracy: 0.1021\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6473 - accuracy: 0.1072\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6054 - accuracy: 0.1095\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5703 - accuracy: 0.1124\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5413 - accuracy: 0.1151\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5165 - accuracy: 0.1185\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4942 - accuracy: 0.1203\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.4750 - accuracy: 0.1230\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4567 - accuracy: 0.1267\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.4403 - accuracy: 0.1282\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.4252 - accuracy: 0.1316\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.4111 - accuracy: 0.1349\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3991 - accuracy: 0.1377\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3870 - accuracy: 0.1402\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3756 - accuracy: 0.1429\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3657 - accuracy: 0.1446\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3561 - accuracy: 0.1471\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3467 - accuracy: 0.1519\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.3380 - accuracy: 0.1546\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3302 - accuracy: 0.1574\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3229 - accuracy: 0.1591\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.3154 - accuracy: 0.1618\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.3082 - accuracy: 0.1645\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3016 - accuracy: 0.1673\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2953 - accuracy: 0.1690\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2888 - accuracy: 0.1718\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2833 - accuracy: 0.1753\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2776 - accuracy: 0.1783\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2719 - accuracy: 0.1797\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2665 - accuracy: 0.1834\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2615 - accuracy: 0.1855\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2566 - accuracy: 0.1879\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2515 - accuracy: 0.1896\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2469 - accuracy: 0.1927\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2421 - accuracy: 0.1947\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2371 - accuracy: 0.1979\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2330 - accuracy: 0.1995\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2285 - accuracy: 0.2013\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2242 - accuracy: 0.2045\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2199 - accuracy: 0.2073\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2157 - accuracy: 0.2087\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2117 - accuracy: 0.2115\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2079 - accuracy: 0.2138\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2038 - accuracy: 0.2150\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.2001 - accuracy: 0.2171\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1957 - accuracy: 0.2203\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1920 - accuracy: 0.2214\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1883 - accuracy: 0.2228\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1841 - accuracy: 0.2258\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1804 - accuracy: 0.2280\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1769 - accuracy: 0.2315\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1730 - accuracy: 0.2325\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1696 - accuracy: 0.2340\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1656 - accuracy: 0.2368\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1618 - accuracy: 0.2390\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1589 - accuracy: 0.2396\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1552 - accuracy: 0.2422\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1511 - accuracy: 0.2448\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1484 - accuracy: 0.2466\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1443 - accuracy: 0.2491\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1411 - accuracy: 0.2506\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1367 - accuracy: 0.2541\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1331 - accuracy: 0.2559\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1298 - accuracy: 0.2574\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1266 - accuracy: 0.2603\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1225 - accuracy: 0.2616\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1189 - accuracy: 0.2651\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1158 - accuracy: 0.2658\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1123 - accuracy: 0.2689\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1086 - accuracy: 0.2711\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1051 - accuracy: 0.2734\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1010 - accuracy: 0.2763\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0986 - accuracy: 0.2774\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0945 - accuracy: 0.2782\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0910 - accuracy: 0.2808\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0874 - accuracy: 0.2839\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0841 - accuracy: 0.2868\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0803 - accuracy: 0.2880\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0767 - accuracy: 0.2895\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0731 - accuracy: 0.2913\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0692 - accuracy: 0.2937\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0660 - accuracy: 0.2966\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0627 - accuracy: 0.2967\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0588 - accuracy: 0.3013\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0545 - accuracy: 0.3010\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0515 - accuracy: 0.3037\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0478 - accuracy: 0.3065\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0440 - accuracy: 0.3067\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0398 - accuracy: 0.3096\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0365 - accuracy: 0.3111\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0332 - accuracy: 0.3142\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0293 - accuracy: 0.3148\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0256 - accuracy: 0.3159\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0223 - accuracy: 0.3204\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0177 - accuracy: 0.3222\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0142 - accuracy: 0.3223\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0109 - accuracy: 0.3247\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0070 - accuracy: 0.3276\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.0027 - accuracy: 0.3280\n",
      "60000/60000 [==============================] - 9s 147us/step\n",
      "Validation accuracy:  0.3281500041484833\n",
      "Tial_num - 1/100: Good_Validation_accuracy: None, learning_rate: 7.501766363967145e-05, Lambda: 5.1346644662009504e-05\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 40us/step - loss: 2.0019 - accuracy: 0.3256\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.3979 - accuracy: 0.5592\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.1455 - accuracy: 0.6421\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 0.9745 - accuracy: 0.6991\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8675 - accuracy: 0.7325\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8064 - accuracy: 0.7504\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7481 - accuracy: 0.7722\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6967 - accuracy: 0.7884\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6580 - accuracy: 0.7973\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6295 - accuracy: 0.8083\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5953 - accuracy: 0.8175\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5605 - accuracy: 0.8305\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5380 - accuracy: 0.8369\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5118 - accuracy: 0.8442\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5067 - accuracy: 0.8472\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4766 - accuracy: 0.8543\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4476 - accuracy: 0.8643\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4498 - accuracy: 0.8638\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4155 - accuracy: 0.8734\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4113 - accuracy: 0.8748\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3873 - accuracy: 0.8830\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3855 - accuracy: 0.8839\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3614 - accuracy: 0.8921\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3442 - accuracy: 0.8963\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3381 - accuracy: 0.8989\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3314 - accuracy: 0.9001\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3152 - accuracy: 0.9064\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3147 - accuracy: 0.9053\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2922 - accuracy: 0.9144\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2791 - accuracy: 0.9181\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2773 - accuracy: 0.9185\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2629 - accuracy: 0.9215\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2539 - accuracy: 0.9270\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2378 - accuracy: 0.9307\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2461 - accuracy: 0.9278\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2286 - accuracy: 0.9346\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2270 - accuracy: 0.9335\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2067 - accuracy: 0.9402\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2183 - accuracy: 0.9379\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2026 - accuracy: 0.9421\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1871 - accuracy: 0.9491\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1911 - accuracy: 0.9471\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1746 - accuracy: 0.9522\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1748 - accuracy: 0.9517\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1589 - accuracy: 0.9581\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1612 - accuracy: 0.9568\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1625 - accuracy: 0.9563\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1509 - accuracy: 0.9593\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1432 - accuracy: 0.9623\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1436 - accuracy: 0.9621\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1322 - accuracy: 0.9667\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1252 - accuracy: 0.9690\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1284 - accuracy: 0.9688\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1293 - accuracy: 0.9673\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1141 - accuracy: 0.9730\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1051 - accuracy: 0.9764\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1138 - accuracy: 0.9733\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1125 - accuracy: 0.9728\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1074 - accuracy: 0.9754\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0929 - accuracy: 0.9804\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0920 - accuracy: 0.9805\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0984 - accuracy: 0.9779\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0818 - accuracy: 0.9839\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0787 - accuracy: 0.9846\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0753 - accuracy: 0.9864\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0721 - accuracy: 0.9876\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0855 - accuracy: 0.9820\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0710 - accuracy: 0.9876\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0659 - accuracy: 0.9891\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0646 - accuracy: 0.9897\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0632 - accuracy: 0.9901\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0701 - accuracy: 0.9874\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0582 - accuracy: 0.9918\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0507 - accuracy: 0.9949\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0544 - accuracy: 0.9934\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0505 - accuracy: 0.9942\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0473 - accuracy: 0.9951\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0458 - accuracy: 0.9964\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0426 - accuracy: 0.9971\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0432 - accuracy: 0.9965\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0435 - accuracy: 0.9966\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0396 - accuracy: 0.9976\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0374 - accuracy: 0.9983\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0395 - accuracy: 0.9974\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0394 - accuracy: 0.9977\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0384 - accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0350 - accuracy: 0.9989\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0345 - accuracy: 0.9989\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0346 - accuracy: 0.9991\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0343 - accuracy: 0.9986\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0336 - accuracy: 0.9988\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0343 - accuracy: 0.9985\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0312 - accuracy: 0.9994\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0314 - accuracy: 0.9992\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0313 - accuracy: 0.9993\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0299 - accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0291 - accuracy: 0.9997\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0294 - accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0295 - accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0290 - accuracy: 0.9997\n",
      "60000/60000 [==============================] - 9s 143us/step\n",
      "Validation accuracy:  0.9418333172798157\n",
      "Tial_num - 2/100: Good_Validation_accuracy: None, learning_rate: 0.049161401130076436, Lambda: 0.0003754464370012833\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 42us/step - loss: 2.9290 - accuracy: 0.0960\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.9269 - accuracy: 0.0954\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.9243 - accuracy: 0.0960\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.9227 - accuracy: 0.0957\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.9205 - accuracy: 0.0965\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.9188 - accuracy: 0.0962\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.9171 - accuracy: 0.0955\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.9149 - accuracy: 0.0963\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.9130 - accuracy: 0.0958\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.9102 - accuracy: 0.0960\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.9078 - accuracy: 0.0958\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.9064 - accuracy: 0.0955\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.9048 - accuracy: 0.0957\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.9028 - accuracy: 0.0968\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.9005 - accuracy: 0.0968\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8988 - accuracy: 0.0957\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8968 - accuracy: 0.0967\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8957 - accuracy: 0.0959\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8935 - accuracy: 0.0966\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8904 - accuracy: 0.0949\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8901 - accuracy: 0.0957\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8879 - accuracy: 0.0960\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8852 - accuracy: 0.0958\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8848 - accuracy: 0.0963\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8824 - accuracy: 0.0963\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8809 - accuracy: 0.0964\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8783 - accuracy: 0.0963\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8762 - accuracy: 0.0965\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8754 - accuracy: 0.0959\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8730 - accuracy: 0.0958\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8719 - accuracy: 0.0966\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8694 - accuracy: 0.0962\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8681 - accuracy: 0.0955\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8660 - accuracy: 0.0965\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8651 - accuracy: 0.0965\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8630 - accuracy: 0.0972\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8616 - accuracy: 0.0970\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8599 - accuracy: 0.0969\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8587 - accuracy: 0.0963\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8564 - accuracy: 0.0960\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8545 - accuracy: 0.0968\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8531 - accuracy: 0.0962\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8514 - accuracy: 0.0965\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8502 - accuracy: 0.0974\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8474 - accuracy: 0.0970\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8469 - accuracy: 0.0964\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8448 - accuracy: 0.0968\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8432 - accuracy: 0.0965\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8422 - accuracy: 0.0974\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8399 - accuracy: 0.0973\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8385 - accuracy: 0.0970\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8370 - accuracy: 0.0973\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8357 - accuracy: 0.0971\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8344 - accuracy: 0.0980\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8325 - accuracy: 0.0968\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8308 - accuracy: 0.0969\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8296 - accuracy: 0.0966\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8276 - accuracy: 0.0973\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8267 - accuracy: 0.0975\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8257 - accuracy: 0.0977\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8234 - accuracy: 0.0965\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8218 - accuracy: 0.0972\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8208 - accuracy: 0.0973\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8192 - accuracy: 0.0974\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8173 - accuracy: 0.0973\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8166 - accuracy: 0.0970\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8150 - accuracy: 0.0966\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8140 - accuracy: 0.0974\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8120 - accuracy: 0.0976\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8110 - accuracy: 0.0974\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8091 - accuracy: 0.0969\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8072 - accuracy: 0.0984\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8057 - accuracy: 0.0983\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8053 - accuracy: 0.0979\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8035 - accuracy: 0.0980\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8018 - accuracy: 0.0983\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.8015 - accuracy: 0.0975\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7993 - accuracy: 0.0985\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7978 - accuracy: 0.0979\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7963 - accuracy: 0.0988\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7951 - accuracy: 0.0977\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7947 - accuracy: 0.0980\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7930 - accuracy: 0.0984\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7916 - accuracy: 0.0982\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7905 - accuracy: 0.0975\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7893 - accuracy: 0.0973\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7877 - accuracy: 0.0976\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7867 - accuracy: 0.0977\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.7853 - accuracy: 0.0984\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7839 - accuracy: 0.0980\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7833 - accuracy: 0.0977\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7816 - accuracy: 0.0980\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7800 - accuracy: 0.0980\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7786 - accuracy: 0.0985\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7775 - accuracy: 0.0983\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7764 - accuracy: 0.0983\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7754 - accuracy: 0.0975\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7740 - accuracy: 0.0986\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7725 - accuracy: 0.0979\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7716 - accuracy: 0.0974\n",
      "60000/60000 [==============================] - 9s 143us/step\n",
      "Validation accuracy:  0.0995333343744278\n",
      "Tial_num - 3/100: Good_Validation_accuracy: None, learning_rate: 9.05797963104552e-07, Lambda: 2.9918948701377396e-05\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 41us/step - loss: 2.1297 - accuracy: 0.2618\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6345 - accuracy: 0.4703\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.3164 - accuracy: 0.5919\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.1370 - accuracy: 0.6487\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.9988 - accuracy: 0.6940\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.9189 - accuracy: 0.7156\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8501 - accuracy: 0.7370\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7874 - accuracy: 0.7574\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7372 - accuracy: 0.7703\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7057 - accuracy: 0.7806\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6630 - accuracy: 0.7922\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6278 - accuracy: 0.8062\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5928 - accuracy: 0.8178\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5761 - accuracy: 0.8194\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5473 - accuracy: 0.8295\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5227 - accuracy: 0.8362\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5066 - accuracy: 0.8427\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4783 - accuracy: 0.8507\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4555 - accuracy: 0.8575\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4478 - accuracy: 0.8599\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4266 - accuracy: 0.8664\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4133 - accuracy: 0.8715\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3975 - accuracy: 0.8772\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3779 - accuracy: 0.8821\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3676 - accuracy: 0.8853\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3495 - accuracy: 0.8916\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3480 - accuracy: 0.8919\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3256 - accuracy: 0.8997\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3193 - accuracy: 0.8998\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3050 - accuracy: 0.9063\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2923 - accuracy: 0.9107\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2855 - accuracy: 0.9107\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2874 - accuracy: 0.9094\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2603 - accuracy: 0.9207\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2565 - accuracy: 0.9209\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2486 - accuracy: 0.9240\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2347 - accuracy: 0.9275\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2346 - accuracy: 0.9284\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2198 - accuracy: 0.9328\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2143 - accuracy: 0.9336\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2130 - accuracy: 0.9340\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1986 - accuracy: 0.9397\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1980 - accuracy: 0.9398\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1856 - accuracy: 0.9439\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1869 - accuracy: 0.9437\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1698 - accuracy: 0.9498\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1647 - accuracy: 0.9518\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1575 - accuracy: 0.9528\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1612 - accuracy: 0.9517\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1545 - accuracy: 0.9542\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1410 - accuracy: 0.9585\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1529 - accuracy: 0.9537\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1356 - accuracy: 0.9605\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1266 - accuracy: 0.9636\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1276 - accuracy: 0.9633\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1266 - accuracy: 0.9637\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1205 - accuracy: 0.9651\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1408 - accuracy: 0.9580\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1125 - accuracy: 0.9672\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1025 - accuracy: 0.9712\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1011 - accuracy: 0.9716\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0880 - accuracy: 0.9771\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0935 - accuracy: 0.9744\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0876 - accuracy: 0.9762\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0842 - accuracy: 0.9783\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0893 - accuracy: 0.9750\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0746 - accuracy: 0.9810\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0757 - accuracy: 0.9806\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0805 - accuracy: 0.9777\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0663 - accuracy: 0.9842\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0664 - accuracy: 0.9832\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0608 - accuracy: 0.9849\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0574 - accuracy: 0.9866\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0574 - accuracy: 0.9863\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0502 - accuracy: 0.9890\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0532 - accuracy: 0.9876\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0570 - accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0477 - accuracy: 0.9898\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0458 - accuracy: 0.9903\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0475 - accuracy: 0.9894\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0446 - accuracy: 0.9903\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0414 - accuracy: 0.9916\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0373 - accuracy: 0.9933\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0356 - accuracy: 0.9935\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0365 - accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0329 - accuracy: 0.9945\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0292 - accuracy: 0.9957\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0380 - accuracy: 0.9925\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0320 - accuracy: 0.9946\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0299 - accuracy: 0.9950\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0280 - accuracy: 0.9955\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0269 - accuracy: 0.9957\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0307 - accuracy: 0.9943\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0234 - accuracy: 0.9971\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0213 - accuracy: 0.9974\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0228 - accuracy: 0.9969\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0210 - accuracy: 0.9977\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0195 - accuracy: 0.9979\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0191 - accuracy: 0.9977\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0158 - accuracy: 0.9988\n",
      "60000/60000 [==============================] - 9s 146us/step\n",
      "Validation accuracy:  0.9345333576202393\n",
      "Tial_num - 4/100: Good_Validation_accuracy: None, learning_rate: 0.0198834839437913, Lambda: 5.651946886568276e-06\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 43us/step - loss: 521401.1130 - accuracy: 0.1009\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 460.8073 - accuracy: 0.0978\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 103.9744 - accuracy: 0.1010\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 73.8146 - accuracy: 0.0986\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 57.6951 - accuracy: 0.0990\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 45.8566 - accuracy: 0.0979\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 39.9638 - accuracy: 0.0991\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 32.7671 - accuracy: 0.1023\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 29.1190 - accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 26.0990 - accuracy: 0.0989\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 23.1053 - accuracy: 0.0999\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 18.2961 - accuracy: 0.0999\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 17.4489 - accuracy: 0.1012\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 17.5327 - accuracy: 0.0985\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 10.1875 - accuracy: 0.1016\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 8.5905 - accuracy: 0.1016\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 6.6098 - accuracy: 0.0984\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.5316 - accuracy: 0.0993\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.4868 - accuracy: 0.1027\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.4719 - accuracy: 0.1008\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.4527 - accuracy: 0.1003\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.4525 - accuracy: 0.0989\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.4381 - accuracy: 0.1019\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.4362 - accuracy: 0.1003\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.4296 - accuracy: 0.0997\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.4232 - accuracy: 0.1002\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.4190 - accuracy: 0.1026\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.4156 - accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.4127 - accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.4075 - accuracy: 0.0998\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.4045 - accuracy: 0.1002\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.4018 - accuracy: 0.1015\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3976 - accuracy: 0.0999\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3942 - accuracy: 0.1018\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3911 - accuracy: 0.1024\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3912 - accuracy: 0.0986\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3884 - accuracy: 0.0990\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3847 - accuracy: 0.1004\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3835 - accuracy: 0.0976\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3808 - accuracy: 0.1005\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3785 - accuracy: 0.0988\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3765 - accuracy: 0.0994\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3745 - accuracy: 0.0975\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3722 - accuracy: 0.0992\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3699 - accuracy: 0.1013\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3677 - accuracy: 0.1012\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3658 - accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3654 - accuracy: 0.0996\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3632 - accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3612 - accuracy: 0.0993\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3598 - accuracy: 0.0990\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3579 - accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3569 - accuracy: 0.0977\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3555 - accuracy: 0.0979\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3538 - accuracy: 0.0990\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3522 - accuracy: 0.0978\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3504 - accuracy: 0.1012\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3485 - accuracy: 0.1017\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3480 - accuracy: 0.0984\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3464 - accuracy: 0.0982\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3451 - accuracy: 0.0986\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3437 - accuracy: 0.0999\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3422 - accuracy: 0.0996\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3407 - accuracy: 0.0999\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3391 - accuracy: 0.1005\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3392 - accuracy: 0.0985\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3375 - accuracy: 0.0988\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3360 - accuracy: 0.1013\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3350 - accuracy: 0.0989\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3335 - accuracy: 0.0981\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3330 - accuracy: 0.0984\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3320 - accuracy: 0.0977\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3304 - accuracy: 0.0978\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3305 - accuracy: 0.0984\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3281 - accuracy: 0.1015\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3272 - accuracy: 0.1013\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3262 - accuracy: 0.0993\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3249 - accuracy: 0.1026\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3246 - accuracy: 0.1009\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3237 - accuracy: 0.0980\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3222 - accuracy: 0.0996\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3217 - accuracy: 0.1004\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3208 - accuracy: 0.1003\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3196 - accuracy: 0.0990\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3185 - accuracy: 0.0951\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3176 - accuracy: 0.0997\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3166 - accuracy: 0.1020\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3160 - accuracy: 0.1022\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3156 - accuracy: 0.1003\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3145 - accuracy: 0.0994\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3131 - accuracy: 0.1010\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3123 - accuracy: 0.0992\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3115 - accuracy: 0.1001\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3106 - accuracy: 0.0988\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3098 - accuracy: 0.1032\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3092 - accuracy: 0.1002\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3085 - accuracy: 0.0988\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3078 - accuracy: 0.0970\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 3.3070 - accuracy: 0.0990\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 3.3060 - accuracy: 0.0996\n",
      "60000/60000 [==============================] - 9s 145us/step\n",
      "Validation accuracy:  0.10000000149011612\n",
      "Tial_num - 5/100: Good_Validation_accuracy: None, learning_rate: 8.541206364603353, Lambda: 0.0036972510631868376\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 40us/step - loss: 1179431.0361 - accuracy: 0.1009\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 214619.9129 - accuracy: 0.1004\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 207958.2701 - accuracy: 0.1001\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 203798.2422 - accuracy: 0.0992\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 200880.4397 - accuracy: 0.0996\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 199217.2712 - accuracy: 0.0975\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 197892.3032 - accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 196767.9769 - accuracy: 0.1020\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 195793.5610 - accuracy: 0.1005\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 194916.9792 - accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 194142.0167 - accuracy: 0.1028\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 193426.9007 - accuracy: 0.1007\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 192776.8452 - accuracy: 0.1001\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 192180.7087 - accuracy: 0.1012\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 191623.8281 - accuracy: 0.0967\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 191108.1291 - accuracy: 0.0991\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 190621.3631 - accuracy: 0.0996\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 190161.8065 - accuracy: 0.0985\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 189730.3620 - accuracy: 0.1010\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 189321.7385 - accuracy: 0.1007\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 188932.2366 - accuracy: 0.0976\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 188563.5298 - accuracy: 0.0985\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 188210.0651 - accuracy: 0.0995\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 187872.4230 - accuracy: 0.1008\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 187549.8482 - accuracy: 0.1005\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 187240.2117 - accuracy: 0.1006\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 186941.6682 - accuracy: 0.1006\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 186657.4479 - accuracy: 0.1017\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 186380.6049 - accuracy: 0.0994\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 186114.8285 - accuracy: 0.1022\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 185852.8371 - accuracy: 0.1003\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 185605.9260 - accuracy: 0.0996\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 185360.0614 - accuracy: 0.1015\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 185126.5584 - accuracy: 0.1036\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 184898.9103 - accuracy: 0.1011\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 184677.7746 - accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 184462.7626 - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 184253.8315 - accuracy: 0.1011\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 184048.1243 - accuracy: 0.1020\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 183849.5867 - accuracy: 0.0992\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 183656.2500 - accuracy: 0.1003\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 183467.8847 - accuracy: 0.0991\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 183283.5800 - accuracy: 0.1012\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 183103.9747 - accuracy: 0.1003\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 182928.0904 - accuracy: 0.0995\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 182756.3676 - accuracy: 0.1004\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 182588.4319 - accuracy: 0.0995\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 182427.6246 - accuracy: 0.0994\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 182262.9249 - accuracy: 0.1005\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 182105.2519 - accuracy: 0.1002\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 181950.8266 - accuracy: 0.1004\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 181805.7407 - accuracy: 0.0991\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 181650.7400 - accuracy: 0.1012\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 181505.9535 - accuracy: 0.1018\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 181365.2917 - accuracy: 0.0998\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 181221.6696 - accuracy: 0.0981\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 181083.7485 - accuracy: 0.1007\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 180948.2199 - accuracy: 0.1024\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 180815.0126 - accuracy: 0.1002\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 180684.0439 - accuracy: 0.1004\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 180555.2894 - accuracy: 0.0968\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 180434.2016 - accuracy: 0.0999\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 180307.8880 - accuracy: 0.1003\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 180181.6380 - accuracy: 0.0987\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 180061.6972 - accuracy: 0.1001\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 179942.0219 - accuracy: 0.0999\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 179830.0856 - accuracy: 0.0995\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 179709.6648 - accuracy: 0.1015\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 179596.0004 - accuracy: 0.1003\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 179488.2578 - accuracy: 0.1017\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 179373.8367 - accuracy: 0.0997\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 179265.0246 - accuracy: 0.0993\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 179157.8519 - accuracy: 0.1012\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 179052.1064 - accuracy: 0.1007\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 178947.8251 - accuracy: 0.0999\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 178847.1060 - accuracy: 0.1023\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 178751.6090 - accuracy: 0.1020\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 178642.9457 - accuracy: 0.1000\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 178544.0208 - accuracy: 0.0991\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 178446.3843 - accuracy: 0.1001\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 178350.8211 - accuracy: 0.1023\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 178277.4695 - accuracy: 0.1010\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 178217.2522 - accuracy: 0.1021\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 178151.8516 - accuracy: 0.0997\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 178090.1596 - accuracy: 0.1000\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 178029.1815 - accuracy: 0.1020\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 177968.9014 - accuracy: 0.1007\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 177909.2898 - accuracy: 0.1005\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 177850.3449 - accuracy: 0.1020\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 177792.1034 - accuracy: 0.1005\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 177734.4591 - accuracy: 0.1018\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 177682.8419 - accuracy: 0.1007\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 177624.0409 - accuracy: 0.0985\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 177565.5584 - accuracy: 0.1002\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 177510.4732 - accuracy: 0.0995\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 177457.4189 - accuracy: 0.1021\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 177401.5565 - accuracy: 0.0983\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 177354.2894 - accuracy: 0.1000\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 177295.9040 - accuracy: 0.1002\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 177243.6429 - accuracy: 0.1003\n",
      "60000/60000 [==============================] - 9s 157us/step\n",
      "Validation accuracy:  0.10001666843891144\n",
      "Tial_num - 6/100: Good_Validation_accuracy: None, learning_rate: 82.74852484464016, Lambda: 6.101335927677003e-07\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 41us/step - loss: 2.8470 - accuracy: 0.1027\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8403 - accuracy: 0.1026\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8328 - accuracy: 0.1029\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8256 - accuracy: 0.1026\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8185 - accuracy: 0.1024\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8119 - accuracy: 0.1017\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8062 - accuracy: 0.1021\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8002 - accuracy: 0.1015\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7938 - accuracy: 0.1018\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7876 - accuracy: 0.1028\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7819 - accuracy: 0.1023\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7767 - accuracy: 0.1019\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7711 - accuracy: 0.1023\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7659 - accuracy: 0.1028\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7607 - accuracy: 0.1026\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7549 - accuracy: 0.1030\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7505 - accuracy: 0.1035\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7452 - accuracy: 0.1032\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7400 - accuracy: 0.1030\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7354 - accuracy: 0.1038\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7314 - accuracy: 0.1034\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7263 - accuracy: 0.1034\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7208 - accuracy: 0.1037\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7168 - accuracy: 0.1039\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7126 - accuracy: 0.1037\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7071 - accuracy: 0.1041\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7044 - accuracy: 0.1035\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6994 - accuracy: 0.1040\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6948 - accuracy: 0.1041\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6911 - accuracy: 0.1039\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6864 - accuracy: 0.1042\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6819 - accuracy: 0.1045\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6781 - accuracy: 0.1052\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6746 - accuracy: 0.1047\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6710 - accuracy: 0.1047\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6673 - accuracy: 0.1039\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6629 - accuracy: 0.1043\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6589 - accuracy: 0.1056\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6560 - accuracy: 0.1052\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6516 - accuracy: 0.1046\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6483 - accuracy: 0.1055\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6442 - accuracy: 0.1061\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6414 - accuracy: 0.1063\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6372 - accuracy: 0.1060\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6342 - accuracy: 0.1055\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6310 - accuracy: 0.1051\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6275 - accuracy: 0.1062\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6246 - accuracy: 0.1066\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6215 - accuracy: 0.1063\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6182 - accuracy: 0.1065\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6150 - accuracy: 0.1070\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6125 - accuracy: 0.1059\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6092 - accuracy: 0.1063\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6063 - accuracy: 0.1066\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6037 - accuracy: 0.1070\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6004 - accuracy: 0.1073\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5977 - accuracy: 0.1069\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5948 - accuracy: 0.1080\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5926 - accuracy: 0.1069\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5895 - accuracy: 0.1067\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5874 - accuracy: 0.1076\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5849 - accuracy: 0.1063\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5820 - accuracy: 0.1079\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5800 - accuracy: 0.1078\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5768 - accuracy: 0.1085\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5746 - accuracy: 0.1078\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5725 - accuracy: 0.1084\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5702 - accuracy: 0.1090\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5670 - accuracy: 0.1086\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5657 - accuracy: 0.1086\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5637 - accuracy: 0.1078\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5613 - accuracy: 0.1093\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5589 - accuracy: 0.1084\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5568 - accuracy: 0.1093\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5548 - accuracy: 0.1095\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5531 - accuracy: 0.1091\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5506 - accuracy: 0.1095\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5485 - accuracy: 0.1101\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5468 - accuracy: 0.1106\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5452 - accuracy: 0.1110\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5431 - accuracy: 0.1111\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5416 - accuracy: 0.1106\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5389 - accuracy: 0.1111\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5369 - accuracy: 0.1118\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5353 - accuracy: 0.1125\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5342 - accuracy: 0.1125\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5318 - accuracy: 0.1117\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5303 - accuracy: 0.1113\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5285 - accuracy: 0.1117\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5277 - accuracy: 0.1125\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5257 - accuracy: 0.1128\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5236 - accuracy: 0.1131\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5222 - accuracy: 0.1125\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5203 - accuracy: 0.1138\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5191 - accuracy: 0.1135\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5177 - accuracy: 0.1145\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5151 - accuracy: 0.1146\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5142 - accuracy: 0.1141\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5125 - accuracy: 0.1144\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.5112 - accuracy: 0.1149\n",
      "60000/60000 [==============================] - 9s 149us/step\n",
      "Validation accuracy:  0.11415000259876251\n",
      "Tial_num - 7/100: Good_Validation_accuracy: None, learning_rate: 4.136279810014275e-06, Lambda: 9.972238766453623e-05\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 44us/step - loss: 2.9486 - accuracy: 0.0967\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.9423 - accuracy: 0.0971\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.9358 - accuracy: 0.0973\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.9288 - accuracy: 0.0971\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.9232 - accuracy: 0.0981\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.9168 - accuracy: 0.0968\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.9108 - accuracy: 0.0978\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.9054 - accuracy: 0.0976\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8998 - accuracy: 0.0983\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8942 - accuracy: 0.0982\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8892 - accuracy: 0.0989\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8829 - accuracy: 0.0982\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8796 - accuracy: 0.0983\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8740 - accuracy: 0.0987\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8691 - accuracy: 0.0988\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8643 - accuracy: 0.0988\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8595 - accuracy: 0.0987\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8544 - accuracy: 0.0990\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8502 - accuracy: 0.0989\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8458 - accuracy: 0.0989\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8411 - accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8379 - accuracy: 0.0990\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8334 - accuracy: 0.0999\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8296 - accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8245 - accuracy: 0.0995\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8212 - accuracy: 0.1005\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8170 - accuracy: 0.0992\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8125 - accuracy: 0.1002\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.8094 - accuracy: 0.1006\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8053 - accuracy: 0.1011\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8026 - accuracy: 0.1001\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7989 - accuracy: 0.1012\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7949 - accuracy: 0.1015\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7920 - accuracy: 0.1009\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7879 - accuracy: 0.1011\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7851 - accuracy: 0.1011\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7820 - accuracy: 0.1008\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7789 - accuracy: 0.1015\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7755 - accuracy: 0.1018\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7720 - accuracy: 0.1020\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7684 - accuracy: 0.1020\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7659 - accuracy: 0.1016\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7626 - accuracy: 0.1013\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7603 - accuracy: 0.1020\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7569 - accuracy: 0.1030\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7535 - accuracy: 0.1018\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7511 - accuracy: 0.1019\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7482 - accuracy: 0.1016\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7453 - accuracy: 0.1026\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7424 - accuracy: 0.1019\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7401 - accuracy: 0.1027\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.7363 - accuracy: 0.1034\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7338 - accuracy: 0.1032\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7311 - accuracy: 0.1027\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7296 - accuracy: 0.1020\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7254 - accuracy: 0.1036\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7235 - accuracy: 0.1027\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7210 - accuracy: 0.1035\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7181 - accuracy: 0.1031\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7149 - accuracy: 0.1027\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7133 - accuracy: 0.1037\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7111 - accuracy: 0.1028\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7081 - accuracy: 0.1031\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7058 - accuracy: 0.1040\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7034 - accuracy: 0.1041\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7009 - accuracy: 0.1036\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6982 - accuracy: 0.1042\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6960 - accuracy: 0.1041\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6938 - accuracy: 0.1039\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6911 - accuracy: 0.1049\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6890 - accuracy: 0.1042\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6865 - accuracy: 0.1046\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6842 - accuracy: 0.1046\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6816 - accuracy: 0.1044\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6802 - accuracy: 0.1048\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6778 - accuracy: 0.1046\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6759 - accuracy: 0.1040\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6735 - accuracy: 0.1051\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6709 - accuracy: 0.1042\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6690 - accuracy: 0.1047\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6674 - accuracy: 0.1047\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6652 - accuracy: 0.1054\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6621 - accuracy: 0.1056\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6608 - accuracy: 0.1056\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6587 - accuracy: 0.1056\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6567 - accuracy: 0.1055\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6548 - accuracy: 0.1054\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6523 - accuracy: 0.1052\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6506 - accuracy: 0.1054\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6487 - accuracy: 0.1055\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6467 - accuracy: 0.1065\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6445 - accuracy: 0.1067\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6435 - accuracy: 0.1067\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6407 - accuracy: 0.1062\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6389 - accuracy: 0.1068\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6368 - accuracy: 0.1068\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6354 - accuracy: 0.1066\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6331 - accuracy: 0.1075\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6312 - accuracy: 0.1068\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.6304 - accuracy: 0.1072\n",
      "60000/60000 [==============================] - 9s 149us/step\n",
      "Validation accuracy:  0.10563333332538605\n",
      "Tial_num - 8/100: Good_Validation_accuracy: None, learning_rate: 2.8657536343829926e-06, Lambda: 0.0008322856271414201\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 42us/step - loss: 3.0083 - accuracy: 0.0980\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8369 - accuracy: 0.1007\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7298 - accuracy: 0.1053\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6595 - accuracy: 0.1069\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6050 - accuracy: 0.1094\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5624 - accuracy: 0.1111\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5257 - accuracy: 0.1146\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4956 - accuracy: 0.1180\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4698 - accuracy: 0.1204\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4473 - accuracy: 0.1239\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4267 - accuracy: 0.1262\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4086 - accuracy: 0.1298\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3920 - accuracy: 0.1338\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3760 - accuracy: 0.1382\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3622 - accuracy: 0.1423\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3489 - accuracy: 0.1457\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3363 - accuracy: 0.1475\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3247 - accuracy: 0.1528\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3134 - accuracy: 0.1567\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3022 - accuracy: 0.1613\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2920 - accuracy: 0.1654\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2826 - accuracy: 0.1687\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2732 - accuracy: 0.1729\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2633 - accuracy: 0.1780\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2545 - accuracy: 0.1813\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2455 - accuracy: 0.1845\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2377 - accuracy: 0.1904\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2286 - accuracy: 0.1940\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2208 - accuracy: 0.1975\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2125 - accuracy: 0.2014\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2044 - accuracy: 0.2065\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1966 - accuracy: 0.2101\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1891 - accuracy: 0.2147\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1810 - accuracy: 0.2192\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1729 - accuracy: 0.2229\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1659 - accuracy: 0.2279\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1586 - accuracy: 0.2315\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1503 - accuracy: 0.2360\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1432 - accuracy: 0.2420\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1364 - accuracy: 0.2451\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1294 - accuracy: 0.2481\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1218 - accuracy: 0.2526\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1146 - accuracy: 0.2561\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1074 - accuracy: 0.2597\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1000 - accuracy: 0.2660\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0932 - accuracy: 0.2688\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0863 - accuracy: 0.2727\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.0801 - accuracy: 0.2747\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0731 - accuracy: 0.2790\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0664 - accuracy: 0.2824\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.0593 - accuracy: 0.2855\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0524 - accuracy: 0.2903\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0448 - accuracy: 0.2940\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0393 - accuracy: 0.2960\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0314 - accuracy: 0.3000\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.0250 - accuracy: 0.3021\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0188 - accuracy: 0.3067\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0119 - accuracy: 0.3102\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0054 - accuracy: 0.3136\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9988 - accuracy: 0.3159\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9925 - accuracy: 0.3199\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9856 - accuracy: 0.3220\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9792 - accuracy: 0.3263\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9733 - accuracy: 0.3298\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9666 - accuracy: 0.3321\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.9598 - accuracy: 0.3372\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9530 - accuracy: 0.3391\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9470 - accuracy: 0.3420\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9411 - accuracy: 0.3440\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9347 - accuracy: 0.3483\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9278 - accuracy: 0.3503\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9230 - accuracy: 0.3534\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9163 - accuracy: 0.3552\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9097 - accuracy: 0.3585\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9042 - accuracy: 0.3620\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8983 - accuracy: 0.3639\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8914 - accuracy: 0.3668\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8857 - accuracy: 0.3698\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8799 - accuracy: 0.3716\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8744 - accuracy: 0.3733\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8690 - accuracy: 0.3757\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8618 - accuracy: 0.3793\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8564 - accuracy: 0.3825\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8505 - accuracy: 0.3834\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8449 - accuracy: 0.3868\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8393 - accuracy: 0.3897\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8327 - accuracy: 0.3914\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8281 - accuracy: 0.3944\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8217 - accuracy: 0.3980\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8166 - accuracy: 0.4005\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8105 - accuracy: 0.4033\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8051 - accuracy: 0.4052\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7997 - accuracy: 0.4063\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7942 - accuracy: 0.4109\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7882 - accuracy: 0.4102\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7817 - accuracy: 0.4164\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7774 - accuracy: 0.4161\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7726 - accuracy: 0.4182\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7669 - accuracy: 0.4220\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7618 - accuracy: 0.4234\n",
      "60000/60000 [==============================] - 9s 158us/step\n",
      "Validation accuracy:  0.420933336019516\n",
      "Tial_num - 9/100: Good_Validation_accuracy: None, learning_rate: 0.0001096934519916913, Lambda: 0.0007479474412428493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,10):\n",
    "    learning_rate = math.pow(10, np.random.uniform(-7.0, 3.0)) \n",
    "    Lambda = math.pow(10, np.random.uniform(-7,-2))\n",
    "    good_score = improving_model(learning_rate = learning_rate, Lambda= Lambda, epochs=100)  \n",
    "    print(\"Tial_num - {0}/{1}, learning_rate: {2}, Lambda: {3}\\n\".format(x, 100, learning_rate, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "    It can be found that in the trials two and four we have very good performance but the model is undergoing overfitting on the data which is not a suitable scenario in ptoduction because we will get very poor results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trial - 5 : Fine Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "StXT2yJv271f",
    "outputId": "258d331c-ec41-4420-9fca-b445e042c4c1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 41us/step - loss: 2.4172 - accuracy: 0.1599\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1195 - accuracy: 0.2671\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.9311 - accuracy: 0.3651\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.7579 - accuracy: 0.4425\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.6115 - accuracy: 0.5019\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.4957 - accuracy: 0.5421\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.3906 - accuracy: 0.5798\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.3094 - accuracy: 0.6043\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.2367 - accuracy: 0.6305\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.1872 - accuracy: 0.6453\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.1271 - accuracy: 0.6645\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.0835 - accuracy: 0.6778\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.0490 - accuracy: 0.6889\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.0073 - accuracy: 0.7025\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.9741 - accuracy: 0.7122\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.9436 - accuracy: 0.7230\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.9179 - accuracy: 0.7286\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8901 - accuracy: 0.7395\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8666 - accuracy: 0.7454\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8466 - accuracy: 0.7516\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8196 - accuracy: 0.7612\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8071 - accuracy: 0.7625\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7817 - accuracy: 0.7735\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7604 - accuracy: 0.7795\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7530 - accuracy: 0.7807\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7344 - accuracy: 0.7875\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7217 - accuracy: 0.7892\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6997 - accuracy: 0.7972\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6890 - accuracy: 0.8008\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6818 - accuracy: 0.8024\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6655 - accuracy: 0.8075\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6501 - accuracy: 0.8132\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6436 - accuracy: 0.8148\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6288 - accuracy: 0.8207\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6162 - accuracy: 0.8260\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6097 - accuracy: 0.8267\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5968 - accuracy: 0.8284\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5909 - accuracy: 0.8310\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5739 - accuracy: 0.8363\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5732 - accuracy: 0.8383\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5519 - accuracy: 0.8462\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5547 - accuracy: 0.8435\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5444 - accuracy: 0.8477\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5326 - accuracy: 0.8523\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5306 - accuracy: 0.8516\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5130 - accuracy: 0.8574\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5053 - accuracy: 0.8608\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4995 - accuracy: 0.8616\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4926 - accuracy: 0.8654\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4800 - accuracy: 0.8686\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4909 - accuracy: 0.8645\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4701 - accuracy: 0.8710\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4654 - accuracy: 0.8722\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4512 - accuracy: 0.8796\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4478 - accuracy: 0.8799\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4451 - accuracy: 0.8803\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4301 - accuracy: 0.8842\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4281 - accuracy: 0.8860\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4262 - accuracy: 0.8857\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4255 - accuracy: 0.8862\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4133 - accuracy: 0.8904\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4052 - accuracy: 0.8934\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3984 - accuracy: 0.8960\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3850 - accuracy: 0.9014\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3932 - accuracy: 0.8964\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3873 - accuracy: 0.8994\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3757 - accuracy: 0.9033\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3743 - accuracy: 0.9032\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3673 - accuracy: 0.9063\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3707 - accuracy: 0.9054\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3548 - accuracy: 0.9109\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3493 - accuracy: 0.9129\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3484 - accuracy: 0.9126\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3392 - accuracy: 0.9162\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3463 - accuracy: 0.9132\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3343 - accuracy: 0.9188\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3315 - accuracy: 0.9184\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3260 - accuracy: 0.9209\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3235 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3129 - accuracy: 0.9256\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3117 - accuracy: 0.9256\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3051 - accuracy: 0.9266\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3051 - accuracy: 0.9286\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3050 - accuracy: 0.9292\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3014 - accuracy: 0.9289\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2929 - accuracy: 0.9301\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2931 - accuracy: 0.9317\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2856 - accuracy: 0.9354\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2843 - accuracy: 0.9345\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2786 - accuracy: 0.9365\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2678 - accuracy: 0.9410\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2740 - accuracy: 0.9388\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2653 - accuracy: 0.9410\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2626 - accuracy: 0.9431\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2646 - accuracy: 0.9425\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2648 - accuracy: 0.9425\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2593 - accuracy: 0.9448\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2496 - accuracy: 0.9469\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2405 - accuracy: 0.9508\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2415 - accuracy: 0.9504\n",
      "60000/60000 [==============================] - 9s 144us/step\n",
      "Validation accuracy:  0.8291666507720947\n",
      "Tial_num - 1/100, learning_rate: 0.0039019349328263185, Lambda: 0.0015828570925151258\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 43us/step - loss: 2.8179 - accuracy: 0.1035\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7091 - accuracy: 0.1074\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6312 - accuracy: 0.1122\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5718 - accuracy: 0.1165\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5267 - accuracy: 0.1209\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4908 - accuracy: 0.1255\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4618 - accuracy: 0.1296\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4376 - accuracy: 0.1324\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4162 - accuracy: 0.1379\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3976 - accuracy: 0.1417\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3810 - accuracy: 0.1460\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3663 - accuracy: 0.1485\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3524 - accuracy: 0.1537\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3400 - accuracy: 0.1569\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3285 - accuracy: 0.1600\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3176 - accuracy: 0.1655\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3076 - accuracy: 0.1688\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2976 - accuracy: 0.1730\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2883 - accuracy: 0.1766\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2795 - accuracy: 0.1808\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2715 - accuracy: 0.1851\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2632 - accuracy: 0.1892\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2548 - accuracy: 0.1928\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2485 - accuracy: 0.1979\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2405 - accuracy: 0.2012\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2331 - accuracy: 0.2064\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2265 - accuracy: 0.2081\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2192 - accuracy: 0.2117\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2131 - accuracy: 0.2167\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2063 - accuracy: 0.2201\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1994 - accuracy: 0.2255\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1935 - accuracy: 0.2262\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1869 - accuracy: 0.2299\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1802 - accuracy: 0.2351\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1748 - accuracy: 0.2381\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1684 - accuracy: 0.2404\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1620 - accuracy: 0.2443\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1558 - accuracy: 0.2491\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1500 - accuracy: 0.2521\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1436 - accuracy: 0.2553\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1381 - accuracy: 0.2580\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1323 - accuracy: 0.2628\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1263 - accuracy: 0.2649\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1203 - accuracy: 0.2683\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1143 - accuracy: 0.2709\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 2.1083 - accuracy: 0.2755\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1022 - accuracy: 0.2775\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0960 - accuracy: 0.2829\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0909 - accuracy: 0.2846\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0848 - accuracy: 0.2867\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0791 - accuracy: 0.2901\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0731 - accuracy: 0.2945\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0672 - accuracy: 0.2958\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0613 - accuracy: 0.2997\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0555 - accuracy: 0.3019\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0499 - accuracy: 0.3033\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0440 - accuracy: 0.3076\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0378 - accuracy: 0.3105\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0320 - accuracy: 0.3137\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0255 - accuracy: 0.3169\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0209 - accuracy: 0.3181\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0139 - accuracy: 0.3214\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0085 - accuracy: 0.3254\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0027 - accuracy: 0.3276\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9961 - accuracy: 0.3307\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9908 - accuracy: 0.3323\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9847 - accuracy: 0.3353\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9786 - accuracy: 0.3377\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9729 - accuracy: 0.3399\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9674 - accuracy: 0.3416\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9608 - accuracy: 0.3455\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9544 - accuracy: 0.3483\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9490 - accuracy: 0.3500\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9435 - accuracy: 0.3531\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9371 - accuracy: 0.3566\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9313 - accuracy: 0.3602\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9258 - accuracy: 0.3619\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9197 - accuracy: 0.3637\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9141 - accuracy: 0.3680\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9076 - accuracy: 0.3700\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9020 - accuracy: 0.3715\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8960 - accuracy: 0.3753\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8897 - accuracy: 0.3784\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8842 - accuracy: 0.3821\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8785 - accuracy: 0.3839\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8733 - accuracy: 0.3855\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8668 - accuracy: 0.3881\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8614 - accuracy: 0.3905\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8553 - accuracy: 0.3949\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8504 - accuracy: 0.3953\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8446 - accuracy: 0.3970\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8385 - accuracy: 0.4012\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8335 - accuracy: 0.4029\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8277 - accuracy: 0.4057\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8223 - accuracy: 0.4072\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8162 - accuracy: 0.4100\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8113 - accuracy: 0.4125\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8060 - accuracy: 0.4149\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8005 - accuracy: 0.4183\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7944 - accuracy: 0.4223\n",
      "60000/60000 [==============================] - 9s 149us/step\n",
      "Validation accuracy:  0.41823333501815796\n",
      "Tial_num - 2/100, learning_rate: 0.00012314882656742776, Lambda: 0.0011982174783625966\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 41us/step - loss: 2.1924 - accuracy: 0.2474\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6523 - accuracy: 0.4728\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.3366 - accuracy: 0.5890\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.1492 - accuracy: 0.6497\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.0137 - accuracy: 0.6952\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.9459 - accuracy: 0.7139\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8669 - accuracy: 0.7382\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8078 - accuracy: 0.7564\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7684 - accuracy: 0.7677\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7238 - accuracy: 0.7822\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6875 - accuracy: 0.7950\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6580 - accuracy: 0.8023\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6294 - accuracy: 0.8110\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6019 - accuracy: 0.8217\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5827 - accuracy: 0.8268\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5552 - accuracy: 0.8355\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5335 - accuracy: 0.8433\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5133 - accuracy: 0.8499\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4900 - accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4901 - accuracy: 0.8546\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4689 - accuracy: 0.8639\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4415 - accuracy: 0.8723\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4412 - accuracy: 0.8735\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4146 - accuracy: 0.8800\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4089 - accuracy: 0.8812\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3942 - accuracy: 0.8874\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3747 - accuracy: 0.8932\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3810 - accuracy: 0.8890\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3532 - accuracy: 0.9014\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3529 - accuracy: 0.9003\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3385 - accuracy: 0.9068\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3295 - accuracy: 0.9094\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3266 - accuracy: 0.9092\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3162 - accuracy: 0.9125\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3011 - accuracy: 0.9207\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3027 - accuracy: 0.9181\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2827 - accuracy: 0.9239\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2756 - accuracy: 0.9259\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2693 - accuracy: 0.9291\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2644 - accuracy: 0.9307\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2492 - accuracy: 0.9358\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2481 - accuracy: 0.9348\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2474 - accuracy: 0.9347\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2276 - accuracy: 0.9431\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2182 - accuracy: 0.9471\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2338 - accuracy: 0.9408\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2231 - accuracy: 0.9428\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2002 - accuracy: 0.9529\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1994 - accuracy: 0.9518\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1881 - accuracy: 0.9581\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1933 - accuracy: 0.9549\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1906 - accuracy: 0.9541\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1947 - accuracy: 0.9535\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1772 - accuracy: 0.9592\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1702 - accuracy: 0.9627\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1698 - accuracy: 0.9627\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1539 - accuracy: 0.9679\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1725 - accuracy: 0.9596\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1475 - accuracy: 0.9705\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1467 - accuracy: 0.9700\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1403 - accuracy: 0.9728\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1508 - accuracy: 0.9683\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1358 - accuracy: 0.9734\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1336 - accuracy: 0.9741\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1261 - accuracy: 0.9777\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1292 - accuracy: 0.9762\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1331 - accuracy: 0.9744\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1242 - accuracy: 0.9779\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1200 - accuracy: 0.9795\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1153 - accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1284 - accuracy: 0.9754\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1142 - accuracy: 0.9813\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1125 - accuracy: 0.9813\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0986 - accuracy: 0.9876\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0985 - accuracy: 0.9867\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1005 - accuracy: 0.9851\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0915 - accuracy: 0.9897\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0940 - accuracy: 0.9880\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0900 - accuracy: 0.9898\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0838 - accuracy: 0.9921\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0862 - accuracy: 0.9907\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.1054 - accuracy: 0.9830\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0866 - accuracy: 0.9907\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0812 - accuracy: 0.9920\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0777 - accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0747 - accuracy: 0.9942\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0752 - accuracy: 0.9945\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0779 - accuracy: 0.9928\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0725 - accuracy: 0.9946\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0703 - accuracy: 0.9955\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0712 - accuracy: 0.9948\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0705 - accuracy: 0.9953\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0686 - accuracy: 0.9959\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0701 - accuracy: 0.9953\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0685 - accuracy: 0.9956\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0687 - accuracy: 0.9955\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0643 - accuracy: 0.9969\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.0624 - accuracy: 0.9973\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0652 - accuracy: 0.9960\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0653 - accuracy: 0.9963\n",
      "60000/60000 [==============================] - 9s 148us/step\n",
      "Validation accuracy:  0.8118833303451538\n",
      "Tial_num - 3/100, learning_rate: 0.019045264220337525, Lambda: 0.0008978522075013951\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 41us/step - loss: 2.8481 - accuracy: 0.0986\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.6330 - accuracy: 0.1039\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5392 - accuracy: 0.1103\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.4807 - accuracy: 0.1205\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4402 - accuracy: 0.1261\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4084 - accuracy: 0.1316\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3830 - accuracy: 0.1405\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3606 - accuracy: 0.1462\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3417 - accuracy: 0.1522\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3245 - accuracy: 0.1585\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3076 - accuracy: 0.1643\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2932 - accuracy: 0.1707\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2792 - accuracy: 0.1766\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2665 - accuracy: 0.1822\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2534 - accuracy: 0.1887\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2417 - accuracy: 0.1943\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2298 - accuracy: 0.2004\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2184 - accuracy: 0.2072\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2070 - accuracy: 0.2135\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1959 - accuracy: 0.2214\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1852 - accuracy: 0.2261\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1739 - accuracy: 0.2340\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1638 - accuracy: 0.2395\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1525 - accuracy: 0.2445\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1419 - accuracy: 0.2514\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1312 - accuracy: 0.2572\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1208 - accuracy: 0.2648\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1096 - accuracy: 0.2712\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0990 - accuracy: 0.2743\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.0888 - accuracy: 0.2823\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0777 - accuracy: 0.2882\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0672 - accuracy: 0.2927\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.0572 - accuracy: 0.2986\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0456 - accuracy: 0.3055\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0358 - accuracy: 0.3110\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0249 - accuracy: 0.3164\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0145 - accuracy: 0.3209\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0030 - accuracy: 0.3272\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9928 - accuracy: 0.3314\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9827 - accuracy: 0.3374\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9727 - accuracy: 0.3419\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9617 - accuracy: 0.3471\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9516 - accuracy: 0.3527\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9416 - accuracy: 0.3559\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9310 - accuracy: 0.3621\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9213 - accuracy: 0.3648\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9112 - accuracy: 0.3718\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9008 - accuracy: 0.3769\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8908 - accuracy: 0.3811\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8815 - accuracy: 0.3848\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8718 - accuracy: 0.3877\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8615 - accuracy: 0.3931\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8517 - accuracy: 0.3966\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.8422 - accuracy: 0.4012\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8332 - accuracy: 0.4046\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8233 - accuracy: 0.4099\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8144 - accuracy: 0.4127\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8048 - accuracy: 0.4179\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7954 - accuracy: 0.4215\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7868 - accuracy: 0.4266\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7782 - accuracy: 0.4302\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7697 - accuracy: 0.4321\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7597 - accuracy: 0.4369\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7524 - accuracy: 0.4416\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7434 - accuracy: 0.4450\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7357 - accuracy: 0.4486\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7269 - accuracy: 0.4519\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7186 - accuracy: 0.4556\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7104 - accuracy: 0.4604\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7018 - accuracy: 0.4635\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6933 - accuracy: 0.4677\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6850 - accuracy: 0.4700\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6778 - accuracy: 0.4741\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6703 - accuracy: 0.4795\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6620 - accuracy: 0.4825\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6541 - accuracy: 0.4862\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6464 - accuracy: 0.4870\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6381 - accuracy: 0.4909\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6313 - accuracy: 0.4951\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6238 - accuracy: 0.4981\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6158 - accuracy: 0.5025\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6088 - accuracy: 0.5050\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6005 - accuracy: 0.5077\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5940 - accuracy: 0.5104\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5875 - accuracy: 0.5135\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5788 - accuracy: 0.5182\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5719 - accuracy: 0.5200\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5660 - accuracy: 0.5225\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5585 - accuracy: 0.5262\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5523 - accuracy: 0.5290\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.5449 - accuracy: 0.5321\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.5373 - accuracy: 0.5350\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5318 - accuracy: 0.5365\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.5247 - accuracy: 0.5398\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5178 - accuracy: 0.5401\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5118 - accuracy: 0.5457\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5053 - accuracy: 0.5473\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4994 - accuracy: 0.5495\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.4924 - accuracy: 0.5512\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4866 - accuracy: 0.5538\n",
      "60000/60000 [==============================] - 9s 147us/step\n",
      "Validation accuracy:  0.5492666959762573\n",
      "Tial_num - 4/100, learning_rate: 0.00018731136187306063, Lambda: 0.0013900614229763661\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 42us/step - loss: 2.6825 - accuracy: 0.1112\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.5222 - accuracy: 0.1220\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.4576 - accuracy: 0.1344\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.4185 - accuracy: 0.1482\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.3901 - accuracy: 0.1599\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3658 - accuracy: 0.1739\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3454 - accuracy: 0.1864\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3251 - accuracy: 0.1989\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3065 - accuracy: 0.2122\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2873 - accuracy: 0.2240\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2687 - accuracy: 0.2361\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2484 - accuracy: 0.2475\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2270 - accuracy: 0.2612\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2049 - accuracy: 0.2748\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1817 - accuracy: 0.2879\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1575 - accuracy: 0.3007\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1318 - accuracy: 0.3111\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1058 - accuracy: 0.3262\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0792 - accuracy: 0.3397\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.0527 - accuracy: 0.3521\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.0260 - accuracy: 0.3640\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.9985 - accuracy: 0.3775\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9728 - accuracy: 0.3884\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.9467 - accuracy: 0.3991\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.9215 - accuracy: 0.4129\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.8954 - accuracy: 0.4222\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.8711 - accuracy: 0.4354\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8467 - accuracy: 0.4444\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8230 - accuracy: 0.4545\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8002 - accuracy: 0.4641\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.7774 - accuracy: 0.4749\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.7549 - accuracy: 0.4844\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7325 - accuracy: 0.4934\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.7123 - accuracy: 0.5018\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.6906 - accuracy: 0.5128\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6702 - accuracy: 0.5205\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6513 - accuracy: 0.5265\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6318 - accuracy: 0.5343\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6139 - accuracy: 0.5418\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5938 - accuracy: 0.5499\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5781 - accuracy: 0.5542\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5603 - accuracy: 0.5603\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5438 - accuracy: 0.5662\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5273 - accuracy: 0.5718\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5120 - accuracy: 0.5779\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4974 - accuracy: 0.5834\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4831 - accuracy: 0.5895\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4681 - accuracy: 0.5937\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4543 - accuracy: 0.5985\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4404 - accuracy: 0.6035\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4286 - accuracy: 0.6077\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4153 - accuracy: 0.6115\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4026 - accuracy: 0.6168\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3912 - accuracy: 0.6213\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3797 - accuracy: 0.6237\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3674 - accuracy: 0.6285\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3557 - accuracy: 0.6337\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3458 - accuracy: 0.6360\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.3355 - accuracy: 0.6393\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3250 - accuracy: 0.6429\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3141 - accuracy: 0.6461\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3048 - accuracy: 0.6483\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2954 - accuracy: 0.6530\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2846 - accuracy: 0.6557\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.2764 - accuracy: 0.6594\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2683 - accuracy: 0.6624\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2584 - accuracy: 0.6645\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2507 - accuracy: 0.6685\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2412 - accuracy: 0.6721\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2320 - accuracy: 0.6745\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2255 - accuracy: 0.6766\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2168 - accuracy: 0.6785\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2103 - accuracy: 0.6797\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2021 - accuracy: 0.6836\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1932 - accuracy: 0.6871\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1861 - accuracy: 0.6887\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1803 - accuracy: 0.6898\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1725 - accuracy: 0.6929\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1651 - accuracy: 0.6940\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1588 - accuracy: 0.6963\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1513 - accuracy: 0.6992\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1437 - accuracy: 0.7028\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.1385 - accuracy: 0.7018\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1314 - accuracy: 0.7056\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.1243 - accuracy: 0.7078\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.1191 - accuracy: 0.7096\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.1125 - accuracy: 0.7112\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.1057 - accuracy: 0.7148\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.1003 - accuracy: 0.7155\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.0953 - accuracy: 0.7166\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0884 - accuracy: 0.7191\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0833 - accuracy: 0.7216\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0767 - accuracy: 0.7225\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0712 - accuracy: 0.7243\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0670 - accuracy: 0.7261\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0611 - accuracy: 0.7264\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0557 - accuracy: 0.7290\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0504 - accuracy: 0.7315\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0462 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0402 - accuracy: 0.7345\n",
      "60000/60000 [==============================] - 9s 148us/step\n",
      "Validation accuracy:  0.7214499711990356\n",
      "Tial_num - 5/100, learning_rate: 0.0005814307988356324, Lambda: 0.007850610946781612\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 42us/step - loss: 2.9320 - accuracy: 0.1055\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7790 - accuracy: 0.1078\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.6741 - accuracy: 0.1128\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5992 - accuracy: 0.1178\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5445 - accuracy: 0.1228\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4995 - accuracy: 0.1279\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4640 - accuracy: 0.1327\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.4333 - accuracy: 0.1362\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4069 - accuracy: 0.1392\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3830 - accuracy: 0.1443\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3622 - accuracy: 0.1495\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3444 - accuracy: 0.1529\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.3272 - accuracy: 0.1607\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3115 - accuracy: 0.1640\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2978 - accuracy: 0.1687\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2843 - accuracy: 0.1752\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2724 - accuracy: 0.1789\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.2597 - accuracy: 0.1849\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2490 - accuracy: 0.1896\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2380 - accuracy: 0.1950\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2282 - accuracy: 0.1981\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2183 - accuracy: 0.2036\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2089 - accuracy: 0.2081\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1996 - accuracy: 0.2125\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1903 - accuracy: 0.2178\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1814 - accuracy: 0.2228\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1733 - accuracy: 0.2263\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1642 - accuracy: 0.2305\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1558 - accuracy: 0.2346\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1478 - accuracy: 0.2395\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1389 - accuracy: 0.2441\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1314 - accuracy: 0.2497\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1235 - accuracy: 0.2535\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1155 - accuracy: 0.2566\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1073 - accuracy: 0.2606\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0992 - accuracy: 0.2632\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0912 - accuracy: 0.2687\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0829 - accuracy: 0.2735\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0748 - accuracy: 0.2782\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0674 - accuracy: 0.2823\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0591 - accuracy: 0.2865\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0511 - accuracy: 0.2908\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0430 - accuracy: 0.2945\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0346 - accuracy: 0.2983\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0266 - accuracy: 0.3015\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0189 - accuracy: 0.3068\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0105 - accuracy: 0.3123\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0026 - accuracy: 0.3147\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.9944 - accuracy: 0.3185\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9863 - accuracy: 0.3225\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9778 - accuracy: 0.3257\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9698 - accuracy: 0.3301\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.9618 - accuracy: 0.3347\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9539 - accuracy: 0.3385\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9462 - accuracy: 0.3421\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.9372 - accuracy: 0.3458\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9293 - accuracy: 0.3498\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.9215 - accuracy: 0.3520\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.9123 - accuracy: 0.3583\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.9046 - accuracy: 0.3610\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8969 - accuracy: 0.3655\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.8886 - accuracy: 0.3690\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8804 - accuracy: 0.3731\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8728 - accuracy: 0.3757\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.8650 - accuracy: 0.3811\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.8571 - accuracy: 0.3840\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.8493 - accuracy: 0.3872\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.8413 - accuracy: 0.3906\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.8336 - accuracy: 0.3955\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.8259 - accuracy: 0.3973\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8186 - accuracy: 0.4001\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.8107 - accuracy: 0.4043\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8034 - accuracy: 0.4072\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7957 - accuracy: 0.4115\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7878 - accuracy: 0.4141\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7808 - accuracy: 0.4175\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7738 - accuracy: 0.4208\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7658 - accuracy: 0.4248\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.7588 - accuracy: 0.4285\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7518 - accuracy: 0.4321\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7448 - accuracy: 0.4348\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7368 - accuracy: 0.4385\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.7294 - accuracy: 0.4410\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7227 - accuracy: 0.4434\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.7155 - accuracy: 0.4462\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7090 - accuracy: 0.4492\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7009 - accuracy: 0.4540\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6945 - accuracy: 0.4573\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6877 - accuracy: 0.4585\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6809 - accuracy: 0.4620\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.6737 - accuracy: 0.4628\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.6677 - accuracy: 0.4670\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.6602 - accuracy: 0.4696\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.6538 - accuracy: 0.4724\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6470 - accuracy: 0.4758\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6412 - accuracy: 0.4782\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6347 - accuracy: 0.4795\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.6278 - accuracy: 0.4823\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.6216 - accuracy: 0.4855\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6147 - accuracy: 0.4890\n",
      "60000/60000 [==============================] - 9s 147us/step\n",
      "Validation accuracy:  0.4873499870300293\n",
      "Tial_num - 6/100, learning_rate: 0.00012917893922824274, Lambda: 0.00013760304326864616\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 41us/step - loss: 2.5180 - accuracy: 0.1169\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2532 - accuracy: 0.1823\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1499 - accuracy: 0.2443\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.0544 - accuracy: 0.2983\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.9552 - accuracy: 0.3492\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8573 - accuracy: 0.3942\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7613 - accuracy: 0.4341\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6718 - accuracy: 0.4705\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5869 - accuracy: 0.5023\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5093 - accuracy: 0.5323\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.4394 - accuracy: 0.5609\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.3767 - accuracy: 0.5829\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.3164 - accuracy: 0.6043\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2619 - accuracy: 0.6215\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2164 - accuracy: 0.6367\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1733 - accuracy: 0.6535\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.1312 - accuracy: 0.6650\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.0964 - accuracy: 0.6763\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.0661 - accuracy: 0.6855\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.0354 - accuracy: 0.6938\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.0058 - accuracy: 0.7027\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9820 - accuracy: 0.7117\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9561 - accuracy: 0.7187\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9346 - accuracy: 0.7246\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9116 - accuracy: 0.7325\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8878 - accuracy: 0.7406\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8760 - accuracy: 0.7415\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8551 - accuracy: 0.7493\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8394 - accuracy: 0.7535\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8167 - accuracy: 0.7611\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8042 - accuracy: 0.7639\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7905 - accuracy: 0.7685\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7743 - accuracy: 0.7727\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7597 - accuracy: 0.7786\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7493 - accuracy: 0.7812\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7352 - accuracy: 0.7846\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7240 - accuracy: 0.7888\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7085 - accuracy: 0.7949\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6966 - accuracy: 0.7978\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6892 - accuracy: 0.7980\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6824 - accuracy: 0.8015\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6679 - accuracy: 0.8062\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6506 - accuracy: 0.8121\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6455 - accuracy: 0.8114\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6398 - accuracy: 0.8141\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6279 - accuracy: 0.8181\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6190 - accuracy: 0.8198\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6152 - accuracy: 0.8212\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5991 - accuracy: 0.8286\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5959 - accuracy: 0.8289\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5850 - accuracy: 0.8317\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5810 - accuracy: 0.8325\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5731 - accuracy: 0.8360\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5564 - accuracy: 0.8409\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5547 - accuracy: 0.8420\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5423 - accuracy: 0.8457\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5412 - accuracy: 0.8445\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5376 - accuracy: 0.8462\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5227 - accuracy: 0.8512\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5143 - accuracy: 0.8543\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5105 - accuracy: 0.8542\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5035 - accuracy: 0.8580\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5070 - accuracy: 0.8545\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4943 - accuracy: 0.8609\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4871 - accuracy: 0.8614\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4821 - accuracy: 0.8633\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4724 - accuracy: 0.8675\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4727 - accuracy: 0.8652\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4618 - accuracy: 0.8692\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4646 - accuracy: 0.8695\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4495 - accuracy: 0.8755\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4433 - accuracy: 0.8763\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4363 - accuracy: 0.8777\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4363 - accuracy: 0.8795\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4431 - accuracy: 0.8749\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4304 - accuracy: 0.8805\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4265 - accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4149 - accuracy: 0.8865\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4143 - accuracy: 0.8847\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4049 - accuracy: 0.8882\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4009 - accuracy: 0.8898\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3946 - accuracy: 0.8918\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3966 - accuracy: 0.8908\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3858 - accuracy: 0.8951\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3919 - accuracy: 0.8917\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3820 - accuracy: 0.8970\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3696 - accuracy: 0.9020\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3669 - accuracy: 0.9023\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3787 - accuracy: 0.8976\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3575 - accuracy: 0.9056\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3590 - accuracy: 0.9045\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3621 - accuracy: 0.9023\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3518 - accuracy: 0.9070\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3463 - accuracy: 0.9085\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3452 - accuracy: 0.9073\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3377 - accuracy: 0.9114\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3391 - accuracy: 0.9114\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3355 - accuracy: 0.9118\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3333 - accuracy: 0.9133\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3253 - accuracy: 0.9171\n",
      "60000/60000 [==============================] - 9s 145us/step\n",
      "Validation accuracy:  0.8482833504676819\n",
      "Tial_num - 7/100, learning_rate: 0.0023511060056369947, Lambda: 0.0008181423672449014\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 39us/step - loss: 2.6358 - accuracy: 0.1017\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.4223 - accuracy: 0.1301\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.3335 - accuracy: 0.1555\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2770 - accuracy: 0.1807\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2353 - accuracy: 0.2027\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1994 - accuracy: 0.2227\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1663 - accuracy: 0.2395\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.1348 - accuracy: 0.2566\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1037 - accuracy: 0.2730\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0725 - accuracy: 0.2915\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0411 - accuracy: 0.3086\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.0103 - accuracy: 0.3237\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9782 - accuracy: 0.3407\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9457 - accuracy: 0.3539\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9144 - accuracy: 0.3686\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8828 - accuracy: 0.3819\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8512 - accuracy: 0.3980\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8205 - accuracy: 0.4096\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7899 - accuracy: 0.4250\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7609 - accuracy: 0.4367\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7307 - accuracy: 0.4505\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7027 - accuracy: 0.4626\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6734 - accuracy: 0.4743\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6458 - accuracy: 0.4847\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6188 - accuracy: 0.4956\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5911 - accuracy: 0.5049\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5650 - accuracy: 0.5161\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5388 - accuracy: 0.5273\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5136 - accuracy: 0.5380\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4890 - accuracy: 0.5450\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4644 - accuracy: 0.5560\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4404 - accuracy: 0.5651\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4182 - accuracy: 0.5731\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3964 - accuracy: 0.5821\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3744 - accuracy: 0.5904\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3525 - accuracy: 0.5976\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3336 - accuracy: 0.6024\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.3141 - accuracy: 0.6104\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2947 - accuracy: 0.6175\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2765 - accuracy: 0.6227\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2593 - accuracy: 0.6286\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2434 - accuracy: 0.6325\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2265 - accuracy: 0.6385\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2103 - accuracy: 0.6445\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1949 - accuracy: 0.6490\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1800 - accuracy: 0.6528\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1653 - accuracy: 0.6567\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1507 - accuracy: 0.6625\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1392 - accuracy: 0.6656\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1274 - accuracy: 0.6681\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.1127 - accuracy: 0.6728\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.1023 - accuracy: 0.6740\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.0885 - accuracy: 0.6816\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0781 - accuracy: 0.6824\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0658 - accuracy: 0.6858\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0572 - accuracy: 0.6890\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0454 - accuracy: 0.6936\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0363 - accuracy: 0.6948\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0251 - accuracy: 0.6983\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0165 - accuracy: 0.6998\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.0065 - accuracy: 0.7051\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9966 - accuracy: 0.7058\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9879 - accuracy: 0.7093\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9789 - accuracy: 0.7128\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9723 - accuracy: 0.7134\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.9624 - accuracy: 0.7170\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.9531 - accuracy: 0.7207\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.9465 - accuracy: 0.7218\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.9365 - accuracy: 0.7268\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.9307 - accuracy: 0.7264\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9235 - accuracy: 0.7290\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9152 - accuracy: 0.7297\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9077 - accuracy: 0.7353\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9008 - accuracy: 0.7358\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8916 - accuracy: 0.7392\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8870 - accuracy: 0.7395\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8801 - accuracy: 0.7420\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8731 - accuracy: 0.7444\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8663 - accuracy: 0.7451\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8601 - accuracy: 0.7491\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8526 - accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8476 - accuracy: 0.7512\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8423 - accuracy: 0.7525\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8348 - accuracy: 0.7552\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8302 - accuracy: 0.7567\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8237 - accuracy: 0.7581\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8173 - accuracy: 0.7593\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8121 - accuracy: 0.7621\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.8080 - accuracy: 0.7627\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7998 - accuracy: 0.7657\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7964 - accuracy: 0.7646\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7901 - accuracy: 0.7670\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7835 - accuracy: 0.7703\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7786 - accuracy: 0.7728\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7746 - accuracy: 0.7728\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7682 - accuracy: 0.7761\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7632 - accuracy: 0.7760\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7579 - accuracy: 0.7783\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7536 - accuracy: 0.7785\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7480 - accuracy: 0.7813\n",
      "60000/60000 [==============================] - 9s 147us/step\n",
      "Validation accuracy:  0.7627500295639038\n",
      "Tial_num - 8/100, learning_rate: 0.0007268562018639155, Lambda: 0.00025870539112420114\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 43us/step - loss: 2.1242 - accuracy: 0.2986\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.5270 - accuracy: 0.5365\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.1988 - accuracy: 0.6539\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.0606 - accuracy: 0.6956\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.9311 - accuracy: 0.7378\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.8649 - accuracy: 0.7559\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7996 - accuracy: 0.7769\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7577 - accuracy: 0.7891\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.7062 - accuracy: 0.8037\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.6747 - accuracy: 0.8133\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6321 - accuracy: 0.8273\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6127 - accuracy: 0.8307\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5849 - accuracy: 0.8408\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5556 - accuracy: 0.8484\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5439 - accuracy: 0.8521\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.5188 - accuracy: 0.8609\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4963 - accuracy: 0.8691\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4809 - accuracy: 0.8712\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4610 - accuracy: 0.8804\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4490 - accuracy: 0.8836\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.4374 - accuracy: 0.8872\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4247 - accuracy: 0.8904\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.4122 - accuracy: 0.8958\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3955 - accuracy: 0.9016\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3819 - accuracy: 0.9034\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3737 - accuracy: 0.9070\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3646 - accuracy: 0.9098\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3416 - accuracy: 0.9193\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3391 - accuracy: 0.9189\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3250 - accuracy: 0.9258\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3237 - accuracy: 0.9245\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.3204 - accuracy: 0.9248\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3022 - accuracy: 0.9317\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2958 - accuracy: 0.9338\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2924 - accuracy: 0.9358\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 0.2837 - accuracy: 0.9372\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2718 - accuracy: 0.9424\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2677 - accuracy: 0.9443\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2506 - accuracy: 0.9495\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2519 - accuracy: 0.9488\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2499 - accuracy: 0.9491\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2375 - accuracy: 0.9528\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2319 - accuracy: 0.9551\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2239 - accuracy: 0.9585\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2307 - accuracy: 0.9553\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.2189 - accuracy: 0.9594\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.2179 - accuracy: 0.9605\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.2034 - accuracy: 0.9652\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.2054 - accuracy: 0.9644\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1949 - accuracy: 0.9681\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1871 - accuracy: 0.9709\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1829 - accuracy: 0.9717\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1906 - accuracy: 0.9674\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1714 - accuracy: 0.9759\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1832 - accuracy: 0.9718\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1620 - accuracy: 0.9795\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1662 - accuracy: 0.9777\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1577 - accuracy: 0.9811\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1597 - accuracy: 0.9791\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1531 - accuracy: 0.9816\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1495 - accuracy: 0.9831\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1444 - accuracy: 0.9844\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1461 - accuracy: 0.9837\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1348 - accuracy: 0.9878\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1380 - accuracy: 0.9865\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1348 - accuracy: 0.9873\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1268 - accuracy: 0.9899\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1331 - accuracy: 0.9867\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1237 - accuracy: 0.9908\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1241 - accuracy: 0.9904\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1228 - accuracy: 0.9909\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1178 - accuracy: 0.9925\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1139 - accuracy: 0.9934\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1145 - accuracy: 0.9927\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1137 - accuracy: 0.9924\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1099 - accuracy: 0.9944\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.1061 - accuracy: 0.9950\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1089 - accuracy: 0.9936\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1030 - accuracy: 0.9955\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1012 - accuracy: 0.9958\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0992 - accuracy: 0.9962\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.1032 - accuracy: 0.9945\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0990 - accuracy: 0.9959\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0975 - accuracy: 0.9964\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0971 - accuracy: 0.9967\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0930 - accuracy: 0.9972\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0931 - accuracy: 0.9969\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0929 - accuracy: 0.9972\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0897 - accuracy: 0.9977\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0878 - accuracy: 0.9982\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0886 - accuracy: 0.9982\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0868 - accuracy: 0.9981\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0869 - accuracy: 0.9982\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0867 - accuracy: 0.9979\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0839 - accuracy: 0.9987\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0834 - accuracy: 0.9983\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.0839 - accuracy: 0.9982\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0815 - accuracy: 0.9987\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0813 - accuracy: 0.9987\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.0809 - accuracy: 0.9988\n",
      "60000/60000 [==============================] - 9s 146us/step\n",
      "Validation accuracy:  0.9424999952316284\n",
      "Tial_num - 9/100, learning_rate: 0.04959044312283231, Lambda: 0.005080746864709904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,10):\n",
    "    learning_rate = math.pow(10, np.random.uniform(-4.0, -1.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-4,-2))\n",
    "    good_score = improving_model(learning_rate = learning_rate, Lambda= Lambda, epochs=100)  \n",
    "    print(\"Tial_num - {0}/{1}, learning_rate: {2}, Lambda: {3}\\n\".format(x, 100, learning_rate, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "    It can be found that in the trial seven we have very good performance where the performance of the model on the training data is 91.71% and on the validation data is 84.82%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step d : Building the model on the Finalized Learning Rate:\n",
    "    Here, we build the model with learning rate that gave good performance in the above trial -5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c6RRWtFjAtyO",
    "outputId": "b853f9f7-4f9e-41c6-9e75-e96d7df9d5b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 3s 77us/step - loss: 2.5346 - accuracy: 0.1390\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.2247 - accuracy: 0.1977\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 2.1098 - accuracy: 0.2474\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.9981 - accuracy: 0.3006\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.8798 - accuracy: 0.3569\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.7613 - accuracy: 0.4094\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.6556 - accuracy: 0.4602\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.5623 - accuracy: 0.5010\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4822 - accuracy: 0.5345\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.4140 - accuracy: 0.5616\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.3501 - accuracy: 0.5853\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2956 - accuracy: 0.6044\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2468 - accuracy: 0.6224\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.2007 - accuracy: 0.6366\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.1617 - accuracy: 0.6506\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.1235 - accuracy: 0.6627\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0888 - accuracy: 0.6715\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0576 - accuracy: 0.6838\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 1.0298 - accuracy: 0.6939\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 1.0020 - accuracy: 0.7002\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.9759 - accuracy: 0.7091\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.9526 - accuracy: 0.7160\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.9306 - accuracy: 0.7222\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.9069 - accuracy: 0.7302\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8868 - accuracy: 0.7362\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8678 - accuracy: 0.7424\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8529 - accuracy: 0.7461\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8328 - accuracy: 0.7527\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8178 - accuracy: 0.7572\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.8029 - accuracy: 0.7630\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7855 - accuracy: 0.7676\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7665 - accuracy: 0.7736\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7579 - accuracy: 0.7765\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7429 - accuracy: 0.7829\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.7328 - accuracy: 0.7827\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7199 - accuracy: 0.7877\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.7010 - accuracy: 0.7939\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.6912 - accuracy: 0.7983\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.6825 - accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.6686 - accuracy: 0.8049\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.6568 - accuracy: 0.8094\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.6540 - accuracy: 0.8087\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.6422 - accuracy: 0.8135\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.6277 - accuracy: 0.8165\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.6230 - accuracy: 0.8185\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.6072 - accuracy: 0.8252\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5988 - accuracy: 0.8262\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5870 - accuracy: 0.8315\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5836 - accuracy: 0.8310\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5788 - accuracy: 0.8325\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5763 - accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5572 - accuracy: 0.8400\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5537 - accuracy: 0.8404\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5465 - accuracy: 0.8423\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5368 - accuracy: 0.8460\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.5316 - accuracy: 0.8480\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5223 - accuracy: 0.8502\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5145 - accuracy: 0.8524\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.5127 - accuracy: 0.8533\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4986 - accuracy: 0.8575\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4969 - accuracy: 0.8580\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4927 - accuracy: 0.8592\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4829 - accuracy: 0.8632\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4737 - accuracy: 0.8661\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4780 - accuracy: 0.8636\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4657 - accuracy: 0.8689\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4671 - accuracy: 0.8675\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4574 - accuracy: 0.8720\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4516 - accuracy: 0.8732\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4479 - accuracy: 0.8736\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4391 - accuracy: 0.8763\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4274 - accuracy: 0.8829\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4311 - accuracy: 0.8794\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4243 - accuracy: 0.8806\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4153 - accuracy: 0.8871\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4163 - accuracy: 0.8858\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.4058 - accuracy: 0.8875\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3993 - accuracy: 0.8912\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3977 - accuracy: 0.8912\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3924 - accuracy: 0.8940\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3934 - accuracy: 0.8915\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3878 - accuracy: 0.8941\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3789 - accuracy: 0.8973\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3786 - accuracy: 0.8954\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3756 - accuracy: 0.8981\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3643 - accuracy: 0.9024\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3650 - accuracy: 0.9031\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3590 - accuracy: 0.9039\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3515 - accuracy: 0.9062\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3456 - accuracy: 0.9091\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3541 - accuracy: 0.9049\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3452 - accuracy: 0.9086\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3398 - accuracy: 0.9087\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3353 - accuracy: 0.9126\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3298 - accuracy: 0.9141\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 21us/step - loss: 0.3258 - accuracy: 0.9151\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3307 - accuracy: 0.9139\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3203 - accuracy: 0.9180\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3115 - accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 20us/step - loss: 0.3124 - accuracy: 0.9206\n",
      "60000/60000 [==============================] - 9s 152us/step\n",
      "Validation accuracy:  0.8508833050727844\n"
     ]
    }
   ],
   "source": [
    "improving_model( learning_rate = 0.0023511060056369947, Lambda= 0.0008181423672449014, epochs= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. With the above given Learning rate and Lambda the model performs well on both training and validation data.\n",
    "2. But, there is huge difference in the performance percentages.\n",
    "3. This diffenrence should also be avoided by tuning some other hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oe7XHOeoLcG"
   },
   "source": [
    "   The finalizing of the model can be done after further improving the model that was built in the Trial-4 of the Model 2 above particulary the model that was optimized by thr Adam Optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KL_dnMSusSSL"
   },
   "source": [
    "#### Step e: Improving the  model in the Trial - 4 of Model - 2:\n",
    "\n",
    "    1. Here the model in the Trial - 4 of Model - 2 is improved by tuning the hyperparameters learning rate and lambda because in the before trial there was some difference in the model's performance on the training and validation data.\n",
    "    \n",
    "    2. Inintially let us try improving the model by tunning the learning rate based on the results we can tune the lambda of the Ridge Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copying the model  and making it as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XbFox8PtRHx"
   },
   "outputs": [],
   "source": [
    "def adam_model_improvement( learning_rate ,Lambda, epochs):\n",
    "    model_bn = Sequential()\n",
    "\n",
    "    model_bn.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True))\n",
    "    model_bn.add(Activation('relu'))\n",
    " \n",
    "    model_bn.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(10, name ='Output_Layer', kernel_regularizer = l2(Lambda)))\n",
    "    model_bn.add(Activation('softmax'))\n",
    "\n",
    "    #Adam optimizer:\n",
    "    adam = Adam(learning_rate)\n",
    "    model_bn.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    history_bn_adam = model_bn.fit(X_train, y_train, batch_size = 1000, epochs = epochs, verbose = 1)\n",
    "\n",
    "    evaluation_val_bt_ad = model_bn.evaluate(X_val, y_val)\n",
    "    print('Validation accuracy: ', evaluation_val_bt_ad[1])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCZmFaZvjKKM"
   },
   "source": [
    "#### Trial - 1: Coarse Tuning the adam model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4uOGxqNjhwWJ",
    "outputId": "f36c541c-d3e2-4d02-ddfc-9c068a18dda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 1.8711 - accuracy: 0.3795\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2297 - accuracy: 0.6513\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9479 - accuracy: 0.7278\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7814 - accuracy: 0.7714\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6799 - accuracy: 0.7969\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6041 - accuracy: 0.8166\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5452 - accuracy: 0.8354\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4847 - accuracy: 0.8537\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4536 - accuracy: 0.8612\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4189 - accuracy: 0.8736\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3857 - accuracy: 0.8817\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3526 - accuracy: 0.8924\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3304 - accuracy: 0.9016\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2992 - accuracy: 0.9109\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.2952 - accuracy: 0.9098\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2679 - accuracy: 0.9197\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2497 - accuracy: 0.9253\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.2368 - accuracy: 0.9295\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.2217 - accuracy: 0.9347\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.2074 - accuracy: 0.9379\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1921 - accuracy: 0.9430\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1803 - accuracy: 0.9467\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1674 - accuracy: 0.9510\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1583 - accuracy: 0.9530\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1567 - accuracy: 0.9538\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1537 - accuracy: 0.9542\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1403 - accuracy: 0.9595\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1375 - accuracy: 0.9596\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1278 - accuracy: 0.9625\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1178 - accuracy: 0.9653\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1132 - accuracy: 0.9663\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1077 - accuracy: 0.9681\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0975 - accuracy: 0.9721\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0970 - accuracy: 0.9721\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0920 - accuracy: 0.9732\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0872 - accuracy: 0.9749\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0921 - accuracy: 0.9725\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0858 - accuracy: 0.9742\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0812 - accuracy: 0.9765\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0925 - accuracy: 0.9730\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0842 - accuracy: 0.9755\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0714 - accuracy: 0.9793\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0701 - accuracy: 0.9798\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0668 - accuracy: 0.9805\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0702 - accuracy: 0.9800\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0594 - accuracy: 0.9826\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0602 - accuracy: 0.9824\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0584 - accuracy: 0.9834\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0583 - accuracy: 0.9828\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0628 - accuracy: 0.9821\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0511 - accuracy: 0.9856\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0533 - accuracy: 0.9848\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0599 - accuracy: 0.9829\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0669 - accuracy: 0.9799\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0534 - accuracy: 0.9849\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0463 - accuracy: 0.9870\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0647 - accuracy: 0.9812\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0628 - accuracy: 0.9809\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0517 - accuracy: 0.9849\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0479 - accuracy: 0.9862\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0447 - accuracy: 0.9873\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0548 - accuracy: 0.9838\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0469 - accuracy: 0.9865\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0409 - accuracy: 0.9886\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0407 - accuracy: 0.9895\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0411 - accuracy: 0.9883\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0386 - accuracy: 0.9896\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0394 - accuracy: 0.9890\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0343 - accuracy: 0.9903\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0309 - accuracy: 0.9918\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0323 - accuracy: 0.9916\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0339 - accuracy: 0.9907\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0302 - accuracy: 0.9920\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0294 - accuracy: 0.9921\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0407 - accuracy: 0.9885\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0499 - accuracy: 0.9852\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0470 - accuracy: 0.9857\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0408 - accuracy: 0.9885\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0394 - accuracy: 0.9886\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0416 - accuracy: 0.9881\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0383 - accuracy: 0.9890\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0383 - accuracy: 0.9890\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0395 - accuracy: 0.9891\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0352 - accuracy: 0.9900\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0346 - accuracy: 0.9902\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0318 - accuracy: 0.9914\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0264 - accuracy: 0.9927\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0278 - accuracy: 0.9923\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0344 - accuracy: 0.9901\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0346 - accuracy: 0.9908\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0305 - accuracy: 0.9920\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0296 - accuracy: 0.9921\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0256 - accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0335 - accuracy: 0.9907\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0355 - accuracy: 0.9908\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0327 - accuracy: 0.9910\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0413 - accuracy: 0.9885\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0365 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0319 - accuracy: 0.9910\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0281 - accuracy: 0.9930\n",
      "60000/60000 [==============================] - 5s 83us/step\n",
      "Validation accuracy:  0.8430666923522949\n",
      "Try 1/100: Good_Validation_acc: None, learning_rate: 0.0009005530700980163, Lambda: 6.790739561828946e-05\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 3100.1829 - accuracy: 0.1002\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 144.2696 - accuracy: 0.0996\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 36.5484 - accuracy: 0.1004\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 39.9225 - accuracy: 0.1003\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 38.9695 - accuracy: 0.0993\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 42.5164 - accuracy: 0.1004\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 32.3655 - accuracy: 0.0985\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 34.6052 - accuracy: 0.0995\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 39.3833 - accuracy: 0.1014\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 38.6774 - accuracy: 0.0998\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 31.9406 - accuracy: 0.0987\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 43.7454 - accuracy: 0.0998\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 48.8157 - accuracy: 0.1002\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 48.5616 - accuracy: 0.1006\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 41.7854 - accuracy: 0.0990\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 49.3027 - accuracy: 0.0998\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 49.0158 - accuracy: 0.1014\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 36.1899 - accuracy: 0.0996\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 39.0085 - accuracy: 0.0987\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 38.5420 - accuracy: 0.0987\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 43.9206 - accuracy: 0.1032\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 36.4056 - accuracy: 0.1022\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 42.4935 - accuracy: 0.1005\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 36.8459 - accuracy: 0.1025\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 36.5041 - accuracy: 0.1001\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 41.8156 - accuracy: 0.1006\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 36.4959 - accuracy: 0.0972\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 40.6172 - accuracy: 0.1010\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 35.9547 - accuracy: 0.0999\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 36.9364 - accuracy: 0.0993\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 39.8554 - accuracy: 0.0985\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 47.9941 - accuracy: 0.0993\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 32.3379 - accuracy: 0.1009\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 37.9925 - accuracy: 0.0986\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 46.1772 - accuracy: 0.0980\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 42.7673 - accuracy: 0.1004\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 30.6168 - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 40.9840 - accuracy: 0.0985\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 45.8520 - accuracy: 0.0985\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 38.7768 - accuracy: 0.1029\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 43.5519 - accuracy: 0.0994\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 36.4879 - accuracy: 0.0971\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 38.1243 - accuracy: 0.0975\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 45.0409 - accuracy: 0.0999\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 49.4041 - accuracy: 0.1002\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 42.7223 - accuracy: 0.1003\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 40.9681 - accuracy: 0.0983\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 44.1123 - accuracy: 0.1014\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 42.9869 - accuracy: 0.1006\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 34.2789 - accuracy: 0.1034\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 45.4341 - accuracy: 0.0992\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 33.4208 - accuracy: 0.1015\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 37.0884 - accuracy: 0.1002\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 35.7743 - accuracy: 0.1014\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 33.8869 - accuracy: 0.1008\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 35.0778 - accuracy: 0.0999\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 43.2088 - accuracy: 0.0997\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 37.1359 - accuracy: 0.0991\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 48.0099 - accuracy: 0.0993\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 36.2945 - accuracy: 0.1021\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 49.7522 - accuracy: 0.1005\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 47.4841 - accuracy: 0.1006\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 48.7165 - accuracy: 0.1010\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 39.1508 - accuracy: 0.0998\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 38.5822 - accuracy: 0.1002\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 44.0037 - accuracy: 0.0998\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 37.9196 - accuracy: 0.1000\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 45.1120 - accuracy: 0.0998\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 52.9786 - accuracy: 0.0995\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 32.0724 - accuracy: 0.1006\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 40.4539 - accuracy: 0.1024\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 31.0235 - accuracy: 0.1027\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 39.5654 - accuracy: 0.1010\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 33.8154 - accuracy: 0.1006\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 30.1215 - accuracy: 0.0990\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 32.8532 - accuracy: 0.0993\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 35.3811 - accuracy: 0.0995\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 33.2044 - accuracy: 0.0993\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 51.5169 - accuracy: 0.0992\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 53.8796 - accuracy: 0.0976\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 48.7570 - accuracy: 0.0979\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 50.9994 - accuracy: 0.1009\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 42.0669 - accuracy: 0.0988\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 37.6583 - accuracy: 0.0974\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 42.2355 - accuracy: 0.1010\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 38.9825 - accuracy: 0.1011\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 38.9352 - accuracy: 0.0997\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 42.3388 - accuracy: 0.1016\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 46.7068 - accuracy: 0.1010\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 46.6890 - accuracy: 0.1006\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 42.9786 - accuracy: 0.0998\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 35.4462 - accuracy: 0.0981\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 36.1947 - accuracy: 0.0993\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 37.7314 - accuracy: 0.1004\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 37.0137 - accuracy: 0.1031\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 32.9422 - accuracy: 0.0980\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 43.9649 - accuracy: 0.1001\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 51.0962 - accuracy: 0.0991\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 36.0599 - accuracy: 0.0993\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 44.0556 - accuracy: 0.1003\n",
      "60000/60000 [==============================] - 5s 83us/step\n",
      "Validation accuracy:  0.10000000149011612\n",
      "Try 2/100: Good_Validation_acc: None, learning_rate: 81.60407314386795, Lambda: 0.001791327905290216\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 31us/step - loss: 1.8125 - accuracy: 0.3726\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1259 - accuracy: 0.6332\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9041 - accuracy: 0.7102\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7793 - accuracy: 0.7505\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6940 - accuracy: 0.7786\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6260 - accuracy: 0.8001\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5682 - accuracy: 0.8202\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5471 - accuracy: 0.8260\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4903 - accuracy: 0.8448\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4595 - accuracy: 0.8546\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4250 - accuracy: 0.8633\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4026 - accuracy: 0.8706\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3693 - accuracy: 0.8845\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3472 - accuracy: 0.8889\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3278 - accuracy: 0.8969\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3030 - accuracy: 0.9048\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2896 - accuracy: 0.9087\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2851 - accuracy: 0.9088\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2623 - accuracy: 0.9167\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2406 - accuracy: 0.9228\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2322 - accuracy: 0.9250\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2166 - accuracy: 0.9310\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1955 - accuracy: 0.9387\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1819 - accuracy: 0.9422\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1795 - accuracy: 0.9423\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1764 - accuracy: 0.9431\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1709 - accuracy: 0.9445\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1494 - accuracy: 0.9516\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1460 - accuracy: 0.9515\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1366 - accuracy: 0.9562\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1463 - accuracy: 0.9537\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1159 - accuracy: 0.9628\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1295 - accuracy: 0.9580\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1226 - accuracy: 0.9589\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1051 - accuracy: 0.9654\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1179 - accuracy: 0.9612\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1015 - accuracy: 0.9660\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0922 - accuracy: 0.9695\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1041 - accuracy: 0.9658\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1134 - accuracy: 0.9626\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0952 - accuracy: 0.9696\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0822 - accuracy: 0.9737\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0684 - accuracy: 0.9774\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0637 - accuracy: 0.9796\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0634 - accuracy: 0.9788\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0669 - accuracy: 0.9779\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0768 - accuracy: 0.9740\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0849 - accuracy: 0.9720\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0748 - accuracy: 0.9753\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0696 - accuracy: 0.9770\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0624 - accuracy: 0.9798\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0677 - accuracy: 0.9780\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0573 - accuracy: 0.9805\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0585 - accuracy: 0.9804\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0587 - accuracy: 0.9810\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0565 - accuracy: 0.9813\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0647 - accuracy: 0.9789\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0565 - accuracy: 0.9821\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0468 - accuracy: 0.9845\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0448 - accuracy: 0.9851\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0531 - accuracy: 0.9821\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0448 - accuracy: 0.9852\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0446 - accuracy: 0.9848\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0476 - accuracy: 0.9842\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0496 - accuracy: 0.9826\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0628 - accuracy: 0.9797\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0477 - accuracy: 0.9840\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0329 - accuracy: 0.9896\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0284 - accuracy: 0.9911\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0352 - accuracy: 0.9890\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0477 - accuracy: 0.9838\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0467 - accuracy: 0.9839\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0386 - accuracy: 0.9867\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0305 - accuracy: 0.9899\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0314 - accuracy: 0.9894\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0387 - accuracy: 0.9875\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0389 - accuracy: 0.9877\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0397 - accuracy: 0.9864\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0329 - accuracy: 0.9893\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0451 - accuracy: 0.9846\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0589 - accuracy: 0.9801\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0406 - accuracy: 0.9868\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0284 - accuracy: 0.9910\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0260 - accuracy: 0.9914\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0295 - accuracy: 0.9904\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0356 - accuracy: 0.9884\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0292 - accuracy: 0.9904\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0377 - accuracy: 0.9875\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0428 - accuracy: 0.9858\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0384 - accuracy: 0.9868\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0296 - accuracy: 0.9902\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0331 - accuracy: 0.9897\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0390 - accuracy: 0.9875\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0312 - accuracy: 0.9894\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0376 - accuracy: 0.9876\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0338 - accuracy: 0.9892\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0296 - accuracy: 0.9905\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0254 - accuracy: 0.9914\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0259 - accuracy: 0.9921\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0333 - accuracy: 0.9892\n",
      "60000/60000 [==============================] - 5s 84us/step\n",
      "Validation accuracy:  0.7785000205039978\n",
      "Try 3/100: Good_Validation_acc: None, learning_rate: 0.0043620913755449625, Lambda: 1.84376552890319e-06\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 2.4359 - accuracy: 0.1330\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2136 - accuracy: 0.2064\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0585 - accuracy: 0.2740\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9349 - accuracy: 0.3374\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8327 - accuracy: 0.3907\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7458 - accuracy: 0.4372\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6727 - accuracy: 0.4757\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6076 - accuracy: 0.5131\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5518 - accuracy: 0.5429\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5007 - accuracy: 0.5691\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4534 - accuracy: 0.5933\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4111 - accuracy: 0.6112\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3707 - accuracy: 0.6309\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3331 - accuracy: 0.6477\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2952 - accuracy: 0.6631\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2614 - accuracy: 0.6790\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2286 - accuracy: 0.6898\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1970 - accuracy: 0.7010\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1668 - accuracy: 0.7133\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1374 - accuracy: 0.7253\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1093 - accuracy: 0.7338\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0816 - accuracy: 0.7443\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0542 - accuracy: 0.7542\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0291 - accuracy: 0.7629\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0050 - accuracy: 0.7689\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9794 - accuracy: 0.7792\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9577 - accuracy: 0.7846\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9344 - accuracy: 0.7931\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9133 - accuracy: 0.7996\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8900 - accuracy: 0.8052\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8713 - accuracy: 0.8108\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8504 - accuracy: 0.8166\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8314 - accuracy: 0.8209\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8109 - accuracy: 0.8283\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7921 - accuracy: 0.8331\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7748 - accuracy: 0.8376\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7563 - accuracy: 0.8426\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7389 - accuracy: 0.8467\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7223 - accuracy: 0.8521\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7075 - accuracy: 0.8551\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6906 - accuracy: 0.8585\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6737 - accuracy: 0.8644\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6592 - accuracy: 0.8677\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6430 - accuracy: 0.8724\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6283 - accuracy: 0.8772\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6132 - accuracy: 0.8802\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5991 - accuracy: 0.8827\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5853 - accuracy: 0.8878\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5731 - accuracy: 0.8890\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5597 - accuracy: 0.8929\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5474 - accuracy: 0.8968\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5321 - accuracy: 0.9005\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5203 - accuracy: 0.9031\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5083 - accuracy: 0.9068\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4963 - accuracy: 0.9098\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4853 - accuracy: 0.9126\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4740 - accuracy: 0.9162\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4631 - accuracy: 0.9188\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4521 - accuracy: 0.9212\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4415 - accuracy: 0.9233\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4320 - accuracy: 0.9260\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4210 - accuracy: 0.9280\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4136 - accuracy: 0.9296\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4015 - accuracy: 0.9340\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3913 - accuracy: 0.9355\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3832 - accuracy: 0.9373\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3740 - accuracy: 0.9405\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3649 - accuracy: 0.9422\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3556 - accuracy: 0.9441\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3485 - accuracy: 0.9457\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3408 - accuracy: 0.9470\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3319 - accuracy: 0.9496\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3241 - accuracy: 0.9508\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3174 - accuracy: 0.9528\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3095 - accuracy: 0.9545\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3023 - accuracy: 0.9556\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2955 - accuracy: 0.9570\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2879 - accuracy: 0.9591\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2814 - accuracy: 0.9596\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2758 - accuracy: 0.9609\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2686 - accuracy: 0.9628\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2609 - accuracy: 0.9642\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2558 - accuracy: 0.9646\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2500 - accuracy: 0.9660\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2441 - accuracy: 0.9677\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2388 - accuracy: 0.9681\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2320 - accuracy: 0.9694\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2268 - accuracy: 0.9706\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2188 - accuracy: 0.9730\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2159 - accuracy: 0.9734\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2109 - accuracy: 0.9742\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2078 - accuracy: 0.9741\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2005 - accuracy: 0.9755\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1965 - accuracy: 0.9776\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1920 - accuracy: 0.9779\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1865 - accuracy: 0.9785\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1819 - accuracy: 0.9799\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1777 - accuracy: 0.9796\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1726 - accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1676 - accuracy: 0.9825\n",
      "60000/60000 [==============================] - 5s 82us/step\n",
      "Validation accuracy:  0.9115333557128906\n",
      "Try 4/100: Good_Validation_acc: None, learning_rate: 3.143173543006022e-05, Lambda: 2.604614204048309e-07\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 31us/step - loss: 2.1147 - accuracy: 0.2541\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.6187 - accuracy: 0.4933\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3389 - accuracy: 0.6242\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1446 - accuracy: 0.6962\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9985 - accuracy: 0.7400\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8803 - accuracy: 0.7731\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7845 - accuracy: 0.7982\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7029 - accuracy: 0.8232\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6329 - accuracy: 0.8389\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5770 - accuracy: 0.8525\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5209 - accuracy: 0.8696\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4731 - accuracy: 0.8819\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4285 - accuracy: 0.8937\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.3946 - accuracy: 0.9027\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3586 - accuracy: 0.9121\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3284 - accuracy: 0.9211\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2990 - accuracy: 0.9282\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.2769 - accuracy: 0.9348\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2494 - accuracy: 0.9429\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.2340 - accuracy: 0.9462\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2151 - accuracy: 0.9522\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2036 - accuracy: 0.9538\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1900 - accuracy: 0.9577\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1702 - accuracy: 0.9640\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1597 - accuracy: 0.9661\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1473 - accuracy: 0.9692\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1408 - accuracy: 0.9699\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1296 - accuracy: 0.9733\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1130 - accuracy: 0.9779\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1141 - accuracy: 0.9761\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1124 - accuracy: 0.9762\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0984 - accuracy: 0.9819\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0886 - accuracy: 0.9836\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0953 - accuracy: 0.9799\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0888 - accuracy: 0.9823\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0764 - accuracy: 0.9857\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0783 - accuracy: 0.9843\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0799 - accuracy: 0.9833\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0685 - accuracy: 0.9874\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0637 - accuracy: 0.9883\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0604 - accuracy: 0.9889\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0680 - accuracy: 0.9862\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0582 - accuracy: 0.9895\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0573 - accuracy: 0.9894\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0578 - accuracy: 0.9886\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0593 - accuracy: 0.9880\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0623 - accuracy: 0.9869\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0528 - accuracy: 0.9901\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0499 - accuracy: 0.9912\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0535 - accuracy: 0.9891\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0451 - accuracy: 0.9916\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0399 - accuracy: 0.9933\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0366 - accuracy: 0.9941\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0419 - accuracy: 0.9923\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0399 - accuracy: 0.9926\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0386 - accuracy: 0.9930\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0400 - accuracy: 0.9925\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0435 - accuracy: 0.9909\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0490 - accuracy: 0.9893\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0509 - accuracy: 0.9881\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0503 - accuracy: 0.9884\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0382 - accuracy: 0.9929\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0317 - accuracy: 0.9947\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0359 - accuracy: 0.9929\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0325 - accuracy: 0.9943\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0318 - accuracy: 0.9942\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0274 - accuracy: 0.9958\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0263 - accuracy: 0.9959\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0278 - accuracy: 0.9955\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0275 - accuracy: 0.9954\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0363 - accuracy: 0.9926\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0439 - accuracy: 0.9903\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0467 - accuracy: 0.9888\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0576 - accuracy: 0.9858\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0478 - accuracy: 0.9886\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0357 - accuracy: 0.9928\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0363 - accuracy: 0.9926\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0277 - accuracy: 0.9952\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0267 - accuracy: 0.9952\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0284 - accuracy: 0.9945\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0253 - accuracy: 0.9956\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0255 - accuracy: 0.9951\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0296 - accuracy: 0.9940\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0294 - accuracy: 0.9940\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0362 - accuracy: 0.9918\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0493 - accuracy: 0.9880\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0517 - accuracy: 0.9866\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0471 - accuracy: 0.9875\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0405 - accuracy: 0.9905\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0327 - accuracy: 0.9928\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0277 - accuracy: 0.9945\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0212 - accuracy: 0.9968\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0255 - accuracy: 0.9951\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0209 - accuracy: 0.9968\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0145 - accuracy: 0.9986\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0155 - accuracy: 0.9979\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0172 - accuracy: 0.9975\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0154 - accuracy: 0.9980\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0175 - accuracy: 0.9976\n",
      "60000/60000 [==============================] - 5s 83us/step\n",
      "Validation accuracy:  0.8112833499908447\n",
      "Try 5/100: Good_Validation_acc: None, learning_rate: 0.0002344043377214389, Lambda: 0.00012517001742777526\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 24.1966 - accuracy: 0.1005\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0395 - accuracy: 0.0974\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8370 - accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7484 - accuracy: 0.1015\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6784 - accuracy: 0.0998\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6392 - accuracy: 0.0993\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6261 - accuracy: 0.1020\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5818 - accuracy: 0.0999\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5505 - accuracy: 0.1008\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5426 - accuracy: 0.1005\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5332 - accuracy: 0.0982\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5997 - accuracy: 0.1012\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6135 - accuracy: 0.1008\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9438 - accuracy: 0.1022\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7779 - accuracy: 0.0999\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.5058 - accuracy: 0.1002\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4962 - accuracy: 0.0991\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5051 - accuracy: 0.0994\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5099 - accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1812 - accuracy: 0.0995\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 8.1543 - accuracy: 0.1005\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 5.5793 - accuracy: 0.1023\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2270 - accuracy: 0.1010\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4497 - accuracy: 0.0995\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4128 - accuracy: 0.0992\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4145 - accuracy: 0.0984\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4043 - accuracy: 0.0986\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4279 - accuracy: 0.0968\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4031 - accuracy: 0.1006\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3983 - accuracy: 0.0977\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3947 - accuracy: 0.0984\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3949 - accuracy: 0.0987\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3916 - accuracy: 0.1018\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4118 - accuracy: 0.0999\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4120 - accuracy: 0.0981\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3991 - accuracy: 0.0983\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4211 - accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4015 - accuracy: 0.1022\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3815 - accuracy: 0.1027\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3848 - accuracy: 0.0986\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3908 - accuracy: 0.0996\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4030 - accuracy: 0.1010\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3831 - accuracy: 0.1010\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3726 - accuracy: 0.1005\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3700 - accuracy: 0.0975\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3830 - accuracy: 0.1002\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3720 - accuracy: 0.0999\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3757 - accuracy: 0.0985\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4021 - accuracy: 0.0989\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4028 - accuracy: 0.1009\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3777 - accuracy: 0.1011\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3670 - accuracy: 0.1007\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3842 - accuracy: 0.0983\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4178 - accuracy: 0.1002\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4803 - accuracy: 0.0994\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1752 - accuracy: 0.1011\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 9.5357 - accuracy: 0.1030\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 11.2755 - accuracy: 0.0966\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 4.2723 - accuracy: 0.1039\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4029 - accuracy: 0.0975\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3416 - accuracy: 0.0990\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3352 - accuracy: 0.1006\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3569 - accuracy: 0.0990\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3400 - accuracy: 0.0998\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3390 - accuracy: 0.0980\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3597 - accuracy: 0.0995\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3461 - accuracy: 0.1012\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3618 - accuracy: 0.1017\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3453 - accuracy: 0.0989\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3425 - accuracy: 0.0968\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3616 - accuracy: 0.1011\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3591 - accuracy: 0.1016\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3767 - accuracy: 0.0998\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3514 - accuracy: 0.1015\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3519 - accuracy: 0.1021\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3473 - accuracy: 0.0970\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3599 - accuracy: 0.1013\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3599 - accuracy: 0.1003\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3742 - accuracy: 0.0992\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3814 - accuracy: 0.0988\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3780 - accuracy: 0.1005\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3610 - accuracy: 0.1019\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3457 - accuracy: 0.1009\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3483 - accuracy: 0.0980\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3442 - accuracy: 0.0986\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3556 - accuracy: 0.0974\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4210 - accuracy: 0.0980\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4017 - accuracy: 0.0966\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3494 - accuracy: 0.1017\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4353 - accuracy: 0.0975\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4006 - accuracy: 0.0980\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3674 - accuracy: 0.0994\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3734 - accuracy: 0.1032\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3818 - accuracy: 0.0977\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0577 - accuracy: 0.0996\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 10.6494 - accuracy: 0.0990\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 8.4425 - accuracy: 0.1011\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.5561 - accuracy: 0.0995\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3493 - accuracy: 0.0993\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3366 - accuracy: 0.1011\n",
      "60000/60000 [==============================] - 5s 84us/step\n",
      "Validation accuracy:  0.10000000149011612\n",
      "Try 6/100: Good_Validation_acc: None, learning_rate: 8.874094848036101, Lambda: 8.927354748673503e-07\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 32us/step - loss: 1.8440 - accuracy: 0.3457\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2096 - accuracy: 0.5999\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9972 - accuracy: 0.6813\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8535 - accuracy: 0.7317\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7572 - accuracy: 0.7640\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6699 - accuracy: 0.7913\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6195 - accuracy: 0.8098\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5615 - accuracy: 0.8281\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5287 - accuracy: 0.8391\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4731 - accuracy: 0.8554\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4489 - accuracy: 0.8637\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4275 - accuracy: 0.8698\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3918 - accuracy: 0.8811\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3667 - accuracy: 0.8914\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3525 - accuracy: 0.8949\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3292 - accuracy: 0.9015\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3055 - accuracy: 0.9109\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2858 - accuracy: 0.9146\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2750 - accuracy: 0.9179\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2521 - accuracy: 0.9256\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2548 - accuracy: 0.9239\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2163 - accuracy: 0.9377\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2163 - accuracy: 0.9372\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2005 - accuracy: 0.9421\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1958 - accuracy: 0.9428\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1854 - accuracy: 0.9452\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1738 - accuracy: 0.9496\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1622 - accuracy: 0.9540\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1612 - accuracy: 0.9536\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1657 - accuracy: 0.9508\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1453 - accuracy: 0.9577\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1379 - accuracy: 0.9604\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1275 - accuracy: 0.9634\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1215 - accuracy: 0.9660\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1136 - accuracy: 0.9678\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1129 - accuracy: 0.9683\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1100 - accuracy: 0.9691\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1034 - accuracy: 0.9701\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1024 - accuracy: 0.9711\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0983 - accuracy: 0.9727\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0843 - accuracy: 0.9768\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0833 - accuracy: 0.9772\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0759 - accuracy: 0.9794\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0971 - accuracy: 0.9714\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0833 - accuracy: 0.9764\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0791 - accuracy: 0.9778\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0713 - accuracy: 0.9809\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0788 - accuracy: 0.9780\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0692 - accuracy: 0.9808\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0696 - accuracy: 0.9804\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0696 - accuracy: 0.9814\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0581 - accuracy: 0.9847\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0581 - accuracy: 0.9843\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0829 - accuracy: 0.9759\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0847 - accuracy: 0.9746\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0815 - accuracy: 0.9768\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0581 - accuracy: 0.9843\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0614 - accuracy: 0.9826\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0611 - accuracy: 0.9828\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0566 - accuracy: 0.9847\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0488 - accuracy: 0.9874\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0427 - accuracy: 0.9895\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0403 - accuracy: 0.9903\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0470 - accuracy: 0.9876\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0550 - accuracy: 0.9845\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0520 - accuracy: 0.9856\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0536 - accuracy: 0.9854\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0529 - accuracy: 0.9847\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0501 - accuracy: 0.9861\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0427 - accuracy: 0.9885\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0478 - accuracy: 0.9870\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0449 - accuracy: 0.9880\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0389 - accuracy: 0.9900\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0432 - accuracy: 0.9883\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0500 - accuracy: 0.9863\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0512 - accuracy: 0.9857\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0386 - accuracy: 0.9906\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0463 - accuracy: 0.9872\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0467 - accuracy: 0.9868\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0451 - accuracy: 0.9875\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0427 - accuracy: 0.9886\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0389 - accuracy: 0.9899\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0393 - accuracy: 0.9894\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0402 - accuracy: 0.9893\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0341 - accuracy: 0.9911\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0404 - accuracy: 0.9893\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0332 - accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0351 - accuracy: 0.9906\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0374 - accuracy: 0.9904\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0468 - accuracy: 0.9868\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0452 - accuracy: 0.9867\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0394 - accuracy: 0.9896\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0325 - accuracy: 0.9916\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0276 - accuracy: 0.9931\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0259 - accuracy: 0.9938\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0364 - accuracy: 0.9905\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0461 - accuracy: 0.9864\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0428 - accuracy: 0.9877\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0448 - accuracy: 0.9874\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0440 - accuracy: 0.9869\n",
      "60000/60000 [==============================] - 5s 81us/step\n",
      "Validation accuracy:  0.7610333561897278\n",
      "Try 7/100: Good_Validation_acc: None, learning_rate: 0.008500281351789164, Lambda: 0.0011642705200159142\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 7.8506 - accuracy: 0.1018\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5901 - accuracy: 0.0996\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3396 - accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3229 - accuracy: 0.0998\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3253 - accuracy: 0.0981\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3458 - accuracy: 0.0995\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3267 - accuracy: 0.1009\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3275 - accuracy: 0.0979\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3360 - accuracy: 0.0988\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3305 - accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3273 - accuracy: 0.1006\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3351 - accuracy: 0.1004\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3301 - accuracy: 0.0969\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3396 - accuracy: 0.0990\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3285 - accuracy: 0.0993\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3468 - accuracy: 0.1006\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3532 - accuracy: 0.0996\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3519 - accuracy: 0.1001\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3468 - accuracy: 0.0996\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3223 - accuracy: 0.1008\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3376 - accuracy: 0.1003\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3428 - accuracy: 0.0985\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3466 - accuracy: 0.0985\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3439 - accuracy: 0.0994\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3419 - accuracy: 0.1017\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3520 - accuracy: 0.0993\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3393 - accuracy: 0.1003\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3386 - accuracy: 0.1016\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3412 - accuracy: 0.0990\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3429 - accuracy: 0.1015\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3400 - accuracy: 0.1006\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3243 - accuracy: 0.0995\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3312 - accuracy: 0.0985\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3475 - accuracy: 0.1001\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3493 - accuracy: 0.0994\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3374 - accuracy: 0.1009\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3450 - accuracy: 0.0996\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3454 - accuracy: 0.1018\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3447 - accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3508 - accuracy: 0.1002\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3557 - accuracy: 0.0981\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3330 - accuracy: 0.1014\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3341 - accuracy: 0.1008\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3421 - accuracy: 0.0998\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3368 - accuracy: 0.1020\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3332 - accuracy: 0.1017\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3381 - accuracy: 0.0982\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3317 - accuracy: 0.1002\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3367 - accuracy: 0.0973\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3417 - accuracy: 0.0991\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3573 - accuracy: 0.0983\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3280 - accuracy: 0.1004\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3482 - accuracy: 0.0981\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3525 - accuracy: 0.0974\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.3362 - accuracy: 0.1006\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3562 - accuracy: 0.1006\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3414 - accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3417 - accuracy: 0.0983\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3349 - accuracy: 0.1008\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3350 - accuracy: 0.0988\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3483 - accuracy: 0.0996\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3647 - accuracy: 0.0987\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3441 - accuracy: 0.1021\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3499 - accuracy: 0.0988\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3439 - accuracy: 0.0988\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3423 - accuracy: 0.1010\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3510 - accuracy: 0.0973\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3579 - accuracy: 0.1002\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3628 - accuracy: 0.0976\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3310 - accuracy: 0.1005\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3308 - accuracy: 0.0999\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3374 - accuracy: 0.0996\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3435 - accuracy: 0.1006\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3402 - accuracy: 0.1013\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3419 - accuracy: 0.1018\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3384 - accuracy: 0.1006\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3417 - accuracy: 0.0988\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3382 - accuracy: 0.0993\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3426 - accuracy: 0.1004\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3314 - accuracy: 0.1009\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3319 - accuracy: 0.0986\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3495 - accuracy: 0.0995\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3306 - accuracy: 0.0983\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3466 - accuracy: 0.0960\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3466 - accuracy: 0.1001\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3383 - accuracy: 0.0999\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3525 - accuracy: 0.0978\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3510 - accuracy: 0.0995\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3408 - accuracy: 0.1026\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3389 - accuracy: 0.0999\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3466 - accuracy: 0.0999\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3417 - accuracy: 0.1029\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3337 - accuracy: 0.1004\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3455 - accuracy: 0.0978\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3485 - accuracy: 0.0972\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3401 - accuracy: 0.0990\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3355 - accuracy: 0.1008\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3378 - accuracy: 0.1005\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3555 - accuracy: 0.0990\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3535 - accuracy: 0.0978\n",
      "60000/60000 [==============================] - 5s 82us/step\n",
      "Validation accuracy:  0.10000000149011612\n",
      "Try 8/100: Good_Validation_acc: None, learning_rate: 3.5062349868576517, Lambda: 0.0005328989210096565\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 32us/step - loss: 2.4558 - accuracy: 0.1551\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1690 - accuracy: 0.2394\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0061 - accuracy: 0.3035\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8805 - accuracy: 0.3614\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7797 - accuracy: 0.4118\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6952 - accuracy: 0.4535\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6210 - accuracy: 0.4946\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5540 - accuracy: 0.5311\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4917 - accuracy: 0.5637\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4346 - accuracy: 0.5957\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3803 - accuracy: 0.6230\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3290 - accuracy: 0.6488\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2818 - accuracy: 0.6716\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2367 - accuracy: 0.6904\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1935 - accuracy: 0.7081\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1524 - accuracy: 0.7264\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1128 - accuracy: 0.7398\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0752 - accuracy: 0.7539\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0423 - accuracy: 0.7646\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0077 - accuracy: 0.7738\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9747 - accuracy: 0.7865\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9445 - accuracy: 0.7947\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9137 - accuracy: 0.8045\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8854 - accuracy: 0.8111\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8584 - accuracy: 0.8190\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8316 - accuracy: 0.8268\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8070 - accuracy: 0.8343\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7821 - accuracy: 0.8401\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7585 - accuracy: 0.8478\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7356 - accuracy: 0.8531\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7136 - accuracy: 0.8595\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6927 - accuracy: 0.8654\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6710 - accuracy: 0.8705\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6524 - accuracy: 0.8761\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6325 - accuracy: 0.8805\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6144 - accuracy: 0.8849\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5953 - accuracy: 0.8892\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5779 - accuracy: 0.8927\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5607 - accuracy: 0.8980\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5436 - accuracy: 0.9028\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5286 - accuracy: 0.9061\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5128 - accuracy: 0.9109\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4970 - accuracy: 0.9148\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4828 - accuracy: 0.9177\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4687 - accuracy: 0.9224\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4560 - accuracy: 0.9232\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4396 - accuracy: 0.9275\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4292 - accuracy: 0.9304\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4152 - accuracy: 0.9345\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4025 - accuracy: 0.9372\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3919 - accuracy: 0.9391\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3793 - accuracy: 0.9413\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3682 - accuracy: 0.9440\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3568 - accuracy: 0.9474\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3458 - accuracy: 0.9496\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.3365 - accuracy: 0.9512\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3285 - accuracy: 0.9528\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3172 - accuracy: 0.9562\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3084 - accuracy: 0.9572\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2967 - accuracy: 0.9596\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2872 - accuracy: 0.9622\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2806 - accuracy: 0.9634\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2719 - accuracy: 0.9647\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2650 - accuracy: 0.9665\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2586 - accuracy: 0.9673\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2502 - accuracy: 0.9686\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2415 - accuracy: 0.9713\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2348 - accuracy: 0.9728\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2294 - accuracy: 0.9732\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2200 - accuracy: 0.9753\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.2159 - accuracy: 0.9755\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2079 - accuracy: 0.9778\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2036 - accuracy: 0.9786\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1978 - accuracy: 0.9797\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1898 - accuracy: 0.9810\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1869 - accuracy: 0.9816\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1808 - accuracy: 0.9818\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1765 - accuracy: 0.9824\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1719 - accuracy: 0.9835\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1650 - accuracy: 0.9855\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1626 - accuracy: 0.9856\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1568 - accuracy: 0.9864\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1531 - accuracy: 0.9865\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1489 - accuracy: 0.9878\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1450 - accuracy: 0.9884\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1393 - accuracy: 0.9892\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1369 - accuracy: 0.9890\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1345 - accuracy: 0.9898\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1291 - accuracy: 0.9906\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1292 - accuracy: 0.9900\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1236 - accuracy: 0.9911\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1194 - accuracy: 0.9915\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1164 - accuracy: 0.9919\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1138 - accuracy: 0.9928\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1111 - accuracy: 0.9925\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1092 - accuracy: 0.9935\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1062 - accuracy: 0.9935\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1022 - accuracy: 0.9944\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0995 - accuracy: 0.9943\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0959 - accuracy: 0.9945\n",
      "60000/60000 [==============================] - 5s 83us/step\n",
      "Validation accuracy:  0.9180999994277954\n",
      "Try 9/100: Good_Validation_acc: None, learning_rate: 4.535873642114638e-05, Lambda: 0.0006000242781636896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,10):\n",
    "    learning_rate = math.pow(10, np.random.uniform(-7.0, 3.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-7,-2))\n",
    "    Good_acc = adam_model_improvement( learning_rate ,Lambda, epochs = 100)\n",
    "    print(\"Try {0}/{1}: Good_Validation_acc: {2}, learning_rate: {3}, Lambda: {4}\\n\".format(x, 100, Good_acc, learning_rate, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. In the Coarse tunning of the learning rate there was not even a single case that can be considered as good performance model either there is overfitting or underfitting.\n",
    "\n",
    "2. Let us try doing the fine tuning the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k46KwOSzvvoK"
   },
   "source": [
    "#### Trial 2: Fine Tuning the adam model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cSNqyguNvvoP",
    "outputId": "516cb886-b9d5-47ae-a1b9-9c057833f482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 1.8124 - accuracy: 0.3811\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1505 - accuracy: 0.6300\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9438 - accuracy: 0.6991\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8087 - accuracy: 0.7459\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7324 - accuracy: 0.7695\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6613 - accuracy: 0.7921\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5924 - accuracy: 0.8137\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5591 - accuracy: 0.8259\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5119 - accuracy: 0.8414\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4774 - accuracy: 0.8515\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4490 - accuracy: 0.8617\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4269 - accuracy: 0.8673\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3826 - accuracy: 0.8817\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3656 - accuracy: 0.8878\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3419 - accuracy: 0.8947\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3181 - accuracy: 0.9028\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3003 - accuracy: 0.9078\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2845 - accuracy: 0.9124\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2614 - accuracy: 0.9199\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2542 - accuracy: 0.9215\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2373 - accuracy: 0.9270\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2253 - accuracy: 0.9304\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2220 - accuracy: 0.9314\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2053 - accuracy: 0.9374\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1921 - accuracy: 0.9414\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1758 - accuracy: 0.9466\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1694 - accuracy: 0.9484\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1616 - accuracy: 0.9511\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1552 - accuracy: 0.9534\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1410 - accuracy: 0.9578\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1434 - accuracy: 0.9571\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1349 - accuracy: 0.9595\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1170 - accuracy: 0.9662\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1220 - accuracy: 0.9645\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1091 - accuracy: 0.9680\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0997 - accuracy: 0.9710\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1048 - accuracy: 0.9694\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1091 - accuracy: 0.9667\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1100 - accuracy: 0.9668\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1034 - accuracy: 0.9680\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0897 - accuracy: 0.9735\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0990 - accuracy: 0.9705\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0805 - accuracy: 0.9765\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0774 - accuracy: 0.9777\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0740 - accuracy: 0.9792\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0741 - accuracy: 0.9780\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0751 - accuracy: 0.9776\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0747 - accuracy: 0.9782\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0788 - accuracy: 0.9772\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0590 - accuracy: 0.9843\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0608 - accuracy: 0.9830\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0640 - accuracy: 0.9817\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0640 - accuracy: 0.9814\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0703 - accuracy: 0.9796\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0686 - accuracy: 0.9802\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0711 - accuracy: 0.9782\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0543 - accuracy: 0.9855\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0522 - accuracy: 0.9853\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0465 - accuracy: 0.9873\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0507 - accuracy: 0.9860\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0565 - accuracy: 0.9838\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0585 - accuracy: 0.9836\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0546 - accuracy: 0.9835\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0496 - accuracy: 0.9857\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0525 - accuracy: 0.9851\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0483 - accuracy: 0.9871\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0498 - accuracy: 0.9861\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0470 - accuracy: 0.9870\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0387 - accuracy: 0.9895\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0353 - accuracy: 0.9912\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0439 - accuracy: 0.9878\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0459 - accuracy: 0.9874\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0436 - accuracy: 0.9880\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0494 - accuracy: 0.9860\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0354 - accuracy: 0.9904\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0295 - accuracy: 0.9929\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0304 - accuracy: 0.9919\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0391 - accuracy: 0.9891\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0431 - accuracy: 0.9881\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0471 - accuracy: 0.9863\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0455 - accuracy: 0.9872\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0323 - accuracy: 0.9911\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0327 - accuracy: 0.9917\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0390 - accuracy: 0.9892\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0501 - accuracy: 0.9850\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0509 - accuracy: 0.9846\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0412 - accuracy: 0.9878\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0294 - accuracy: 0.9922\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0267 - accuracy: 0.9933\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0306 - accuracy: 0.9920\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0319 - accuracy: 0.9914\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0348 - accuracy: 0.9903\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0319 - accuracy: 0.9913\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0314 - accuracy: 0.9914\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0330 - accuracy: 0.9910\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0266 - accuracy: 0.9932\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0198 - accuracy: 0.9955\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0220 - accuracy: 0.9950\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0362 - accuracy: 0.9896\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0438 - accuracy: 0.9871\n",
      "60000/60000 [==============================] - 5s 89us/step\n",
      "Validation accuracy:  0.7993666529655457\n",
      "Try 1/100: Good_Validation_acc: None, learning_rate: 0.004374597671343508, Lambda: 0.00024080161797484563\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 33us/step - loss: 2.3008 - accuracy: 0.1839\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.8818 - accuracy: 0.3761\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.6208 - accuracy: 0.5219\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.4344 - accuracy: 0.6163\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2897 - accuracy: 0.6773\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1699 - accuracy: 0.7200\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0691 - accuracy: 0.7498\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9827 - accuracy: 0.7722\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9033 - accuracy: 0.7952\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8340 - accuracy: 0.8132\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7770 - accuracy: 0.8280\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7204 - accuracy: 0.8419\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6682 - accuracy: 0.8552\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6238 - accuracy: 0.8677\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5851 - accuracy: 0.8762\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5384 - accuracy: 0.8911\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5052 - accuracy: 0.8976\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4728 - accuracy: 0.9063\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4423 - accuracy: 0.9147\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4142 - accuracy: 0.9226\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3893 - accuracy: 0.9289\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3680 - accuracy: 0.9339\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3401 - accuracy: 0.9407\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3216 - accuracy: 0.9466\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3069 - accuracy: 0.9484\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.2786 - accuracy: 0.9571\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2626 - accuracy: 0.9609\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2553 - accuracy: 0.9625\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2372 - accuracy: 0.9662\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2207 - accuracy: 0.9705\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2091 - accuracy: 0.9731\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2048 - accuracy: 0.9730\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1908 - accuracy: 0.9765\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1798 - accuracy: 0.9793\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1756 - accuracy: 0.9792\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1665 - accuracy: 0.9822\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1581 - accuracy: 0.9839\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1474 - accuracy: 0.9861\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1413 - accuracy: 0.9869\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1382 - accuracy: 0.9877\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1407 - accuracy: 0.9858\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1314 - accuracy: 0.9884\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1276 - accuracy: 0.9892\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1212 - accuracy: 0.9905\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1130 - accuracy: 0.9925\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1089 - accuracy: 0.9929\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1067 - accuracy: 0.9931\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1053 - accuracy: 0.9928\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0999 - accuracy: 0.9943\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0969 - accuracy: 0.9953\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0959 - accuracy: 0.9944\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0946 - accuracy: 0.9950\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0911 - accuracy: 0.9962\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0855 - accuracy: 0.9965\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0856 - accuracy: 0.9965\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0887 - accuracy: 0.9956\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0915 - accuracy: 0.9944\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0989 - accuracy: 0.9921\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0954 - accuracy: 0.9936\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0848 - accuracy: 0.9961\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0784 - accuracy: 0.9976\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0821 - accuracy: 0.9961\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0872 - accuracy: 0.9944\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0779 - accuracy: 0.9972\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0715 - accuracy: 0.9981\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0679 - accuracy: 0.9988\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0667 - accuracy: 0.9990\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0638 - accuracy: 0.9994\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0653 - accuracy: 0.9989\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0745 - accuracy: 0.9965\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0820 - accuracy: 0.9945\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0846 - accuracy: 0.9939\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0958 - accuracy: 0.9906\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0892 - accuracy: 0.9926\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0870 - accuracy: 0.9926\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0873 - accuracy: 0.9919\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0773 - accuracy: 0.9954\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0722 - accuracy: 0.9967\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0685 - accuracy: 0.9972\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0620 - accuracy: 0.9988\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0598 - accuracy: 0.9991\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0573 - accuracy: 0.9992\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0558 - accuracy: 0.9994\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0549 - accuracy: 0.9995\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0554 - accuracy: 0.9993\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0526 - accuracy: 0.9998\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0513 - accuracy: 0.9998\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0502 - accuracy: 0.9999\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0492 - accuracy: 0.9999\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0485 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0470 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0466 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0458 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0466 - accuracy: 0.9999\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0456 - accuracy: 0.9999\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0447 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0442 - accuracy: 1.0000\n",
      "60000/60000 [==============================] - 5s 82us/step\n",
      "Validation accuracy:  0.9396666884422302\n",
      "Try 2/100: Good_Validation_acc: None, learning_rate: 0.00014597050666373954, Lambda: 0.0015703727439606212\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 2.2769 - accuracy: 0.1871\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8705 - accuracy: 0.3718\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6556 - accuracy: 0.5005\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4956 - accuracy: 0.5844\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3703 - accuracy: 0.6393\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2602 - accuracy: 0.6814\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1669 - accuracy: 0.7130\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0825 - accuracy: 0.7434\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0074 - accuracy: 0.7665\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9392 - accuracy: 0.7869\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8790 - accuracy: 0.8035\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8228 - accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7660 - accuracy: 0.8366\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7164 - accuracy: 0.8469\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6721 - accuracy: 0.8587\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6303 - accuracy: 0.8696\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5922 - accuracy: 0.8794\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5526 - accuracy: 0.8900\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5201 - accuracy: 0.8995\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4902 - accuracy: 0.9050\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4568 - accuracy: 0.9137\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4356 - accuracy: 0.9177\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4044 - accuracy: 0.9276\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3817 - accuracy: 0.9327\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3593 - accuracy: 0.9395\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3391 - accuracy: 0.9442\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3185 - accuracy: 0.9493\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3048 - accuracy: 0.9509\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2861 - accuracy: 0.9555\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2703 - accuracy: 0.9600\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2560 - accuracy: 0.9630\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2413 - accuracy: 0.9660\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2300 - accuracy: 0.9694\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2172 - accuracy: 0.9726\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2034 - accuracy: 0.9764\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1957 - accuracy: 0.9777\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1898 - accuracy: 0.9781\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1862 - accuracy: 0.9779\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1801 - accuracy: 0.9794\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1668 - accuracy: 0.9829\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1519 - accuracy: 0.9870\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1469 - accuracy: 0.9876\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1409 - accuracy: 0.9885\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1384 - accuracy: 0.9885\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1351 - accuracy: 0.9885\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1321 - accuracy: 0.9891\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1216 - accuracy: 0.9916\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1180 - accuracy: 0.9924\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1134 - accuracy: 0.9932\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1097 - accuracy: 0.9932\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1064 - accuracy: 0.9942\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1099 - accuracy: 0.9932\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1107 - accuracy: 0.9923\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1042 - accuracy: 0.9938\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1036 - accuracy: 0.9940\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1071 - accuracy: 0.9924\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0965 - accuracy: 0.9952\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0918 - accuracy: 0.9958\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0890 - accuracy: 0.9963\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0859 - accuracy: 0.9967\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0891 - accuracy: 0.9957\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0807 - accuracy: 0.9977\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0785 - accuracy: 0.9977\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0833 - accuracy: 0.9967\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0851 - accuracy: 0.9957\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0809 - accuracy: 0.9973\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0807 - accuracy: 0.9967\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0787 - accuracy: 0.9973\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0775 - accuracy: 0.9975\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0785 - accuracy: 0.9970\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0751 - accuracy: 0.9976\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0755 - accuracy: 0.9973\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0720 - accuracy: 0.9982\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0730 - accuracy: 0.9975\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0703 - accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0661 - accuracy: 0.9989\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0652 - accuracy: 0.9990\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0619 - accuracy: 0.9994\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0601 - accuracy: 0.9996\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0615 - accuracy: 0.9993\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0610 - accuracy: 0.9992\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0680 - accuracy: 0.9980\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0746 - accuracy: 0.9960\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0850 - accuracy: 0.9931\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0997 - accuracy: 0.9892\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0978 - accuracy: 0.9895\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0842 - accuracy: 0.9939\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0747 - accuracy: 0.9962\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0654 - accuracy: 0.9984\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0608 - accuracy: 0.9989\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0574 - accuracy: 0.9993\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0566 - accuracy: 0.9993\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0540 - accuracy: 0.9998\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0521 - accuracy: 0.9998\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0518 - accuracy: 0.9998\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0509 - accuracy: 0.9999\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0502 - accuracy: 0.9999\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0498 - accuracy: 0.9999\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0495 - accuracy: 0.9998\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0498 - accuracy: 0.9999\n",
      "60000/60000 [==============================] - 5s 82us/step\n",
      "Validation accuracy:  0.9376333355903625\n",
      "Try 3/100: Good_Validation_acc: None, learning_rate: 0.000122606987526071, Lambda: 0.001629899585197732\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 1.9614 - accuracy: 0.3896\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2757 - accuracy: 0.6457\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0306 - accuracy: 0.7139\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8721 - accuracy: 0.7618\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7757 - accuracy: 0.7865\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6974 - accuracy: 0.8099\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6385 - accuracy: 0.8274\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5856 - accuracy: 0.8415\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5451 - accuracy: 0.8554\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5062 - accuracy: 0.8636\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4810 - accuracy: 0.8716\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4467 - accuracy: 0.8824\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4219 - accuracy: 0.8897\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3899 - accuracy: 0.8977\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3634 - accuracy: 0.9083\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3395 - accuracy: 0.9149\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3255 - accuracy: 0.9185\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3112 - accuracy: 0.9218\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3024 - accuracy: 0.9241\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2846 - accuracy: 0.9295\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2721 - accuracy: 0.9323\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2504 - accuracy: 0.9398\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2338 - accuracy: 0.9449\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2175 - accuracy: 0.9503\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2113 - accuracy: 0.9508\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1992 - accuracy: 0.9554\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1863 - accuracy: 0.9582\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1802 - accuracy: 0.9591\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1636 - accuracy: 0.9656\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1692 - accuracy: 0.9624\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1599 - accuracy: 0.9657\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1477 - accuracy: 0.9690\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1537 - accuracy: 0.9657\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1405 - accuracy: 0.9697\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1312 - accuracy: 0.9734\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1247 - accuracy: 0.9749\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1213 - accuracy: 0.9750\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1087 - accuracy: 0.9790\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1040 - accuracy: 0.9810\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1078 - accuracy: 0.9791\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1036 - accuracy: 0.9799\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1064 - accuracy: 0.9790\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0952 - accuracy: 0.9816\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0867 - accuracy: 0.9848\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0889 - accuracy: 0.9834\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0925 - accuracy: 0.9820\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0924 - accuracy: 0.9818\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0946 - accuracy: 0.9816\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0848 - accuracy: 0.9837\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0794 - accuracy: 0.9859\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0849 - accuracy: 0.9834\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0854 - accuracy: 0.9833\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0918 - accuracy: 0.9813\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0725 - accuracy: 0.9874\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0657 - accuracy: 0.9896\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0698 - accuracy: 0.9874\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0652 - accuracy: 0.9891\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0579 - accuracy: 0.9924\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0544 - accuracy: 0.9925\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0499 - accuracy: 0.9937\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0531 - accuracy: 0.9926\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0607 - accuracy: 0.9900\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0775 - accuracy: 0.9843\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0792 - accuracy: 0.9829\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0735 - accuracy: 0.9841\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0702 - accuracy: 0.9860\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0626 - accuracy: 0.9886\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0545 - accuracy: 0.9910\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0570 - accuracy: 0.9901\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0542 - accuracy: 0.9910\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0473 - accuracy: 0.9931\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0572 - accuracy: 0.9894\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0587 - accuracy: 0.9888\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0558 - accuracy: 0.9902\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0484 - accuracy: 0.9925\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0527 - accuracy: 0.9910\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0566 - accuracy: 0.9898\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0610 - accuracy: 0.9877\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0547 - accuracy: 0.9895\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0443 - accuracy: 0.9930\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0516 - accuracy: 0.9905\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0529 - accuracy: 0.9904\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0444 - accuracy: 0.9925\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0415 - accuracy: 0.9940\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0372 - accuracy: 0.9953\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0407 - accuracy: 0.9936\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0433 - accuracy: 0.9928\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0458 - accuracy: 0.9917\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0363 - accuracy: 0.9951\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0340 - accuracy: 0.9960\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0331 - accuracy: 0.9960\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0333 - accuracy: 0.9957\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0390 - accuracy: 0.9938\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0487 - accuracy: 0.9904\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0442 - accuracy: 0.9920\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0485 - accuracy: 0.9898\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0572 - accuracy: 0.9872\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0608 - accuracy: 0.9862\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0626 - accuracy: 0.9850\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0637 - accuracy: 0.9854\n",
      "60000/60000 [==============================] - 5s 82us/step\n",
      "Validation accuracy:  0.7151333093643188\n",
      "Try 4/100: Good_Validation_acc: None, learning_rate: 0.003248767294557822, Lambda: 0.008498513787726843\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 33us/step - loss: 2.0464 - accuracy: 0.2567\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.4028 - accuracy: 0.5373\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0872 - accuracy: 0.6585\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9148 - accuracy: 0.7171\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7985 - accuracy: 0.7574\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7075 - accuracy: 0.7874\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6383 - accuracy: 0.8090\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5892 - accuracy: 0.8255\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5528 - accuracy: 0.8345\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5133 - accuracy: 0.8493\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4854 - accuracy: 0.8570\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4390 - accuracy: 0.8724\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4013 - accuracy: 0.8852\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3798 - accuracy: 0.8913\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.3566 - accuracy: 0.8977\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3394 - accuracy: 0.9030\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3224 - accuracy: 0.9075\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2946 - accuracy: 0.9160\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2772 - accuracy: 0.9217\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2638 - accuracy: 0.9249\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2520 - accuracy: 0.9285\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2464 - accuracy: 0.9308\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2324 - accuracy: 0.9350\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2167 - accuracy: 0.9390\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2019 - accuracy: 0.9442\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2004 - accuracy: 0.9431\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1920 - accuracy: 0.9460\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1757 - accuracy: 0.9518\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1585 - accuracy: 0.9564\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1645 - accuracy: 0.9553\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1569 - accuracy: 0.9562\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1377 - accuracy: 0.9637\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1369 - accuracy: 0.9630\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1286 - accuracy: 0.9650\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1201 - accuracy: 0.9682\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1186 - accuracy: 0.9680\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1154 - accuracy: 0.9680\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1080 - accuracy: 0.9721\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0965 - accuracy: 0.9748\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0989 - accuracy: 0.9741\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1047 - accuracy: 0.9718\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0990 - accuracy: 0.9740\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0877 - accuracy: 0.9779\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0897 - accuracy: 0.9771\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0873 - accuracy: 0.9768\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0767 - accuracy: 0.9808\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0899 - accuracy: 0.9765\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0872 - accuracy: 0.9774\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0884 - accuracy: 0.9760\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0719 - accuracy: 0.9822\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0704 - accuracy: 0.9819\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0701 - accuracy: 0.9819\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0761 - accuracy: 0.9795\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0726 - accuracy: 0.9816\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0627 - accuracy: 0.9848\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0653 - accuracy: 0.9837\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0610 - accuracy: 0.9854\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0559 - accuracy: 0.9862\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0585 - accuracy: 0.9858\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0698 - accuracy: 0.9819\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0601 - accuracy: 0.9851\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0589 - accuracy: 0.9863\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0504 - accuracy: 0.9880\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0584 - accuracy: 0.9851\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0590 - accuracy: 0.9850\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0609 - accuracy: 0.9841\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0547 - accuracy: 0.9865\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0517 - accuracy: 0.9875\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0453 - accuracy: 0.9892\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0474 - accuracy: 0.9887\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0481 - accuracy: 0.9886\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0480 - accuracy: 0.9883\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0531 - accuracy: 0.9865\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0477 - accuracy: 0.9880\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0462 - accuracy: 0.9889\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0476 - accuracy: 0.9884\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0458 - accuracy: 0.9892\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0425 - accuracy: 0.9898\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0504 - accuracy: 0.9873\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0427 - accuracy: 0.9893\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0364 - accuracy: 0.9916\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0357 - accuracy: 0.9918\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0438 - accuracy: 0.9896\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0576 - accuracy: 0.9841\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0510 - accuracy: 0.9868\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0515 - accuracy: 0.9863\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0490 - accuracy: 0.9870\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0413 - accuracy: 0.9897\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0433 - accuracy: 0.9889\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0396 - accuracy: 0.9909\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0375 - accuracy: 0.9911\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0400 - accuracy: 0.9903\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0612 - accuracy: 0.9831\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0615 - accuracy: 0.9826\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0506 - accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0430 - accuracy: 0.9891\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0433 - accuracy: 0.9885\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0442 - accuracy: 0.9880\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0378 - accuracy: 0.9905\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0340 - accuracy: 0.9916\n",
      "60000/60000 [==============================] - 5s 82us/step\n",
      "Validation accuracy:  0.7976499795913696\n",
      "Try 5/100: Good_Validation_acc: None, learning_rate: 0.008916651450005638, Lambda: 0.0038969905683226987\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 31us/step - loss: 2.3245 - accuracy: 0.1140\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0284 - accuracy: 0.2126\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6344 - accuracy: 0.3980\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2636 - accuracy: 0.5719\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0039 - accuracy: 0.6760\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8695 - accuracy: 0.7251\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7769 - accuracy: 0.7572\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6910 - accuracy: 0.7865\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6272 - accuracy: 0.8091\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5789 - accuracy: 0.8234\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5369 - accuracy: 0.8374\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5111 - accuracy: 0.8444\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4785 - accuracy: 0.8556\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4457 - accuracy: 0.8652\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4340 - accuracy: 0.8687\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4038 - accuracy: 0.8770\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3897 - accuracy: 0.8813\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3697 - accuracy: 0.8891\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3443 - accuracy: 0.8967\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3236 - accuracy: 0.9041\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3169 - accuracy: 0.9064\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2980 - accuracy: 0.9125\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2950 - accuracy: 0.9119\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2971 - accuracy: 0.9130\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2689 - accuracy: 0.9217\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2558 - accuracy: 0.9253\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2410 - accuracy: 0.9292\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2333 - accuracy: 0.9306\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2349 - accuracy: 0.9303\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2300 - accuracy: 0.9320\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2211 - accuracy: 0.9339\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2119 - accuracy: 0.9370\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1950 - accuracy: 0.9429\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1896 - accuracy: 0.9450\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1848 - accuracy: 0.9455\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1757 - accuracy: 0.9477\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1848 - accuracy: 0.9463\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1901 - accuracy: 0.9435\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1599 - accuracy: 0.9532\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1588 - accuracy: 0.9536\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1542 - accuracy: 0.9558\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1469 - accuracy: 0.9582\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1359 - accuracy: 0.9606\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1367 - accuracy: 0.9610\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1343 - accuracy: 0.9611\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1334 - accuracy: 0.9611\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1252 - accuracy: 0.9645\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1295 - accuracy: 0.9635\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1264 - accuracy: 0.9638\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1210 - accuracy: 0.9659\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1064 - accuracy: 0.9699\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1116 - accuracy: 0.9679\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1103 - accuracy: 0.9696\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1103 - accuracy: 0.9685\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1072 - accuracy: 0.9695\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0980 - accuracy: 0.9720\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0933 - accuracy: 0.9738\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0924 - accuracy: 0.9739\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1162 - accuracy: 0.9664\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0960 - accuracy: 0.9732\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0905 - accuracy: 0.9744\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0854 - accuracy: 0.9761\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0862 - accuracy: 0.9759\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0727 - accuracy: 0.9801\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0847 - accuracy: 0.9758\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0860 - accuracy: 0.9758\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0865 - accuracy: 0.9755\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0819 - accuracy: 0.9780\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0900 - accuracy: 0.9745\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0848 - accuracy: 0.9755\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0782 - accuracy: 0.9777\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0792 - accuracy: 0.9772\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0760 - accuracy: 0.9793\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0767 - accuracy: 0.9790\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0921 - accuracy: 0.9740\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0818 - accuracy: 0.9765\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0712 - accuracy: 0.9801\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0651 - accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0632 - accuracy: 0.9830\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0552 - accuracy: 0.9853\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0592 - accuracy: 0.9843\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0647 - accuracy: 0.9821\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0690 - accuracy: 0.9809\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0639 - accuracy: 0.9830\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0829 - accuracy: 0.9768\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0786 - accuracy: 0.9782\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0695 - accuracy: 0.9805\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0721 - accuracy: 0.9801\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0655 - accuracy: 0.9816\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0560 - accuracy: 0.9851\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0598 - accuracy: 0.9835\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0604 - accuracy: 0.9832\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0546 - accuracy: 0.9853\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0576 - accuracy: 0.9851\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0556 - accuracy: 0.9848\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0648 - accuracy: 0.9826\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0530 - accuracy: 0.9856\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0478 - accuracy: 0.9876\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0487 - accuracy: 0.9873\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0534 - accuracy: 0.9856\n",
      "60000/60000 [==============================] - 5s 81us/step\n",
      "Validation accuracy:  0.8282999992370605\n",
      "Try 6/100: Good_Validation_acc: None, learning_rate: 0.04249522298309469, Lambda: 0.001559480133677572\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 2.1250 - accuracy: 0.2889\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5630 - accuracy: 0.5681\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2541 - accuracy: 0.6912\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0403 - accuracy: 0.7521\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8955 - accuracy: 0.7863\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7960 - accuracy: 0.8134\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7230 - accuracy: 0.8316\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6535 - accuracy: 0.8512\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6025 - accuracy: 0.8653\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5600 - accuracy: 0.8777\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5248 - accuracy: 0.8851\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4896 - accuracy: 0.8957\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4585 - accuracy: 0.9045\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4161 - accuracy: 0.9187\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3979 - accuracy: 0.9239\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3736 - accuracy: 0.9293\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3490 - accuracy: 0.9374\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3333 - accuracy: 0.9412\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3192 - accuracy: 0.9436\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2986 - accuracy: 0.9510\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2882 - accuracy: 0.9526\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2787 - accuracy: 0.9546\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2680 - accuracy: 0.9575\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2414 - accuracy: 0.9654\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2260 - accuracy: 0.9696\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2217 - accuracy: 0.9695\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2168 - accuracy: 0.9707\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1995 - accuracy: 0.9750\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1962 - accuracy: 0.9755\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1876 - accuracy: 0.9778\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1822 - accuracy: 0.9785\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1795 - accuracy: 0.9780\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1676 - accuracy: 0.9819\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1583 - accuracy: 0.9842\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1517 - accuracy: 0.9856\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1604 - accuracy: 0.9820\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1549 - accuracy: 0.9825\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1462 - accuracy: 0.9857\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1349 - accuracy: 0.9887\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1261 - accuracy: 0.9910\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1226 - accuracy: 0.9911\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1213 - accuracy: 0.9911\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1169 - accuracy: 0.9919\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1126 - accuracy: 0.9927\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1128 - accuracy: 0.9920\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1123 - accuracy: 0.9918\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1122 - accuracy: 0.9915\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1115 - accuracy: 0.9911\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1054 - accuracy: 0.9928\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0983 - accuracy: 0.9947\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0932 - accuracy: 0.9952\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0904 - accuracy: 0.9961\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0890 - accuracy: 0.9958\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0887 - accuracy: 0.9954\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0866 - accuracy: 0.9964\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0825 - accuracy: 0.9970\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0813 - accuracy: 0.9971\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0819 - accuracy: 0.9966\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0851 - accuracy: 0.9952\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0919 - accuracy: 0.9935\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0947 - accuracy: 0.9922\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0928 - accuracy: 0.9929\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0964 - accuracy: 0.9915\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1091 - accuracy: 0.9869\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1011 - accuracy: 0.9895\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1002 - accuracy: 0.9889\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0977 - accuracy: 0.9904\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0908 - accuracy: 0.9920\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0822 - accuracy: 0.9944\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0721 - accuracy: 0.9967\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0648 - accuracy: 0.9984\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0598 - accuracy: 0.9990\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0577 - accuracy: 0.9991\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0561 - accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0558 - accuracy: 0.9991\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0547 - accuracy: 0.9992\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0530 - accuracy: 0.9994\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0521 - accuracy: 0.9994\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0524 - accuracy: 0.9991\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0514 - accuracy: 0.9992\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0495 - accuracy: 0.9996\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0474 - accuracy: 0.9996\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0463 - accuracy: 0.9997\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0484 - accuracy: 0.9993\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0507 - accuracy: 0.9987\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0723 - accuracy: 0.9931\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1108 - accuracy: 0.9811\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1717 - accuracy: 0.9584\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1709 - accuracy: 0.9589\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1294 - accuracy: 0.9747\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.0885 - accuracy: 0.9887\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0808 - accuracy: 0.9905\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0786 - accuracy: 0.9907\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0673 - accuracy: 0.9949\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0599 - accuracy: 0.9967\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0558 - accuracy: 0.9974\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0507 - accuracy: 0.9984\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0477 - accuracy: 0.9991\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0439 - accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0436 - accuracy: 0.9993\n",
      "60000/60000 [==============================] - 5s 82us/step\n",
      "Validation accuracy:  0.916533350944519\n",
      "Try 7/100: Good_Validation_acc: None, learning_rate: 0.000505836528343134, Lambda: 0.006181837437787254\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 32us/step - loss: 1.9960 - accuracy: 0.2650\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3439 - accuracy: 0.5349\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0466 - accuracy: 0.6540\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8987 - accuracy: 0.7079\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7767 - accuracy: 0.7510\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6973 - accuracy: 0.7803\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6437 - accuracy: 0.7970\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5681 - accuracy: 0.8210\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5441 - accuracy: 0.8288\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5004 - accuracy: 0.8444\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4636 - accuracy: 0.8559\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4307 - accuracy: 0.8647\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4098 - accuracy: 0.8735\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3642 - accuracy: 0.8879\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3496 - accuracy: 0.8926\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3276 - accuracy: 0.8992\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3190 - accuracy: 0.8997\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2893 - accuracy: 0.9101\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2663 - accuracy: 0.9174\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2524 - accuracy: 0.9219\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2404 - accuracy: 0.9247\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2291 - accuracy: 0.9290\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2113 - accuracy: 0.9347\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1992 - accuracy: 0.9380\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1892 - accuracy: 0.9410\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1785 - accuracy: 0.9451\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1703 - accuracy: 0.9474\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1668 - accuracy: 0.9478\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1607 - accuracy: 0.9502\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1439 - accuracy: 0.9566\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1369 - accuracy: 0.9582\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1415 - accuracy: 0.9557\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1412 - accuracy: 0.9559\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1164 - accuracy: 0.9643\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1105 - accuracy: 0.9655\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1000 - accuracy: 0.9692\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1112 - accuracy: 0.9652\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1177 - accuracy: 0.9628\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1057 - accuracy: 0.9669\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0926 - accuracy: 0.9711\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0855 - accuracy: 0.9742\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0788 - accuracy: 0.9763\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0856 - accuracy: 0.9736\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0842 - accuracy: 0.9745\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0881 - accuracy: 0.9731\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0752 - accuracy: 0.9775\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0719 - accuracy: 0.9784\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0675 - accuracy: 0.9801\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0682 - accuracy: 0.9797\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0872 - accuracy: 0.9731\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0884 - accuracy: 0.9736\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0648 - accuracy: 0.9805\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0557 - accuracy: 0.9835\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0572 - accuracy: 0.9828\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0576 - accuracy: 0.9827\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0583 - accuracy: 0.9828\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0504 - accuracy: 0.9854\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0478 - accuracy: 0.9856\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0590 - accuracy: 0.9823\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0513 - accuracy: 0.9850\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0474 - accuracy: 0.9856\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0512 - accuracy: 0.9843\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0531 - accuracy: 0.9835\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0703 - accuracy: 0.9778\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0593 - accuracy: 0.9818\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0464 - accuracy: 0.9867\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0464 - accuracy: 0.9861\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0453 - accuracy: 0.9871\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0446 - accuracy: 0.9872\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0411 - accuracy: 0.9877\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0413 - accuracy: 0.9878\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0412 - accuracy: 0.9877\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0444 - accuracy: 0.9870\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0487 - accuracy: 0.9853\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0470 - accuracy: 0.9855\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0418 - accuracy: 0.9872\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0399 - accuracy: 0.9880\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0409 - accuracy: 0.9879\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0412 - accuracy: 0.9881\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0379 - accuracy: 0.9891\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0411 - accuracy: 0.9878\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0448 - accuracy: 0.9870\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0405 - accuracy: 0.9881\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0400 - accuracy: 0.9880\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0304 - accuracy: 0.9912\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0357 - accuracy: 0.9892\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0372 - accuracy: 0.9887\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0397 - accuracy: 0.9880\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0387 - accuracy: 0.9891\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0388 - accuracy: 0.9889\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0310 - accuracy: 0.9913\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0265 - accuracy: 0.9929\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0366 - accuracy: 0.9895\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0334 - accuracy: 0.9894\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0385 - accuracy: 0.9891\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0390 - accuracy: 0.9883\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0349 - accuracy: 0.9894\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0388 - accuracy: 0.9883\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0403 - accuracy: 0.9882\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0299 - accuracy: 0.9916\n",
      "60000/60000 [==============================] - 5s 81us/step\n",
      "Validation accuracy:  0.8387500047683716\n",
      "Try 8/100: Good_Validation_acc: None, learning_rate: 0.008918681669299164, Lambda: 0.0001871253542155526\n",
      "\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 31us/step - loss: 1.9857 - accuracy: 0.3025\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3838 - accuracy: 0.6010\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0636 - accuracy: 0.7082\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8747 - accuracy: 0.7602\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.7461 - accuracy: 0.7905\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6557 - accuracy: 0.8119\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5778 - accuracy: 0.8332\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5111 - accuracy: 0.8531\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4755 - accuracy: 0.8622\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4299 - accuracy: 0.8754\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3919 - accuracy: 0.8885\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3560 - accuracy: 0.8987\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3304 - accuracy: 0.9053\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2992 - accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2860 - accuracy: 0.9203\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2649 - accuracy: 0.9257\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2431 - accuracy: 0.9329\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2267 - accuracy: 0.9376\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2119 - accuracy: 0.9419\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1925 - accuracy: 0.9481\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1850 - accuracy: 0.9496\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1800 - accuracy: 0.9515\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1705 - accuracy: 0.9529\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.1697 - accuracy: 0.9540\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1460 - accuracy: 0.9622\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1358 - accuracy: 0.9646\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1283 - accuracy: 0.9673\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1095 - accuracy: 0.9736\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1019 - accuracy: 0.9760\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1076 - accuracy: 0.9732\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1197 - accuracy: 0.9670\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1177 - accuracy: 0.9691\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1070 - accuracy: 0.9726\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0982 - accuracy: 0.9752\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0988 - accuracy: 0.9754\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0916 - accuracy: 0.9770\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0835 - accuracy: 0.9810\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0749 - accuracy: 0.9826\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0783 - accuracy: 0.9817\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0818 - accuracy: 0.9804\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0737 - accuracy: 0.9834\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0654 - accuracy: 0.9859\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0649 - accuracy: 0.9857\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0647 - accuracy: 0.9853\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0585 - accuracy: 0.9872\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0596 - accuracy: 0.9869\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0642 - accuracy: 0.9846\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0632 - accuracy: 0.9853\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0677 - accuracy: 0.9840\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0634 - accuracy: 0.9848\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0564 - accuracy: 0.9869\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0581 - accuracy: 0.9874\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0602 - accuracy: 0.9857\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0567 - accuracy: 0.9872\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0514 - accuracy: 0.9890\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0579 - accuracy: 0.9875\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0541 - accuracy: 0.9884\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0459 - accuracy: 0.9904\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0421 - accuracy: 0.9916\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0359 - accuracy: 0.9939\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0349 - accuracy: 0.9941\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0382 - accuracy: 0.9929\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0372 - accuracy: 0.9932\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0510 - accuracy: 0.9883\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0528 - accuracy: 0.9881\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0641 - accuracy: 0.9843\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0679 - accuracy: 0.9826\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0676 - accuracy: 0.9830\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0559 - accuracy: 0.9867\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0434 - accuracy: 0.9906\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0412 - accuracy: 0.9914\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0399 - accuracy: 0.9923\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0287 - accuracy: 0.9958\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0316 - accuracy: 0.9947\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0351 - accuracy: 0.9939\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0355 - accuracy: 0.9932\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0296 - accuracy: 0.9952\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0269 - accuracy: 0.9965\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0225 - accuracy: 0.9975\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0249 - accuracy: 0.9964\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0305 - accuracy: 0.9952\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0313 - accuracy: 0.9946\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0401 - accuracy: 0.9916\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0541 - accuracy: 0.9867\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0564 - accuracy: 0.9857\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0649 - accuracy: 0.9831\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0549 - accuracy: 0.9861\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0500 - accuracy: 0.9882\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0416 - accuracy: 0.9912\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0348 - accuracy: 0.9930\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0325 - accuracy: 0.9941\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0304 - accuracy: 0.9945\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0337 - accuracy: 0.9939\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0401 - accuracy: 0.9911\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0331 - accuracy: 0.9934\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0307 - accuracy: 0.9941\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0309 - accuracy: 0.9946\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0276 - accuracy: 0.9954\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0306 - accuracy: 0.9943\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0249 - accuracy: 0.9961\n",
      "60000/60000 [==============================] - 5s 80us/step\n",
      "Validation accuracy:  0.8243499994277954\n",
      "Try 9/100: Good_Validation_acc: None, learning_rate: 0.0005398150292541877, Lambda: 0.00027063115789058745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,10):\n",
    "    learning_rate = math.pow(10, np.random.uniform(-4.0, -1.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-4,-2))\n",
    "    Good_acc = adam_model_improvement( learning_rate ,Lambda, epochs = 100)\n",
    "    print(\"Try {0}/{1}: Good_Validation_acc: {2}, learning_rate: {3}, Lambda: {4}\\n\".format(x, 100, Good_acc, learning_rate, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. It can be found from the above that in all trials there is overfitting of the model.\n",
    "2. To control this overfitting there should be some improvement on regularization to be done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Further, the model is tuned with random values for lambda and learning rate of 0.00001 which was used in the model of Trial - 4 of Model - 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k46KwOSzvvoK"
   },
   "source": [
    "#### Trial 3: Tuning the model with Lambda value of 1e-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "H8RkGV79B6Xj",
    "outputId": "02c990ad-2936-4c3b-83d7-af7aff5763a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 31us/step - loss: 2.5661 - accuracy: 0.1061\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.4721 - accuracy: 0.1234\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4021 - accuracy: 0.1435\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.3417 - accuracy: 0.1612\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2872 - accuracy: 0.1806\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.2383 - accuracy: 0.1985\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.1942 - accuracy: 0.2148\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1536 - accuracy: 0.2289\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.1159 - accuracy: 0.2463\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0803 - accuracy: 0.2607\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.0462 - accuracy: 0.2754\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.0147 - accuracy: 0.2873\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.9840 - accuracy: 0.3020\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.9557 - accuracy: 0.3152\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.9276 - accuracy: 0.3287\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.9019 - accuracy: 0.3408\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.8776 - accuracy: 0.3533\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.8537 - accuracy: 0.3655\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.8302 - accuracy: 0.3781\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.8077 - accuracy: 0.3907\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.7856 - accuracy: 0.4025\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.7656 - accuracy: 0.4136\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7447 - accuracy: 0.4251\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.7254 - accuracy: 0.4357\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.7058 - accuracy: 0.4477\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.6868 - accuracy: 0.4589\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.6690 - accuracy: 0.4705\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.6510 - accuracy: 0.4822\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.6343 - accuracy: 0.4917\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.6169 - accuracy: 0.5016\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.6005 - accuracy: 0.5109\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.5850 - accuracy: 0.5197\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.5683 - accuracy: 0.5299\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.5537 - accuracy: 0.5388\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.5389 - accuracy: 0.5481\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.5253 - accuracy: 0.5543\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.5100 - accuracy: 0.5650\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.4964 - accuracy: 0.5730\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.4832 - accuracy: 0.5793\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.4692 - accuracy: 0.5870\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4561 - accuracy: 0.5938\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.4440 - accuracy: 0.6001\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.4315 - accuracy: 0.6068\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.4180 - accuracy: 0.6157\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.4067 - accuracy: 0.6201\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3955 - accuracy: 0.6265\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3837 - accuracy: 0.6321\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3728 - accuracy: 0.6371\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3610 - accuracy: 0.6438\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3494 - accuracy: 0.6497\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3394 - accuracy: 0.6540\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3285 - accuracy: 0.6594\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.3174 - accuracy: 0.6647\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.3076 - accuracy: 0.6695\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2969 - accuracy: 0.6725\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2867 - accuracy: 0.6795\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2767 - accuracy: 0.6848\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2666 - accuracy: 0.6895\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2572 - accuracy: 0.6940\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2472 - accuracy: 0.6987\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2379 - accuracy: 0.7025\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2281 - accuracy: 0.7083\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2194 - accuracy: 0.7105\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.2105 - accuracy: 0.7159\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.2012 - accuracy: 0.7191\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1921 - accuracy: 0.7226\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1830 - accuracy: 0.7262\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1738 - accuracy: 0.7315\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1652 - accuracy: 0.7344\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1577 - accuracy: 0.7363\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.1485 - accuracy: 0.7430\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1399 - accuracy: 0.7444\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1313 - accuracy: 0.7470\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1240 - accuracy: 0.7493\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1147 - accuracy: 0.7555\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.1074 - accuracy: 0.7561\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0988 - accuracy: 0.7592\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0915 - accuracy: 0.7622\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0837 - accuracy: 0.7641\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0756 - accuracy: 0.7679\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0677 - accuracy: 0.7704\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0606 - accuracy: 0.7734\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0521 - accuracy: 0.7759\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0455 - accuracy: 0.7781\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0380 - accuracy: 0.7797\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0304 - accuracy: 0.7837\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0247 - accuracy: 0.7852\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0156 - accuracy: 0.7871\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.0101 - accuracy: 0.7891\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.0018 - accuracy: 0.7927\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9940 - accuracy: 0.7960\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9875 - accuracy: 0.7970\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9799 - accuracy: 0.8000\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9723 - accuracy: 0.8015\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9669 - accuracy: 0.8037\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9593 - accuracy: 0.8063\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9530 - accuracy: 0.8079\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9471 - accuracy: 0.8099\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9420 - accuracy: 0.8111\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9326 - accuracy: 0.8131\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9266 - accuracy: 0.8160\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9198 - accuracy: 0.8189\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9135 - accuracy: 0.8194\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.9066 - accuracy: 0.8206\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.9007 - accuracy: 0.8230\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8953 - accuracy: 0.8235\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8887 - accuracy: 0.8269\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8821 - accuracy: 0.8282\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8758 - accuracy: 0.8305\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8700 - accuracy: 0.8315\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8641 - accuracy: 0.8345\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8568 - accuracy: 0.8358\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8516 - accuracy: 0.8360\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8449 - accuracy: 0.8394\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8390 - accuracy: 0.8413\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8344 - accuracy: 0.8427\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8275 - accuracy: 0.8448\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8219 - accuracy: 0.8463\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.8154 - accuracy: 0.8488\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8102 - accuracy: 0.8489\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.8043 - accuracy: 0.8514\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7984 - accuracy: 0.8527\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7938 - accuracy: 0.8529\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7872 - accuracy: 0.8557\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7827 - accuracy: 0.8562\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7776 - accuracy: 0.8582\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7709 - accuracy: 0.8605\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7660 - accuracy: 0.8611\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7596 - accuracy: 0.8630\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7551 - accuracy: 0.8645\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7503 - accuracy: 0.8644\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7444 - accuracy: 0.8659\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7395 - accuracy: 0.8679\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7338 - accuracy: 0.8700\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7285 - accuracy: 0.8702\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7241 - accuracy: 0.8729\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7181 - accuracy: 0.8746\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7141 - accuracy: 0.8748\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7092 - accuracy: 0.8743\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.7037 - accuracy: 0.8776\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6987 - accuracy: 0.8774\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6940 - accuracy: 0.8792\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6889 - accuracy: 0.8806\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6833 - accuracy: 0.8828\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6795 - accuracy: 0.8827\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6739 - accuracy: 0.8860\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6701 - accuracy: 0.8846\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6647 - accuracy: 0.8870\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6599 - accuracy: 0.8879\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6567 - accuracy: 0.8890\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6505 - accuracy: 0.8899\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.6461 - accuracy: 0.8910\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6418 - accuracy: 0.8914\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6384 - accuracy: 0.8920\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6334 - accuracy: 0.8940\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6283 - accuracy: 0.8953\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6241 - accuracy: 0.8957\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6182 - accuracy: 0.8979\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6140 - accuracy: 0.8986\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6107 - accuracy: 0.9000\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6065 - accuracy: 0.8986\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.6020 - accuracy: 0.9015\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5964 - accuracy: 0.9027\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5933 - accuracy: 0.9031\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5885 - accuracy: 0.9041\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5846 - accuracy: 0.9052\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5800 - accuracy: 0.9054\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5754 - accuracy: 0.9066\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5732 - accuracy: 0.9084\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5673 - accuracy: 0.9094\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5638 - accuracy: 0.9102\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5593 - accuracy: 0.9111\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5549 - accuracy: 0.9126\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5512 - accuracy: 0.9136\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5473 - accuracy: 0.9139\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5449 - accuracy: 0.9134\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5401 - accuracy: 0.9151\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5361 - accuracy: 0.9158\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5322 - accuracy: 0.9167\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5288 - accuracy: 0.9171\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5242 - accuracy: 0.9190\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5202 - accuracy: 0.9199\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5184 - accuracy: 0.9205\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5117 - accuracy: 0.9214\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.5075 - accuracy: 0.9228\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5044 - accuracy: 0.9247\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.5018 - accuracy: 0.9238\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4973 - accuracy: 0.9256\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4944 - accuracy: 0.9250\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4897 - accuracy: 0.9278\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4876 - accuracy: 0.9271\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4838 - accuracy: 0.9284\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4796 - accuracy: 0.9285\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4760 - accuracy: 0.9296\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4728 - accuracy: 0.9313\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4684 - accuracy: 0.9321\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.4659 - accuracy: 0.9320\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4626 - accuracy: 0.9330\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4587 - accuracy: 0.9335\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 0.4552 - accuracy: 0.9354\n",
      "60000/60000 [==============================] - 5s 83us/step\n",
      "Validation accuracy:  0.8755166530609131\n"
     ]
    }
   ],
   "source": [
    "adam_model_improvement(learning_rate=0.00001, Lambda=1e-4, epochs= 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k46KwOSzvvoK"
   },
   "source": [
    "#### Trial 4:Tuning the model with Lambda value of 1e-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CL8titfMCNof",
    "outputId": "92115cf9-b5cb-4a5d-e1c3-09f8ef59c395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 33us/step - loss: 4.0049 - accuracy: 0.1086\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.9086 - accuracy: 0.1239\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 3.8337 - accuracy: 0.1369\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.7690 - accuracy: 0.1522\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.7126 - accuracy: 0.1686\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.6606 - accuracy: 0.1826\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.6143 - accuracy: 0.2002\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.5696 - accuracy: 0.2154\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.5283 - accuracy: 0.2305\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.4879 - accuracy: 0.2421\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.4517 - accuracy: 0.2586\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.4147 - accuracy: 0.2726\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3814 - accuracy: 0.2861\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3474 - accuracy: 0.3007\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.3151 - accuracy: 0.3132\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2827 - accuracy: 0.3259\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2533 - accuracy: 0.3380\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.2235 - accuracy: 0.3509\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1958 - accuracy: 0.3633\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1691 - accuracy: 0.3746\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1441 - accuracy: 0.3850\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.1188 - accuracy: 0.3984\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0939 - accuracy: 0.4094\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0696 - accuracy: 0.4204\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0476 - accuracy: 0.4315\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0258 - accuracy: 0.4413\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 3.0028 - accuracy: 0.4538\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9824 - accuracy: 0.4605\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9614 - accuracy: 0.4700\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9417 - accuracy: 0.4798\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9230 - accuracy: 0.4893\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.9030 - accuracy: 0.5004\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8845 - accuracy: 0.5095\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.8660 - accuracy: 0.5175\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8478 - accuracy: 0.5249\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8306 - accuracy: 0.5337\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.8149 - accuracy: 0.5424\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.7977 - accuracy: 0.5494\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7817 - accuracy: 0.5564\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7661 - accuracy: 0.5650\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7513 - accuracy: 0.5718\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7353 - accuracy: 0.5788\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7201 - accuracy: 0.5851\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.7053 - accuracy: 0.5939\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6926 - accuracy: 0.5979\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6775 - accuracy: 0.6056\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6641 - accuracy: 0.6126\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6485 - accuracy: 0.6187\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6364 - accuracy: 0.6248\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6225 - accuracy: 0.6305\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.6097 - accuracy: 0.6355\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5967 - accuracy: 0.6412\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5848 - accuracy: 0.6455\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5719 - accuracy: 0.6518\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5598 - accuracy: 0.6558\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5480 - accuracy: 0.6608\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5357 - accuracy: 0.6664\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5229 - accuracy: 0.6713\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5121 - accuracy: 0.6763\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.5000 - accuracy: 0.6811\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4890 - accuracy: 0.6847\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4768 - accuracy: 0.6881\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4655 - accuracy: 0.6923\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4550 - accuracy: 0.6964\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4450 - accuracy: 0.6996\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4341 - accuracy: 0.7045\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4227 - accuracy: 0.7083\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4111 - accuracy: 0.7110\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.4015 - accuracy: 0.7143\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3904 - accuracy: 0.7187\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3814 - accuracy: 0.7214\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3707 - accuracy: 0.7247\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3603 - accuracy: 0.7298\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3513 - accuracy: 0.7321\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3412 - accuracy: 0.7349\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3303 - accuracy: 0.7378\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3216 - accuracy: 0.7403\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3116 - accuracy: 0.7450\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.3029 - accuracy: 0.7470\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2931 - accuracy: 0.7500\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2834 - accuracy: 0.7524\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2751 - accuracy: 0.7561\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2654 - accuracy: 0.7583\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2561 - accuracy: 0.7608\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2481 - accuracy: 0.7629\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2392 - accuracy: 0.7654\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2297 - accuracy: 0.7688\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2214 - accuracy: 0.7700\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2123 - accuracy: 0.7745\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.2035 - accuracy: 0.7761\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1948 - accuracy: 0.7770\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1869 - accuracy: 0.7797\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1789 - accuracy: 0.7809\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.1709 - accuracy: 0.7843\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1625 - accuracy: 0.7857\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1549 - accuracy: 0.7880\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1452 - accuracy: 0.7911\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1366 - accuracy: 0.7937\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1292 - accuracy: 0.7957\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1220 - accuracy: 0.7971\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1133 - accuracy: 0.8006\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.1059 - accuracy: 0.8020\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 2.0977 - accuracy: 0.8038\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0899 - accuracy: 0.8049\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0813 - accuracy: 0.8082\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0752 - accuracy: 0.8096\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0670 - accuracy: 0.8107\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0596 - accuracy: 0.8118\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0515 - accuracy: 0.8157\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0442 - accuracy: 0.8171\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0370 - accuracy: 0.8185\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0292 - accuracy: 0.8198\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0223 - accuracy: 0.8210\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0152 - accuracy: 0.8235\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 2.0078 - accuracy: 0.8263\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9996 - accuracy: 0.8265\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9928 - accuracy: 0.8292\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9870 - accuracy: 0.8303\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9794 - accuracy: 0.8307\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9723 - accuracy: 0.8343\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9646 - accuracy: 0.8351\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9576 - accuracy: 0.8368\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9502 - accuracy: 0.8377\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9448 - accuracy: 0.8377\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9372 - accuracy: 0.8405\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9312 - accuracy: 0.8420\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9235 - accuracy: 0.8448\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9178 - accuracy: 0.8449\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.9110 - accuracy: 0.8464\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.9028 - accuracy: 0.8480\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8971 - accuracy: 0.8496\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8917 - accuracy: 0.8494\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8841 - accuracy: 0.8522\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8784 - accuracy: 0.8524\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8715 - accuracy: 0.8537\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8654 - accuracy: 0.8553\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8599 - accuracy: 0.8554\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8530 - accuracy: 0.8570\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8464 - accuracy: 0.8598\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8398 - accuracy: 0.8606\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8329 - accuracy: 0.8619\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8275 - accuracy: 0.8623\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8210 - accuracy: 0.8633\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8150 - accuracy: 0.8648\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8083 - accuracy: 0.8656\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.8029 - accuracy: 0.8662\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7961 - accuracy: 0.8682\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7905 - accuracy: 0.8687\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 15us/step - loss: 1.7847 - accuracy: 0.8708\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7780 - accuracy: 0.8704\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7737 - accuracy: 0.8713\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7667 - accuracy: 0.8735\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7612 - accuracy: 0.8746\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7549 - accuracy: 0.8756\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7494 - accuracy: 0.8765\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7433 - accuracy: 0.8780\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7379 - accuracy: 0.8784\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7323 - accuracy: 0.8790\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7265 - accuracy: 0.8811\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7198 - accuracy: 0.8818\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7150 - accuracy: 0.8820\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7086 - accuracy: 0.8832\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.7045 - accuracy: 0.8842\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6986 - accuracy: 0.8850\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6925 - accuracy: 0.8858\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6877 - accuracy: 0.8862\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6809 - accuracy: 0.8883\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6764 - accuracy: 0.8891\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6707 - accuracy: 0.8897\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6655 - accuracy: 0.8903\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6598 - accuracy: 0.8905\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6548 - accuracy: 0.8914\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6499 - accuracy: 0.8924\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6444 - accuracy: 0.8931\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6399 - accuracy: 0.8947\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6341 - accuracy: 0.8953\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6286 - accuracy: 0.8957\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6224 - accuracy: 0.8969\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6179 - accuracy: 0.8972\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6126 - accuracy: 0.8982\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6081 - accuracy: 0.8990\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.6029 - accuracy: 0.9001\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5975 - accuracy: 0.9008\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5925 - accuracy: 0.9013\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5875 - accuracy: 0.9009\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5831 - accuracy: 0.9020\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5768 - accuracy: 0.9043\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5727 - accuracy: 0.9050\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5670 - accuracy: 0.9063\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5629 - accuracy: 0.9058\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5584 - accuracy: 0.9073\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5537 - accuracy: 0.9069\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5483 - accuracy: 0.9084\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5437 - accuracy: 0.9080\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5390 - accuracy: 0.9105\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5329 - accuracy: 0.9106\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5294 - accuracy: 0.9117\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5252 - accuracy: 0.9113\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5204 - accuracy: 0.9125\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 1.5160 - accuracy: 0.9125\n",
      "60000/60000 [==============================] - 5s 83us/step\n",
      "Validation accuracy:  0.8656833171844482\n"
     ]
    }
   ],
   "source": [
    "adam_model_improvement(learning_rate=0.00001, Lambda=1e-1, epochs= 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above Trials:\n",
    "1. It can be found that in the above trials out of three trials fourth trial gives good performance.\n",
    "2. The performance of the model with the above parameters gives training accuracy of 91.3% and on validation data it gives around 86.5%.\n",
    "3. Model in the Trial - 4 can be considered as acceptable because there is no overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HFQSajRMEeB"
   },
   "source": [
    "### Step 11: Finalizing the models:\n",
    "    Among the models built above and subjected to Hyperparameter tuned, the model that is optimized with Adam optimizer with the learning rate of 0.00001 and lambda of Ridge regularization of 1e-4 gave good performance because it does not have overfitting and the difference in accuracy on the training and validation is also less comparatively. Now let us build the model seperately with those parameters and evaluate the performance on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-CQKNgA9CU8M"
   },
   "outputs": [],
   "source": [
    "model_bn = Sequential()\n",
    "\n",
    "model_bn.add(Dense(1024, input_shape = (1024, ), kernel_initializer='he_normal', name ='Layer_1'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(512, kernel_initializer='he_normal', name ='Layer_2'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(128, kernel_initializer='he_normal', name ='Layer_3'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(64, kernel_initializer='he_normal', name ='Layer_4'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_5'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(32, kernel_initializer='he_normal', name ='Layer_6'))\n",
    "model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "model_bn.add(Activation('relu'))\n",
    "\n",
    "model_bn.add(Dense(10, name ='Output_Layer', kernel_regularizer = l2(1e-1)))\n",
    "model_bn.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5ykPw_dSLaVq",
    "outputId": "f26184de-18e5-4114-e3d9-5ed8036a1324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 2s 42us/step - loss: 4.0365 - accuracy: 0.1159 - val_loss: 3.8045 - val_accuracy: 0.1071\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.9248 - accuracy: 0.1410 - val_loss: 3.7921 - val_accuracy: 0.1265\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 3.8347 - accuracy: 0.1642 - val_loss: 3.7845 - val_accuracy: 0.1383\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.7605 - accuracy: 0.1872 - val_loss: 3.7605 - val_accuracy: 0.1548\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.6955 - accuracy: 0.2055 - val_loss: 3.7213 - val_accuracy: 0.1741\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.6381 - accuracy: 0.2229 - val_loss: 3.6792 - val_accuracy: 0.1925\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.5863 - accuracy: 0.2387 - val_loss: 3.6269 - val_accuracy: 0.2164\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.5394 - accuracy: 0.2542 - val_loss: 3.5731 - val_accuracy: 0.2379\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.4972 - accuracy: 0.2675 - val_loss: 3.5279 - val_accuracy: 0.2540\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.4578 - accuracy: 0.2819 - val_loss: 3.4875 - val_accuracy: 0.2697\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.4213 - accuracy: 0.2926 - val_loss: 3.4465 - val_accuracy: 0.2833\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.3876 - accuracy: 0.3048 - val_loss: 3.4095 - val_accuracy: 0.2973\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.3543 - accuracy: 0.3174 - val_loss: 3.3780 - val_accuracy: 0.3072\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.3234 - accuracy: 0.3261 - val_loss: 3.3465 - val_accuracy: 0.3194\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.2959 - accuracy: 0.3372 - val_loss: 3.3152 - val_accuracy: 0.3311\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.2689 - accuracy: 0.3478 - val_loss: 3.2867 - val_accuracy: 0.3410\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.2443 - accuracy: 0.3555 - val_loss: 3.2628 - val_accuracy: 0.3501\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.2200 - accuracy: 0.3635 - val_loss: 3.2384 - val_accuracy: 0.3599\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.1969 - accuracy: 0.3725 - val_loss: 3.2115 - val_accuracy: 0.3697\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.1749 - accuracy: 0.3816 - val_loss: 3.1900 - val_accuracy: 0.3787\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.1530 - accuracy: 0.3882 - val_loss: 3.1733 - val_accuracy: 0.3822\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.1331 - accuracy: 0.3962 - val_loss: 3.1495 - val_accuracy: 0.3905\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.1129 - accuracy: 0.4030 - val_loss: 3.1298 - val_accuracy: 0.4002\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.0925 - accuracy: 0.4116 - val_loss: 3.1108 - val_accuracy: 0.4063\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.0743 - accuracy: 0.4187 - val_loss: 3.0911 - val_accuracy: 0.4134\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.0568 - accuracy: 0.4253 - val_loss: 3.0744 - val_accuracy: 0.4193\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.0381 - accuracy: 0.4332 - val_loss: 3.0582 - val_accuracy: 0.4279\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.0208 - accuracy: 0.4391 - val_loss: 3.0381 - val_accuracy: 0.4337\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 3.0035 - accuracy: 0.4477 - val_loss: 3.0233 - val_accuracy: 0.4383\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.9863 - accuracy: 0.4549 - val_loss: 3.0065 - val_accuracy: 0.4455\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.9702 - accuracy: 0.4596 - val_loss: 2.9906 - val_accuracy: 0.4512\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.9547 - accuracy: 0.4669 - val_loss: 2.9712 - val_accuracy: 0.4586\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.9377 - accuracy: 0.4740 - val_loss: 2.9586 - val_accuracy: 0.4648\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.9217 - accuracy: 0.4799 - val_loss: 2.9446 - val_accuracy: 0.4676\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.9067 - accuracy: 0.4869 - val_loss: 2.9301 - val_accuracy: 0.4753\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8919 - accuracy: 0.4923 - val_loss: 2.9134 - val_accuracy: 0.4831\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8781 - accuracy: 0.4986 - val_loss: 2.8989 - val_accuracy: 0.4875\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8633 - accuracy: 0.5060 - val_loss: 2.8834 - val_accuracy: 0.4942\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8485 - accuracy: 0.5121 - val_loss: 2.8731 - val_accuracy: 0.5020\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.8335 - accuracy: 0.5180 - val_loss: 2.8654 - val_accuracy: 0.5036\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8194 - accuracy: 0.5248 - val_loss: 2.8426 - val_accuracy: 0.5144\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.8059 - accuracy: 0.5320 - val_loss: 2.8370 - val_accuracy: 0.5159\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7926 - accuracy: 0.5385 - val_loss: 2.8200 - val_accuracy: 0.5237\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7791 - accuracy: 0.5441 - val_loss: 2.8050 - val_accuracy: 0.5293\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7655 - accuracy: 0.5497 - val_loss: 2.7937 - val_accuracy: 0.5345\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7521 - accuracy: 0.5574 - val_loss: 2.7805 - val_accuracy: 0.5411\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7399 - accuracy: 0.5626 - val_loss: 2.7701 - val_accuracy: 0.5466\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.7272 - accuracy: 0.5675 - val_loss: 2.7541 - val_accuracy: 0.5562\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7145 - accuracy: 0.5745 - val_loss: 2.7441 - val_accuracy: 0.5612\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.7007 - accuracy: 0.5806 - val_loss: 2.7302 - val_accuracy: 0.5647\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.6887 - accuracy: 0.5882 - val_loss: 2.7216 - val_accuracy: 0.5727\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.6772 - accuracy: 0.5922 - val_loss: 2.7162 - val_accuracy: 0.5763\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.6642 - accuracy: 0.5991 - val_loss: 2.6996 - val_accuracy: 0.5804\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.6521 - accuracy: 0.6045 - val_loss: 2.6877 - val_accuracy: 0.5889\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.6413 - accuracy: 0.6123 - val_loss: 2.6776 - val_accuracy: 0.5930\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.6300 - accuracy: 0.6180 - val_loss: 2.6638 - val_accuracy: 0.6024\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.6170 - accuracy: 0.6228 - val_loss: 2.6528 - val_accuracy: 0.6039\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.6066 - accuracy: 0.6269 - val_loss: 2.6421 - val_accuracy: 0.6062\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.5951 - accuracy: 0.6330 - val_loss: 2.6315 - val_accuracy: 0.6129\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.5834 - accuracy: 0.6394 - val_loss: 2.6212 - val_accuracy: 0.6173\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.5727 - accuracy: 0.6436 - val_loss: 2.6049 - val_accuracy: 0.6236\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.5605 - accuracy: 0.6497 - val_loss: 2.6065 - val_accuracy: 0.6211\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.5506 - accuracy: 0.6540 - val_loss: 2.5875 - val_accuracy: 0.6352\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.5399 - accuracy: 0.6590 - val_loss: 2.5741 - val_accuracy: 0.6425\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.5285 - accuracy: 0.6642 - val_loss: 2.5728 - val_accuracy: 0.6410\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.5187 - accuracy: 0.6690 - val_loss: 2.5534 - val_accuracy: 0.6490\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.5073 - accuracy: 0.6731 - val_loss: 2.5453 - val_accuracy: 0.6513\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.4965 - accuracy: 0.6786 - val_loss: 2.5304 - val_accuracy: 0.6546\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.4867 - accuracy: 0.6836 - val_loss: 2.5278 - val_accuracy: 0.6610\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.4761 - accuracy: 0.6871 - val_loss: 2.5194 - val_accuracy: 0.6593\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.4669 - accuracy: 0.6901 - val_loss: 2.5029 - val_accuracy: 0.6711\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.4559 - accuracy: 0.6954 - val_loss: 2.4983 - val_accuracy: 0.6737\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.4464 - accuracy: 0.7002 - val_loss: 2.4874 - val_accuracy: 0.6794\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.4363 - accuracy: 0.7040 - val_loss: 2.4740 - val_accuracy: 0.6833\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.4271 - accuracy: 0.7060 - val_loss: 2.4643 - val_accuracy: 0.6847\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.4176 - accuracy: 0.7118 - val_loss: 2.4624 - val_accuracy: 0.6894\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.4058 - accuracy: 0.7156 - val_loss: 2.4486 - val_accuracy: 0.6948\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.3977 - accuracy: 0.7196 - val_loss: 2.4409 - val_accuracy: 0.6947\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.3880 - accuracy: 0.7214 - val_loss: 2.4276 - val_accuracy: 0.7006\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.3791 - accuracy: 0.7263 - val_loss: 2.4208 - val_accuracy: 0.7048\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.3701 - accuracy: 0.7297 - val_loss: 2.4151 - val_accuracy: 0.7048\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.3611 - accuracy: 0.7341 - val_loss: 2.4029 - val_accuracy: 0.7071\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.3509 - accuracy: 0.7364 - val_loss: 2.3966 - val_accuracy: 0.7136\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.3423 - accuracy: 0.7402 - val_loss: 2.3845 - val_accuracy: 0.7173\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.3327 - accuracy: 0.7424 - val_loss: 2.3789 - val_accuracy: 0.7205\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.3241 - accuracy: 0.7479 - val_loss: 2.3721 - val_accuracy: 0.7206\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.3154 - accuracy: 0.7501 - val_loss: 2.3620 - val_accuracy: 0.7236\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.3070 - accuracy: 0.7520 - val_loss: 2.3525 - val_accuracy: 0.7270\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2984 - accuracy: 0.7540 - val_loss: 2.3409 - val_accuracy: 0.7290\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2887 - accuracy: 0.7587 - val_loss: 2.3419 - val_accuracy: 0.7286\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2813 - accuracy: 0.7595 - val_loss: 2.3304 - val_accuracy: 0.7378\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2722 - accuracy: 0.7632 - val_loss: 2.3177 - val_accuracy: 0.7379\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2636 - accuracy: 0.7659 - val_loss: 2.3115 - val_accuracy: 0.7386\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2564 - accuracy: 0.7697 - val_loss: 2.3043 - val_accuracy: 0.7434\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2466 - accuracy: 0.7722 - val_loss: 2.2924 - val_accuracy: 0.7480\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2393 - accuracy: 0.7740 - val_loss: 2.2944 - val_accuracy: 0.7425\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2304 - accuracy: 0.7778 - val_loss: 2.2808 - val_accuracy: 0.7516\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2234 - accuracy: 0.7791 - val_loss: 2.2754 - val_accuracy: 0.7527\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2145 - accuracy: 0.7816 - val_loss: 2.2663 - val_accuracy: 0.7564\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.2059 - accuracy: 0.7847 - val_loss: 2.2588 - val_accuracy: 0.7518\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1986 - accuracy: 0.7862 - val_loss: 2.2476 - val_accuracy: 0.7592\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1900 - accuracy: 0.7895 - val_loss: 2.2436 - val_accuracy: 0.7591\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1824 - accuracy: 0.7918 - val_loss: 2.2329 - val_accuracy: 0.7628\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1742 - accuracy: 0.7952 - val_loss: 2.2281 - val_accuracy: 0.7695\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1668 - accuracy: 0.7957 - val_loss: 2.2177 - val_accuracy: 0.7695\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1587 - accuracy: 0.7987 - val_loss: 2.2128 - val_accuracy: 0.7707\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1512 - accuracy: 0.8006 - val_loss: 2.2056 - val_accuracy: 0.7702\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1438 - accuracy: 0.8031 - val_loss: 2.1987 - val_accuracy: 0.7718\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1354 - accuracy: 0.8057 - val_loss: 2.1871 - val_accuracy: 0.7746\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1281 - accuracy: 0.8076 - val_loss: 2.1841 - val_accuracy: 0.7790\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1199 - accuracy: 0.8118 - val_loss: 2.1783 - val_accuracy: 0.7789\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1137 - accuracy: 0.8114 - val_loss: 2.1730 - val_accuracy: 0.7781\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.1060 - accuracy: 0.8137 - val_loss: 2.1638 - val_accuracy: 0.7825\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0986 - accuracy: 0.8158 - val_loss: 2.1566 - val_accuracy: 0.7836\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0909 - accuracy: 0.8174 - val_loss: 2.1495 - val_accuracy: 0.7864\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 2.0836 - accuracy: 0.8198 - val_loss: 2.1386 - val_accuracy: 0.7918\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0767 - accuracy: 0.8218 - val_loss: 2.1330 - val_accuracy: 0.7903\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0692 - accuracy: 0.8237 - val_loss: 2.1282 - val_accuracy: 0.7942\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0618 - accuracy: 0.8265 - val_loss: 2.1196 - val_accuracy: 0.7904\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0539 - accuracy: 0.8281 - val_loss: 2.1127 - val_accuracy: 0.7963\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0472 - accuracy: 0.8282 - val_loss: 2.1111 - val_accuracy: 0.7937\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0400 - accuracy: 0.8310 - val_loss: 2.0992 - val_accuracy: 0.7989\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0339 - accuracy: 0.8325 - val_loss: 2.0940 - val_accuracy: 0.7999\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0267 - accuracy: 0.8333 - val_loss: 2.0855 - val_accuracy: 0.8033\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 2.0200 - accuracy: 0.8354 - val_loss: 2.0835 - val_accuracy: 0.8016\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0124 - accuracy: 0.8379 - val_loss: 2.0739 - val_accuracy: 0.8067\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 2.0063 - accuracy: 0.8390 - val_loss: 2.0679 - val_accuracy: 0.8084\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9993 - accuracy: 0.8417 - val_loss: 2.0633 - val_accuracy: 0.8089\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 1s 24us/step - loss: 1.9920 - accuracy: 0.8426 - val_loss: 2.0567 - val_accuracy: 0.8088\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9862 - accuracy: 0.8447 - val_loss: 2.0500 - val_accuracy: 0.8106\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9792 - accuracy: 0.8464 - val_loss: 2.0399 - val_accuracy: 0.8122\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9730 - accuracy: 0.8474 - val_loss: 2.0336 - val_accuracy: 0.8141\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9655 - accuracy: 0.8489 - val_loss: 2.0288 - val_accuracy: 0.8155\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9589 - accuracy: 0.8503 - val_loss: 2.0213 - val_accuracy: 0.8180\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9535 - accuracy: 0.8515 - val_loss: 2.0169 - val_accuracy: 0.8162\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9468 - accuracy: 0.8527 - val_loss: 2.0120 - val_accuracy: 0.8173\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9400 - accuracy: 0.8550 - val_loss: 2.0045 - val_accuracy: 0.8181\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9341 - accuracy: 0.8547 - val_loss: 1.9998 - val_accuracy: 0.8206\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9279 - accuracy: 0.8555 - val_loss: 1.9924 - val_accuracy: 0.8231\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9196 - accuracy: 0.8582 - val_loss: 1.9885 - val_accuracy: 0.8236\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9149 - accuracy: 0.8595 - val_loss: 1.9829 - val_accuracy: 0.8250\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9088 - accuracy: 0.8612 - val_loss: 1.9789 - val_accuracy: 0.8263\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9018 - accuracy: 0.8617 - val_loss: 1.9699 - val_accuracy: 0.8244\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8958 - accuracy: 0.8631 - val_loss: 1.9658 - val_accuracy: 0.8256\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8897 - accuracy: 0.8648 - val_loss: 1.9570 - val_accuracy: 0.8302\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8839 - accuracy: 0.8656 - val_loss: 1.9508 - val_accuracy: 0.8303\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8780 - accuracy: 0.8671 - val_loss: 1.9422 - val_accuracy: 0.8299\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8717 - accuracy: 0.8677 - val_loss: 1.9359 - val_accuracy: 0.8316\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8652 - accuracy: 0.8689 - val_loss: 1.9369 - val_accuracy: 0.8360\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8588 - accuracy: 0.8714 - val_loss: 1.9280 - val_accuracy: 0.8317\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8532 - accuracy: 0.8728 - val_loss: 1.9285 - val_accuracy: 0.8351\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8466 - accuracy: 0.8751 - val_loss: 1.9136 - val_accuracy: 0.8359\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8415 - accuracy: 0.8737 - val_loss: 1.9093 - val_accuracy: 0.8364\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8350 - accuracy: 0.8754 - val_loss: 1.9085 - val_accuracy: 0.8365\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8296 - accuracy: 0.8760 - val_loss: 1.9043 - val_accuracy: 0.8375\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8237 - accuracy: 0.8765 - val_loss: 1.8939 - val_accuracy: 0.8401\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8180 - accuracy: 0.8787 - val_loss: 1.8886 - val_accuracy: 0.8405\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8127 - accuracy: 0.8781 - val_loss: 1.8870 - val_accuracy: 0.8400\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 1s 22us/step - loss: 1.8064 - accuracy: 0.8813 - val_loss: 1.8765 - val_accuracy: 0.8440\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.8010 - accuracy: 0.8810 - val_loss: 1.8782 - val_accuracy: 0.8421\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7950 - accuracy: 0.8836 - val_loss: 1.8690 - val_accuracy: 0.8417\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7895 - accuracy: 0.8837 - val_loss: 1.8658 - val_accuracy: 0.8454\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7840 - accuracy: 0.8844 - val_loss: 1.8579 - val_accuracy: 0.8424\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7776 - accuracy: 0.8859 - val_loss: 1.8552 - val_accuracy: 0.8474\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7717 - accuracy: 0.8873 - val_loss: 1.8430 - val_accuracy: 0.8473\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7671 - accuracy: 0.8873 - val_loss: 1.8397 - val_accuracy: 0.8489\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7618 - accuracy: 0.8875 - val_loss: 1.8356 - val_accuracy: 0.8498\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7563 - accuracy: 0.8888 - val_loss: 1.8370 - val_accuracy: 0.8501\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7496 - accuracy: 0.8910 - val_loss: 1.8205 - val_accuracy: 0.8522\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7453 - accuracy: 0.8899 - val_loss: 1.8219 - val_accuracy: 0.8495\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7388 - accuracy: 0.8916 - val_loss: 1.8170 - val_accuracy: 0.8528\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7340 - accuracy: 0.8922 - val_loss: 1.8112 - val_accuracy: 0.8542\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7295 - accuracy: 0.8935 - val_loss: 1.8084 - val_accuracy: 0.8542\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7241 - accuracy: 0.8931 - val_loss: 1.8036 - val_accuracy: 0.8534\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7181 - accuracy: 0.8961 - val_loss: 1.7955 - val_accuracy: 0.8543\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7117 - accuracy: 0.8966 - val_loss: 1.7908 - val_accuracy: 0.8562\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7071 - accuracy: 0.8971 - val_loss: 1.7861 - val_accuracy: 0.8546\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.7027 - accuracy: 0.8983 - val_loss: 1.7834 - val_accuracy: 0.8539\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6964 - accuracy: 0.8989 - val_loss: 1.7713 - val_accuracy: 0.8572\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6909 - accuracy: 0.9001 - val_loss: 1.7721 - val_accuracy: 0.8591\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6862 - accuracy: 0.9001 - val_loss: 1.7621 - val_accuracy: 0.8589\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6811 - accuracy: 0.9005 - val_loss: 1.7662 - val_accuracy: 0.8590\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6761 - accuracy: 0.9010 - val_loss: 1.7523 - val_accuracy: 0.8612\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6713 - accuracy: 0.9027 - val_loss: 1.7531 - val_accuracy: 0.8610\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6661 - accuracy: 0.9027 - val_loss: 1.7483 - val_accuracy: 0.8624\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6604 - accuracy: 0.9039 - val_loss: 1.7392 - val_accuracy: 0.8633\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6552 - accuracy: 0.9043 - val_loss: 1.7384 - val_accuracy: 0.8614\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6498 - accuracy: 0.9068 - val_loss: 1.7301 - val_accuracy: 0.8643\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6463 - accuracy: 0.9062 - val_loss: 1.7302 - val_accuracy: 0.8645\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6409 - accuracy: 0.9070 - val_loss: 1.7231 - val_accuracy: 0.8645\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6361 - accuracy: 0.9079 - val_loss: 1.7167 - val_accuracy: 0.8644\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6312 - accuracy: 0.9082 - val_loss: 1.7132 - val_accuracy: 0.8667\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6257 - accuracy: 0.9099 - val_loss: 1.7093 - val_accuracy: 0.8669\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6212 - accuracy: 0.9100 - val_loss: 1.7116 - val_accuracy: 0.8634\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6165 - accuracy: 0.9112 - val_loss: 1.7017 - val_accuracy: 0.8669\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6112 - accuracy: 0.9120 - val_loss: 1.6966 - val_accuracy: 0.8643\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6067 - accuracy: 0.9120 - val_loss: 1.6985 - val_accuracy: 0.8660\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.6021 - accuracy: 0.9136 - val_loss: 1.6888 - val_accuracy: 0.8695\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.5972 - accuracy: 0.9143 - val_loss: 1.6833 - val_accuracy: 0.8694\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.5920 - accuracy: 0.9144 - val_loss: 1.6785 - val_accuracy: 0.8701\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(0.00001)\n",
    "model_bn.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history_bn_adam = model_bn.fit(X_train, y_train,validation_data=(X_val, y_val), batch_size = 1000, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 795
    },
    "colab_type": "code",
    "id": "dVu6QYTGSiQ8",
    "outputId": "ea5333d8-7ace-4b15-eb31-ac2cc4d77e70"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss function\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(history_bn_adam.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(history_bn_adam.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "# Plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(history_bn_adam.history['accuracy']), 'r', label='train')\n",
    "ax.plot(np.sqrt(history_bn_adam.history['val_accuracy']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZFF9v7hxLJj3",
    "outputId": "c7da2361-9b7e-4009-f945-bbb3949c0fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 84us/step\n",
      "Validation accuracy:  0.7594444155693054\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_bt_ad = model_bn.evaluate(X_test, y_test)\n",
    "print('Validation accuracy: ', evaluation_val_bt_ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. It can be found that in the above output the accuracy of the model on training data is ~91% and on validation data is ~87%.\n",
    "2. Also the first plot shows that as the number of epochs increses, loss gradually decreasses for both the data. But the Loss on validation data is high compared to the loss on the training data.\n",
    "3. In the second plot as the number of epochs increses, accuracy gradually decreasses for both the data. But the accuracy on validation data is high compared to the loss on the training data.\n",
    "4. The performance of the model on testing data is just ~76%.\\\n",
    "\n",
    "\n",
    "    Below, a try was made on the model by doing many hyperparameters tuning using GridsearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ek4K6wnlXIFN"
   },
   "source": [
    "### Step 12: Many Hyperparameters tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwl9aTrpXiHt"
   },
   "outputs": [],
   "source": [
    "def model_h(init_mode):\n",
    "    model_bn = Sequential()\n",
    "\n",
    "    model_bn.add(Dense(1024, input_shape = (1024, ), kernel_initializer=init_mode, name ='Layer_1'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(512, kernel_initializer=init_mode, name ='Layer_2'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(128, kernel_initializer=init_mode, name ='Layer_3'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(64, kernel_initializer=init_mode, name ='Layer_4'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(32, kernel_initializer=init_mode, name ='Layer_5'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(32, kernel_initializer=init_mode, name ='Layer_6'))\n",
    "    model_bn.add(BatchNormalization(center=True, scale=True ))\n",
    "    model_bn.add(Activation('relu'))\n",
    "\n",
    "    model_bn.add(Dense(10, kernel_initializer=init_mode, name ='Output_Layer', kernel_regularizer = l2(1e-1)))\n",
    "    model_bn.add(Activation('softmax'))\n",
    "\n",
    "    model_bn.compile(optimizer = Adam(), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZayJrkEFvs33",
    "outputId": "6c38d040-d0f0-4c15-ac47-c89a6c022033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1333 - accuracy: 0.9902\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.1210 - accuracy: 0.9933\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1191 - accuracy: 0.9935\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1286 - accuracy: 0.9899\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1155 - accuracy: 0.9935\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1212 - accuracy: 0.9916\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1205 - accuracy: 0.9918\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1146 - accuracy: 0.9932\n",
      "Epoch 117/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1165 - accuracy: 0.9924\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1183 - accuracy: 0.9915\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1131 - accuracy: 0.9929\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1134 - accuracy: 0.9926\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1138 - accuracy: 0.9925\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1208 - accuracy: 0.9899\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1090 - accuracy: 0.9933\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1088 - accuracy: 0.9929\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1023 - accuracy: 0.9949\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1089 - accuracy: 0.9924\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1096 - accuracy: 0.9923\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1039 - accuracy: 0.9937\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1002 - accuracy: 0.9945\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1109 - accuracy: 0.9914\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0969 - accuracy: 0.9946\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1023 - accuracy: 0.9931\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1067 - accuracy: 0.9918\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1014 - accuracy: 0.9930\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0963 - accuracy: 0.9949\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1031 - accuracy: 0.9923\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0916 - accuracy: 0.9955\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0973 - accuracy: 0.9933\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0949 - accuracy: 0.9940\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0951 - accuracy: 0.9941\n",
      "Epoch 141/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0933 - accuracy: 0.9943\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0963 - accuracy: 0.9936\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0908 - accuracy: 0.9943\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0979 - accuracy: 0.9926\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0868 - accuracy: 0.9953\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0910 - accuracy: 0.9941\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0836 - accuracy: 0.9963\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0884 - accuracy: 0.9943\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0915 - accuracy: 0.9933\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0854 - accuracy: 0.9955\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0900 - accuracy: 0.9931\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0933 - accuracy: 0.9925\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0839 - accuracy: 0.9951\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0870 - accuracy: 0.9941\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0869 - accuracy: 0.9941\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0792 - accuracy: 0.9959\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0911 - accuracy: 0.9922\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0834 - accuracy: 0.9946\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0802 - accuracy: 0.9953\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0802 - accuracy: 0.9950\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0803 - accuracy: 0.9946\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0843 - accuracy: 0.9939\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0773 - accuracy: 0.9956\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0767 - accuracy: 0.9959\n",
      "Epoch 165/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0786 - accuracy: 0.9945\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0807 - accuracy: 0.9945\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0706 - accuracy: 0.9970\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0786 - accuracy: 0.9948\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0780 - accuracy: 0.9945\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0773 - accuracy: 0.9946\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0756 - accuracy: 0.9949\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0702 - accuracy: 0.9966\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0725 - accuracy: 0.9960\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0759 - accuracy: 0.9951\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0744 - accuracy: 0.9950\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0761 - accuracy: 0.9943\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0733 - accuracy: 0.9951\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0706 - accuracy: 0.9956\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0747 - accuracy: 0.9945\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0709 - accuracy: 0.9957\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0672 - accuracy: 0.9965\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0730 - accuracy: 0.9948\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0629 - accuracy: 0.9976\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0718 - accuracy: 0.9946\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0739 - accuracy: 0.9947\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0691 - accuracy: 0.9957\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0675 - accuracy: 0.9955\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0628 - accuracy: 0.9972\n",
      "Epoch 189/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0673 - accuracy: 0.9957\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0677 - accuracy: 0.9952\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0595 - accuracy: 0.9976\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0638 - accuracy: 0.9961\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.0713 - accuracy: 0.9940\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0664 - accuracy: 0.9956\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0663 - accuracy: 0.9951\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0676 - accuracy: 0.9945\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0615 - accuracy: 0.9964\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0628 - accuracy: 0.9962\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0638 - accuracy: 0.9962\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0626 - accuracy: 0.9959\n",
      "14000/14000 [==============================] - 0s 13us/step\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 1s 36us/step - loss: 4.0570 - accuracy: 0.3006\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 3.1847 - accuracy: 0.5360\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 2.7084 - accuracy: 0.6266\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 2.3261 - accuracy: 0.6784\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 2.0172 - accuracy: 0.7138\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.7784 - accuracy: 0.7370\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.5817 - accuracy: 0.7570\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.4153 - accuracy: 0.7794\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.2952 - accuracy: 0.7907\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 1.1919 - accuracy: 0.8031\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.1039 - accuracy: 0.8187\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.0452 - accuracy: 0.8224\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.9791 - accuracy: 0.8394\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.9376 - accuracy: 0.8452\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.8833 - accuracy: 0.8580\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.8530 - accuracy: 0.8639\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.8114 - accuracy: 0.8738\n",
      "Epoch 18/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.7794 - accuracy: 0.8802\n",
      "Epoch 19/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.7518 - accuracy: 0.8849\n",
      "Epoch 20/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.7178 - accuracy: 0.8952\n",
      "Epoch 21/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.6958 - accuracy: 0.8996\n",
      "Epoch 22/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.6708 - accuracy: 0.9035\n",
      "Epoch 23/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.6459 - accuracy: 0.9092\n",
      "Epoch 24/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.6224 - accuracy: 0.9143\n",
      "Epoch 25/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.5994 - accuracy: 0.9200\n",
      "Epoch 26/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.5856 - accuracy: 0.9218\n",
      "Epoch 27/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.5656 - accuracy: 0.9262\n",
      "Epoch 28/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.5496 - accuracy: 0.9276\n",
      "Epoch 29/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.5215 - accuracy: 0.9356\n",
      "Epoch 30/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.5182 - accuracy: 0.9335\n",
      "Epoch 31/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4968 - accuracy: 0.9398\n",
      "Epoch 32/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4902 - accuracy: 0.9388\n",
      "Epoch 33/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.4743 - accuracy: 0.9425\n",
      "Epoch 34/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.4590 - accuracy: 0.9466\n",
      "Epoch 35/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4436 - accuracy: 0.9496\n",
      "Epoch 36/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4301 - accuracy: 0.9508\n",
      "Epoch 37/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4198 - accuracy: 0.9548\n",
      "Epoch 38/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4043 - accuracy: 0.9563\n",
      "Epoch 39/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4023 - accuracy: 0.9573\n",
      "Epoch 40/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.3851 - accuracy: 0.9603\n",
      "Epoch 41/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3792 - accuracy: 0.9598\n",
      "Epoch 42/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3699 - accuracy: 0.9620\n",
      "Epoch 43/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3721 - accuracy: 0.9595\n",
      "Epoch 44/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.3488 - accuracy: 0.9661\n",
      "Epoch 45/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.3497 - accuracy: 0.9626\n",
      "Epoch 46/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.3293 - accuracy: 0.9698\n",
      "Epoch 47/200\n",
      "28000/28000 [==============================] - 0s 11us/step - loss: 0.3305 - accuracy: 0.9672\n",
      "Epoch 48/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3213 - accuracy: 0.9695\n",
      "Epoch 49/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3034 - accuracy: 0.9749\n",
      "Epoch 50/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3084 - accuracy: 0.9715\n",
      "Epoch 51/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3035 - accuracy: 0.9714\n",
      "Epoch 52/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3002 - accuracy: 0.9708\n",
      "Epoch 53/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2805 - accuracy: 0.9754\n",
      "Epoch 54/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2880 - accuracy: 0.9725\n",
      "Epoch 55/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2700 - accuracy: 0.9782\n",
      "Epoch 56/200\n",
      "28000/28000 [==============================] - 0s 11us/step - loss: 0.2639 - accuracy: 0.9786\n",
      "Epoch 57/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2726 - accuracy: 0.9741\n",
      "Epoch 58/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2550 - accuracy: 0.9795\n",
      "Epoch 59/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2538 - accuracy: 0.9785\n",
      "Epoch 60/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2470 - accuracy: 0.9794\n",
      "Epoch 61/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2487 - accuracy: 0.9793\n",
      "Epoch 62/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2415 - accuracy: 0.9798\n",
      "Epoch 63/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2444 - accuracy: 0.9776\n",
      "Epoch 64/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2280 - accuracy: 0.9824\n",
      "Epoch 65/200\n",
      "28000/28000 [==============================] - 0s 11us/step - loss: 0.2307 - accuracy: 0.9803\n",
      "Epoch 66/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2226 - accuracy: 0.9834\n",
      "Epoch 67/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2217 - accuracy: 0.9827\n",
      "Epoch 68/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2206 - accuracy: 0.9818\n",
      "Epoch 69/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2046 - accuracy: 0.9862\n",
      "Epoch 70/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2109 - accuracy: 0.9837\n",
      "Epoch 71/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2092 - accuracy: 0.9839\n",
      "Epoch 72/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.2024 - accuracy: 0.9853\n",
      "Epoch 73/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.2038 - accuracy: 0.9839\n",
      "Epoch 74/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1970 - accuracy: 0.9854\n",
      "Epoch 75/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1897 - accuracy: 0.9873\n",
      "Epoch 76/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1930 - accuracy: 0.9851\n",
      "Epoch 77/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1876 - accuracy: 0.9864\n",
      "Epoch 78/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1829 - accuracy: 0.9875\n",
      "Epoch 79/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1850 - accuracy: 0.9867\n",
      "Epoch 80/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1686 - accuracy: 0.9910\n",
      "Epoch 81/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1844 - accuracy: 0.9846\n",
      "Epoch 82/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1821 - accuracy: 0.9854\n",
      "Epoch 83/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1639 - accuracy: 0.9910\n",
      "Epoch 84/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1741 - accuracy: 0.9864\n",
      "Epoch 85/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1697 - accuracy: 0.9879\n",
      "Epoch 86/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1616 - accuracy: 0.9898\n",
      "Epoch 87/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1638 - accuracy: 0.9885\n",
      "Epoch 88/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1573 - accuracy: 0.9893\n",
      "Epoch 89/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1581 - accuracy: 0.9896\n",
      "Epoch 90/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1668 - accuracy: 0.9861\n",
      "Epoch 91/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1505 - accuracy: 0.9907\n",
      "Epoch 92/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1537 - accuracy: 0.9897\n",
      "Epoch 93/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1504 - accuracy: 0.9897\n",
      "Epoch 94/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1480 - accuracy: 0.9903\n",
      "Epoch 95/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1486 - accuracy: 0.9900\n",
      "Epoch 96/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1408 - accuracy: 0.9916\n",
      "Epoch 97/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1453 - accuracy: 0.9905\n",
      "Epoch 98/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1430 - accuracy: 0.9905\n",
      "Epoch 99/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1440 - accuracy: 0.9892\n",
      "Epoch 100/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1352 - accuracy: 0.9915\n",
      "Epoch 101/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1327 - accuracy: 0.9926\n",
      "Epoch 102/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.1355 - accuracy: 0.9914\n",
      "Epoch 103/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1413 - accuracy: 0.9892\n",
      "Epoch 104/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1256 - accuracy: 0.9934\n",
      "Epoch 105/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1370 - accuracy: 0.9894\n",
      "Epoch 106/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1264 - accuracy: 0.9926\n",
      "Epoch 107/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1306 - accuracy: 0.9909\n",
      "Epoch 108/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1246 - accuracy: 0.9927\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1306 - accuracy: 0.9904\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1197 - accuracy: 0.9930\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1230 - accuracy: 0.9918\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1248 - accuracy: 0.9908\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1248 - accuracy: 0.9905\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1094 - accuracy: 0.9952\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1194 - accuracy: 0.9919\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1151 - accuracy: 0.9929\n",
      "Epoch 117/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1227 - accuracy: 0.9909\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1132 - accuracy: 0.9927\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1109 - accuracy: 0.9930\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1123 - accuracy: 0.9930\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1084 - accuracy: 0.9935\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1088 - accuracy: 0.9929\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1126 - accuracy: 0.9922\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1077 - accuracy: 0.9927\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1079 - accuracy: 0.9928\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1074 - accuracy: 0.9929\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1012 - accuracy: 0.9945\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1036 - accuracy: 0.9934\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 0s 11us/step - loss: 0.0996 - accuracy: 0.9943\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1027 - accuracy: 0.9932\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0975 - accuracy: 0.9948\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1004 - accuracy: 0.9933\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1003 - accuracy: 0.9933\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0993 - accuracy: 0.9936\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1003 - accuracy: 0.9936\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0952 - accuracy: 0.9944\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0909 - accuracy: 0.9961\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0942 - accuracy: 0.9943\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0982 - accuracy: 0.9928\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0934 - accuracy: 0.9943\n",
      "Epoch 141/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0959 - accuracy: 0.9931\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0883 - accuracy: 0.9955\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 0s 11us/step - loss: 0.0879 - accuracy: 0.9958\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0966 - accuracy: 0.9923\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0935 - accuracy: 0.9934\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0899 - accuracy: 0.9944\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0874 - accuracy: 0.9944\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0868 - accuracy: 0.9950\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0894 - accuracy: 0.9935\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0825 - accuracy: 0.9959\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0901 - accuracy: 0.9934\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0885 - accuracy: 0.9937\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0864 - accuracy: 0.9943\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0842 - accuracy: 0.9947\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0829 - accuracy: 0.9949\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0791 - accuracy: 0.9962\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0864 - accuracy: 0.9939\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0828 - accuracy: 0.9948\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.0789 - accuracy: 0.9954\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0749 - accuracy: 0.9968\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0837 - accuracy: 0.9939\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0813 - accuracy: 0.9944\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0737 - accuracy: 0.9966\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0862 - accuracy: 0.9925\n",
      "Epoch 165/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0758 - accuracy: 0.9956\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0741 - accuracy: 0.9960\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0815 - accuracy: 0.9933\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0751 - accuracy: 0.9952\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0746 - accuracy: 0.9958\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0771 - accuracy: 0.9949\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0780 - accuracy: 0.9940\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.0708 - accuracy: 0.9960\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0722 - accuracy: 0.9956\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0709 - accuracy: 0.9964\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0745 - accuracy: 0.9950\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0647 - accuracy: 0.9974\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0768 - accuracy: 0.9941\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0744 - accuracy: 0.9942\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0684 - accuracy: 0.9964\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0691 - accuracy: 0.9962\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0719 - accuracy: 0.9945\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 0s 11us/step - loss: 0.0739 - accuracy: 0.9944\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0659 - accuracy: 0.9965\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0691 - accuracy: 0.9953\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0671 - accuracy: 0.9960\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0659 - accuracy: 0.9965\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0653 - accuracy: 0.9964\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0695 - accuracy: 0.9950\n",
      "Epoch 189/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0669 - accuracy: 0.9954\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0634 - accuracy: 0.9962\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0613 - accuracy: 0.9968\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 0s 11us/step - loss: 0.0658 - accuracy: 0.9956\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0656 - accuracy: 0.9956\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0637 - accuracy: 0.9962\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0644 - accuracy: 0.9957\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0632 - accuracy: 0.9964\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0622 - accuracy: 0.9963\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0652 - accuracy: 0.9957\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0554 - accuracy: 0.9979\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0658 - accuracy: 0.9947\n",
      "14000/14000 [==============================] - 0s 12us/step\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 1s 38us/step - loss: 3.5725 - accuracy: 0.3591\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 2.7886 - accuracy: 0.5861\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 2.3718 - accuracy: 0.6497\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 2.0553 - accuracy: 0.6931\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 1.8079 - accuracy: 0.7189\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 1.6071 - accuracy: 0.7417\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.4493 - accuracy: 0.7602\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.3179 - accuracy: 0.7794\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.2203 - accuracy: 0.7903\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.1342 - accuracy: 0.8040\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.0619 - accuracy: 0.8184\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 1.0048 - accuracy: 0.8270\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.9535 - accuracy: 0.8390\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.9125 - accuracy: 0.8451\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.8610 - accuracy: 0.8609\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.8345 - accuracy: 0.8645\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.7992 - accuracy: 0.8753\n",
      "Epoch 18/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.7650 - accuracy: 0.8804\n",
      "Epoch 19/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.7402 - accuracy: 0.8871\n",
      "Epoch 20/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.7224 - accuracy: 0.8890\n",
      "Epoch 21/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.6829 - accuracy: 0.8995\n",
      "Epoch 22/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.6689 - accuracy: 0.9008\n",
      "Epoch 23/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.6383 - accuracy: 0.9113\n",
      "Epoch 24/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.6230 - accuracy: 0.9104\n",
      "Epoch 25/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.6056 - accuracy: 0.9147\n",
      "Epoch 26/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.5863 - accuracy: 0.9174\n",
      "Epoch 27/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.5614 - accuracy: 0.9252\n",
      "Epoch 28/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.5487 - accuracy: 0.9278\n",
      "Epoch 29/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.5260 - accuracy: 0.9314\n",
      "Epoch 30/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.5163 - accuracy: 0.9336\n",
      "Epoch 31/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4915 - accuracy: 0.9388\n",
      "Epoch 32/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4842 - accuracy: 0.9398\n",
      "Epoch 33/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.4763 - accuracy: 0.9400\n",
      "Epoch 34/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4544 - accuracy: 0.9455\n",
      "Epoch 35/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4521 - accuracy: 0.9444\n",
      "Epoch 36/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4258 - accuracy: 0.9528\n",
      "Epoch 37/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4221 - accuracy: 0.9520\n",
      "Epoch 38/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4143 - accuracy: 0.9530\n",
      "Epoch 39/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.4122 - accuracy: 0.9507\n",
      "Epoch 40/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3817 - accuracy: 0.9603\n",
      "Epoch 41/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3811 - accuracy: 0.9580\n",
      "Epoch 42/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.3669 - accuracy: 0.9621\n",
      "Epoch 43/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3604 - accuracy: 0.9623\n",
      "Epoch 44/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3587 - accuracy: 0.9624\n",
      "Epoch 45/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.3419 - accuracy: 0.9660\n",
      "Epoch 46/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.3335 - accuracy: 0.9674\n",
      "Epoch 47/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.3245 - accuracy: 0.9676\n",
      "Epoch 48/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.3252 - accuracy: 0.9667\n",
      "Epoch 49/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.3165 - accuracy: 0.9696\n",
      "Epoch 50/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3079 - accuracy: 0.9702\n",
      "Epoch 51/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.3055 - accuracy: 0.9705\n",
      "Epoch 52/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2870 - accuracy: 0.9754\n",
      "Epoch 53/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.2881 - accuracy: 0.9743\n",
      "Epoch 54/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2807 - accuracy: 0.9749\n",
      "Epoch 55/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2716 - accuracy: 0.9766\n",
      "Epoch 56/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.2691 - accuracy: 0.9767\n",
      "Epoch 57/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2660 - accuracy: 0.9766\n",
      "Epoch 58/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2576 - accuracy: 0.9787\n",
      "Epoch 59/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2516 - accuracy: 0.9787\n",
      "Epoch 60/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.2494 - accuracy: 0.9790\n",
      "Epoch 61/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2415 - accuracy: 0.9807\n",
      "Epoch 62/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2508 - accuracy: 0.9772\n",
      "Epoch 63/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2306 - accuracy: 0.9827\n",
      "Epoch 64/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.2337 - accuracy: 0.9804\n",
      "Epoch 65/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.2363 - accuracy: 0.9795\n",
      "Epoch 66/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.2175 - accuracy: 0.9836\n",
      "Epoch 67/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2236 - accuracy: 0.9821\n",
      "Epoch 68/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2174 - accuracy: 0.9829\n",
      "Epoch 69/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.2095 - accuracy: 0.9843\n",
      "Epoch 70/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.2086 - accuracy: 0.9840\n",
      "Epoch 71/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.2058 - accuracy: 0.9843\n",
      "Epoch 72/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.2051 - accuracy: 0.9835\n",
      "Epoch 73/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1997 - accuracy: 0.9852\n",
      "Epoch 74/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1949 - accuracy: 0.9861\n",
      "Epoch 75/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1904 - accuracy: 0.9865\n",
      "Epoch 76/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1959 - accuracy: 0.9839\n",
      "Epoch 77/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1883 - accuracy: 0.9857\n",
      "Epoch 78/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1862 - accuracy: 0.9859\n",
      "Epoch 79/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1828 - accuracy: 0.9863\n",
      "Epoch 80/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1735 - accuracy: 0.9887\n",
      "Epoch 81/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1786 - accuracy: 0.9868\n",
      "Epoch 82/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1714 - accuracy: 0.9886\n",
      "Epoch 83/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1743 - accuracy: 0.9863\n",
      "Epoch 84/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1677 - accuracy: 0.9882\n",
      "Epoch 85/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1674 - accuracy: 0.9876\n",
      "Epoch 86/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1617 - accuracy: 0.9893\n",
      "Epoch 87/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1660 - accuracy: 0.9875\n",
      "Epoch 88/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1579 - accuracy: 0.9896\n",
      "Epoch 89/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1628 - accuracy: 0.9874\n",
      "Epoch 90/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1538 - accuracy: 0.9904\n",
      "Epoch 91/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1528 - accuracy: 0.9893\n",
      "Epoch 92/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.1527 - accuracy: 0.9898\n",
      "Epoch 93/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1531 - accuracy: 0.9880\n",
      "Epoch 94/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1438 - accuracy: 0.9914\n",
      "Epoch 95/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1527 - accuracy: 0.9890\n",
      "Epoch 96/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1452 - accuracy: 0.9899\n",
      "Epoch 97/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1456 - accuracy: 0.9895\n",
      "Epoch 98/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1412 - accuracy: 0.9909\n",
      "Epoch 99/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1433 - accuracy: 0.9894\n",
      "Epoch 100/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.1371 - accuracy: 0.9906\n",
      "Epoch 101/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1370 - accuracy: 0.9910\n",
      "Epoch 102/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1349 - accuracy: 0.9907\n",
      "Epoch 103/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1316 - accuracy: 0.9917\n",
      "Epoch 104/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1324 - accuracy: 0.9914\n",
      "Epoch 105/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.1321 - accuracy: 0.9904\n",
      "Epoch 106/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.1324 - accuracy: 0.9906\n",
      "Epoch 107/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1239 - accuracy: 0.9924\n",
      "Epoch 108/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1290 - accuracy: 0.9906\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.1253 - accuracy: 0.9916\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1285 - accuracy: 0.9906\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1248 - accuracy: 0.9910\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1182 - accuracy: 0.9927\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1172 - accuracy: 0.9933\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1221 - accuracy: 0.9913\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1217 - accuracy: 0.9908\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1119 - accuracy: 0.9935\n",
      "Epoch 117/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1209 - accuracy: 0.9909\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1136 - accuracy: 0.9925\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1149 - accuracy: 0.9915\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1067 - accuracy: 0.9942\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1147 - accuracy: 0.9915\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1149 - accuracy: 0.9913\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1067 - accuracy: 0.9935\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1032 - accuracy: 0.9944\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1044 - accuracy: 0.9936\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1048 - accuracy: 0.9937\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1031 - accuracy: 0.9936\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1025 - accuracy: 0.9936\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1051 - accuracy: 0.9930\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1046 - accuracy: 0.9927\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0988 - accuracy: 0.9940\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.1040 - accuracy: 0.9919\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.1015 - accuracy: 0.9933\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.0935 - accuracy: 0.9954\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0983 - accuracy: 0.9940\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0926 - accuracy: 0.9952\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0983 - accuracy: 0.9924\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0989 - accuracy: 0.9927\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0930 - accuracy: 0.9944\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.1012 - accuracy: 0.9919\n",
      "Epoch 141/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0847 - accuracy: 0.9961\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0977 - accuracy: 0.9929\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0917 - accuracy: 0.9941\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0919 - accuracy: 0.9937\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0870 - accuracy: 0.9953\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0868 - accuracy: 0.9949\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0860 - accuracy: 0.9952\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0944 - accuracy: 0.9924\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0872 - accuracy: 0.9942\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0890 - accuracy: 0.9940\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0842 - accuracy: 0.9950\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0824 - accuracy: 0.9951\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0845 - accuracy: 0.9949\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0881 - accuracy: 0.9933\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 0s 15us/step - loss: 0.0848 - accuracy: 0.9937\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0809 - accuracy: 0.9950\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0823 - accuracy: 0.9947\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0818 - accuracy: 0.9940\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0753 - accuracy: 0.9963\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0789 - accuracy: 0.9953\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0756 - accuracy: 0.9962\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0816 - accuracy: 0.9936\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0807 - accuracy: 0.9944\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0793 - accuracy: 0.9950\n",
      "Epoch 165/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0742 - accuracy: 0.9963\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0744 - accuracy: 0.9960\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0793 - accuracy: 0.9942\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0684 - accuracy: 0.9974\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0807 - accuracy: 0.9933\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0718 - accuracy: 0.9960\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0761 - accuracy: 0.9946\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0742 - accuracy: 0.9952\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0730 - accuracy: 0.9953\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0712 - accuracy: 0.9959\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0720 - accuracy: 0.9956\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0766 - accuracy: 0.9941\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0691 - accuracy: 0.9959\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0744 - accuracy: 0.9944\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0638 - accuracy: 0.9975\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0718 - accuracy: 0.9949\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0726 - accuracy: 0.9946\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0709 - accuracy: 0.9951\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0638 - accuracy: 0.9971\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0680 - accuracy: 0.9961\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 0s 14us/step - loss: 0.0758 - accuracy: 0.9932\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0598 - accuracy: 0.9979\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0687 - accuracy: 0.9954\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0673 - accuracy: 0.9955\n",
      "Epoch 189/200\n",
      "28000/28000 [==============================] - 0s 13us/step - loss: 0.0670 - accuracy: 0.9957\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0626 - accuracy: 0.9969\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0660 - accuracy: 0.9957\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0604 - accuracy: 0.9974\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0624 - accuracy: 0.9967\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0674 - accuracy: 0.9949\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0617 - accuracy: 0.9970\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0654 - accuracy: 0.9954\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0575 - accuracy: 0.9975\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0614 - accuracy: 0.9967\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0642 - accuracy: 0.9951\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 0s 12us/step - loss: 0.0629 - accuracy: 0.9960\n",
      "14000/14000 [==============================] - 0s 14us/step\n",
      "Epoch 1/100\n",
      "28000/28000 [==============================] - 1s 32us/step - loss: 4.0414 - accuracy: 0.2645\n",
      "Epoch 2/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.3893 - accuracy: 0.4818\n",
      "Epoch 3/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.0384 - accuracy: 0.5782\n",
      "Epoch 4/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.7687 - accuracy: 0.6318\n",
      "Epoch 5/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.5625 - accuracy: 0.6585\n",
      "Epoch 6/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.3768 - accuracy: 0.6805\n",
      "Epoch 7/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 2.1830 - accuracy: 0.7181\n",
      "Epoch 8/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.0502 - accuracy: 0.7257\n",
      "Epoch 9/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.9205 - accuracy: 0.7406\n",
      "Epoch 10/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.7871 - accuracy: 0.7581\n",
      "Epoch 11/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6855 - accuracy: 0.7657\n",
      "Epoch 12/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5886 - accuracy: 0.7797\n",
      "Epoch 13/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4901 - accuracy: 0.7911\n",
      "Epoch 14/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4259 - accuracy: 0.7935\n",
      "Epoch 15/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3412 - accuracy: 0.8082\n",
      "Epoch 16/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2921 - accuracy: 0.8127\n",
      "Epoch 17/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2183 - accuracy: 0.8231\n",
      "Epoch 18/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.1679 - accuracy: 0.8306\n",
      "Epoch 19/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.1250 - accuracy: 0.8364\n",
      "Epoch 20/100\n",
      "28000/28000 [==============================] - 0s 10us/step - loss: 1.0746 - accuracy: 0.8444\n",
      "Epoch 21/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.0397 - accuracy: 0.8474\n",
      "Epoch 22/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0069 - accuracy: 0.8518\n",
      "Epoch 23/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9746 - accuracy: 0.8600\n",
      "Epoch 24/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9296 - accuracy: 0.8693\n",
      "Epoch 25/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9066 - accuracy: 0.8717\n",
      "Epoch 26/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8935 - accuracy: 0.8706\n",
      "Epoch 27/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8564 - accuracy: 0.8813\n",
      "Epoch 28/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8202 - accuracy: 0.8894\n",
      "Epoch 29/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8127 - accuracy: 0.8879\n",
      "Epoch 30/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7954 - accuracy: 0.8909\n",
      "Epoch 31/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7592 - accuracy: 0.9016\n",
      "Epoch 32/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7608 - accuracy: 0.8947\n",
      "Epoch 33/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7330 - accuracy: 0.9041\n",
      "Epoch 34/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7108 - accuracy: 0.9084\n",
      "Epoch 35/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7062 - accuracy: 0.9078\n",
      "Epoch 36/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6874 - accuracy: 0.9118\n",
      "Epoch 37/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6755 - accuracy: 0.9125\n",
      "Epoch 38/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6578 - accuracy: 0.9184\n",
      "Epoch 39/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6438 - accuracy: 0.9202\n",
      "Epoch 40/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.6229 - accuracy: 0.9264\n",
      "Epoch 41/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6118 - accuracy: 0.9282\n",
      "Epoch 42/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6032 - accuracy: 0.9293\n",
      "Epoch 43/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5847 - accuracy: 0.9336\n",
      "Epoch 44/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5822 - accuracy: 0.9324\n",
      "Epoch 45/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5644 - accuracy: 0.9381\n",
      "Epoch 46/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5491 - accuracy: 0.9402\n",
      "Epoch 47/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5487 - accuracy: 0.9392\n",
      "Epoch 48/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5323 - accuracy: 0.9426\n",
      "Epoch 49/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5245 - accuracy: 0.9443\n",
      "Epoch 50/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5141 - accuracy: 0.9447\n",
      "Epoch 51/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5091 - accuracy: 0.9455\n",
      "Epoch 52/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4835 - accuracy: 0.9536\n",
      "Epoch 53/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4990 - accuracy: 0.9461\n",
      "Epoch 54/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4647 - accuracy: 0.9570\n",
      "Epoch 55/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4612 - accuracy: 0.9571\n",
      "Epoch 56/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4688 - accuracy: 0.9528\n",
      "Epoch 57/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4450 - accuracy: 0.9591\n",
      "Epoch 58/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4568 - accuracy: 0.9540\n",
      "Epoch 59/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4313 - accuracy: 0.9625\n",
      "Epoch 60/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4322 - accuracy: 0.9593\n",
      "Epoch 61/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4175 - accuracy: 0.9631\n",
      "Epoch 62/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4305 - accuracy: 0.9574\n",
      "Epoch 63/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4051 - accuracy: 0.9646\n",
      "Epoch 64/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4133 - accuracy: 0.9609\n",
      "Epoch 65/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3946 - accuracy: 0.9672\n",
      "Epoch 66/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3864 - accuracy: 0.9680\n",
      "Epoch 67/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3664 - accuracy: 0.9745\n",
      "Epoch 68/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3966 - accuracy: 0.9629\n",
      "Epoch 69/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3738 - accuracy: 0.9682\n",
      "Epoch 70/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3776 - accuracy: 0.9658\n",
      "Epoch 71/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3623 - accuracy: 0.9707\n",
      "Epoch 72/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3694 - accuracy: 0.9666\n",
      "Epoch 73/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3392 - accuracy: 0.9760\n",
      "Epoch 74/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3606 - accuracy: 0.9682\n",
      "Epoch 75/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3392 - accuracy: 0.9745\n",
      "Epoch 76/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3364 - accuracy: 0.9749\n",
      "Epoch 77/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3423 - accuracy: 0.9711\n",
      "Epoch 78/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3177 - accuracy: 0.9780\n",
      "Epoch 79/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3232 - accuracy: 0.9756\n",
      "Epoch 80/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3188 - accuracy: 0.9772\n",
      "Epoch 81/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3258 - accuracy: 0.9745\n",
      "Epoch 82/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3111 - accuracy: 0.9776\n",
      "Epoch 83/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3123 - accuracy: 0.9763\n",
      "Epoch 84/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2967 - accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3053 - accuracy: 0.9776\n",
      "Epoch 86/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2916 - accuracy: 0.9806\n",
      "Epoch 87/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2959 - accuracy: 0.9790\n",
      "Epoch 88/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2799 - accuracy: 0.9831\n",
      "Epoch 89/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2860 - accuracy: 0.9808\n",
      "Epoch 90/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2839 - accuracy: 0.9801\n",
      "Epoch 91/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2824 - accuracy: 0.9803\n",
      "Epoch 92/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2871 - accuracy: 0.9783\n",
      "Epoch 93/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2541 - accuracy: 0.9874\n",
      "Epoch 94/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2806 - accuracy: 0.9780\n",
      "Epoch 95/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2563 - accuracy: 0.9847\n",
      "Epoch 96/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2622 - accuracy: 0.9833\n",
      "Epoch 97/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2575 - accuracy: 0.9840\n",
      "Epoch 98/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2714 - accuracy: 0.9786\n",
      "Epoch 99/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2409 - accuracy: 0.9882\n",
      "Epoch 100/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2549 - accuracy: 0.9831\n",
      "14000/14000 [==============================] - 0s 11us/step\n",
      "Epoch 1/100\n",
      "28000/28000 [==============================] - 1s 31us/step - loss: 4.0467 - accuracy: 0.2696\n",
      "Epoch 2/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 3.3879 - accuracy: 0.4893\n",
      "Epoch 3/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 3.0483 - accuracy: 0.5723\n",
      "Epoch 4/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 2.7871 - accuracy: 0.6263\n",
      "Epoch 5/100\n",
      "28000/28000 [==============================] - 0s 10us/step - loss: 2.5731 - accuracy: 0.6598\n",
      "Epoch 6/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 2.3848 - accuracy: 0.6868\n",
      "Epoch 7/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.2245 - accuracy: 0.7013\n",
      "Epoch 8/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 2.0698 - accuracy: 0.7216\n",
      "Epoch 9/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.9183 - accuracy: 0.7448\n",
      "Epoch 10/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.8244 - accuracy: 0.7443\n",
      "Epoch 11/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.7122 - accuracy: 0.7580\n",
      "Epoch 12/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6105 - accuracy: 0.7726\n",
      "Epoch 13/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5117 - accuracy: 0.7858\n",
      "Epoch 14/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4424 - accuracy: 0.7897\n",
      "Epoch 15/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3653 - accuracy: 0.8027\n",
      "Epoch 16/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3017 - accuracy: 0.8098\n",
      "Epoch 17/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2400 - accuracy: 0.8179\n",
      "Epoch 18/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1780 - accuracy: 0.8261\n",
      "Epoch 19/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.1447 - accuracy: 0.8296\n",
      "Epoch 20/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.0877 - accuracy: 0.8414\n",
      "Epoch 21/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0534 - accuracy: 0.8434\n",
      "Epoch 22/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0133 - accuracy: 0.8497\n",
      "Epoch 23/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9792 - accuracy: 0.8566\n",
      "Epoch 24/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9436 - accuracy: 0.8623\n",
      "Epoch 25/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9337 - accuracy: 0.8594\n",
      "Epoch 26/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8777 - accuracy: 0.8774\n",
      "Epoch 27/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8815 - accuracy: 0.8669\n",
      "Epoch 28/100\n",
      "28000/28000 [==============================] - 0s 10us/step - loss: 0.8279 - accuracy: 0.8864\n",
      "Epoch 29/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8247 - accuracy: 0.8816\n",
      "Epoch 30/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.7948 - accuracy: 0.8885\n",
      "Epoch 31/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7625 - accuracy: 0.8990\n",
      "Epoch 32/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7710 - accuracy: 0.8907\n",
      "Epoch 33/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7302 - accuracy: 0.9042\n",
      "Epoch 34/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7074 - accuracy: 0.9090\n",
      "Epoch 35/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7085 - accuracy: 0.9031\n",
      "Epoch 36/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.6855 - accuracy: 0.9095\n",
      "Epoch 37/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.6777 - accuracy: 0.9102\n",
      "Epoch 38/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.6614 - accuracy: 0.9149\n",
      "Epoch 39/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.6352 - accuracy: 0.9237\n",
      "Epoch 40/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.6228 - accuracy: 0.9244\n",
      "Epoch 41/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6173 - accuracy: 0.9242\n",
      "Epoch 42/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6010 - accuracy: 0.9298\n",
      "Epoch 43/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5898 - accuracy: 0.9314\n",
      "Epoch 44/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5687 - accuracy: 0.9359\n",
      "Epoch 45/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5637 - accuracy: 0.9377\n",
      "Epoch 46/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5651 - accuracy: 0.9342\n",
      "Epoch 47/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5414 - accuracy: 0.9398\n",
      "Epoch 48/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5337 - accuracy: 0.9410\n",
      "Epoch 49/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5236 - accuracy: 0.9435\n",
      "Epoch 50/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5161 - accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5094 - accuracy: 0.9453\n",
      "Epoch 52/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4888 - accuracy: 0.9502\n",
      "Epoch 53/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4857 - accuracy: 0.9506\n",
      "Epoch 54/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4764 - accuracy: 0.9527\n",
      "Epoch 55/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4650 - accuracy: 0.9538\n",
      "Epoch 56/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4590 - accuracy: 0.9552\n",
      "Epoch 57/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4481 - accuracy: 0.9580\n",
      "Epoch 58/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4470 - accuracy: 0.9568\n",
      "Epoch 59/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4321 - accuracy: 0.9602\n",
      "Epoch 60/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4444 - accuracy: 0.9554\n",
      "Epoch 61/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4172 - accuracy: 0.9621\n",
      "Epoch 62/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4160 - accuracy: 0.9622\n",
      "Epoch 63/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4195 - accuracy: 0.9597\n",
      "Epoch 64/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4084 - accuracy: 0.9628\n",
      "Epoch 65/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3722 - accuracy: 0.9730\n",
      "Epoch 66/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4047 - accuracy: 0.9621\n",
      "Epoch 67/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3887 - accuracy: 0.9660\n",
      "Epoch 68/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3732 - accuracy: 0.9705\n",
      "Epoch 69/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3773 - accuracy: 0.9686\n",
      "Epoch 70/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3648 - accuracy: 0.9701\n",
      "Epoch 71/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3726 - accuracy: 0.9666\n",
      "Epoch 72/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3468 - accuracy: 0.9744\n",
      "Epoch 73/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3542 - accuracy: 0.9704\n",
      "Epoch 74/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3440 - accuracy: 0.9737\n",
      "Epoch 75/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3350 - accuracy: 0.9754\n",
      "Epoch 76/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3368 - accuracy: 0.9741\n",
      "Epoch 77/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3428 - accuracy: 0.9700\n",
      "Epoch 78/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3138 - accuracy: 0.9795\n",
      "Epoch 79/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3451 - accuracy: 0.9690\n",
      "Epoch 80/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3198 - accuracy: 0.9756\n",
      "Epoch 81/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3024 - accuracy: 0.9810\n",
      "Epoch 82/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3220 - accuracy: 0.9744\n",
      "Epoch 83/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3175 - accuracy: 0.9744\n",
      "Epoch 84/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2958 - accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2967 - accuracy: 0.9797\n",
      "Epoch 86/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2911 - accuracy: 0.9811\n",
      "Epoch 87/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3093 - accuracy: 0.9740\n",
      "Epoch 88/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2717 - accuracy: 0.9863\n",
      "Epoch 89/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2908 - accuracy: 0.9792\n",
      "Epoch 90/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2792 - accuracy: 0.9818\n",
      "Epoch 91/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2844 - accuracy: 0.9801\n",
      "Epoch 92/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2637 - accuracy: 0.9850\n",
      "Epoch 93/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2802 - accuracy: 0.9793\n",
      "Epoch 94/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2743 - accuracy: 0.9803\n",
      "Epoch 95/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2548 - accuracy: 0.9860\n",
      "Epoch 96/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2694 - accuracy: 0.9812\n",
      "Epoch 97/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2625 - accuracy: 0.9826\n",
      "Epoch 98/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2528 - accuracy: 0.9857\n",
      "Epoch 99/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2574 - accuracy: 0.9833\n",
      "Epoch 100/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2422 - accuracy: 0.9878\n",
      "14000/14000 [==============================] - 0s 12us/step\n",
      "Epoch 1/100\n",
      "28000/28000 [==============================] - 1s 34us/step - loss: 4.1088 - accuracy: 0.2541\n",
      "Epoch 2/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 3.4150 - accuracy: 0.4891\n",
      "Epoch 3/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 3.0529 - accuracy: 0.5824\n",
      "Epoch 4/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.7887 - accuracy: 0.6291\n",
      "Epoch 5/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.5636 - accuracy: 0.6658\n",
      "Epoch 6/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 2.3856 - accuracy: 0.6834\n",
      "Epoch 7/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.1947 - accuracy: 0.7112\n",
      "Epoch 8/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.0560 - accuracy: 0.7178\n",
      "Epoch 9/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.9207 - accuracy: 0.7377\n",
      "Epoch 10/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.7906 - accuracy: 0.7544\n",
      "Epoch 11/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6876 - accuracy: 0.7638\n",
      "Epoch 12/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5846 - accuracy: 0.7751\n",
      "Epoch 13/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.4913 - accuracy: 0.7905\n",
      "Epoch 14/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.4209 - accuracy: 0.7968\n",
      "Epoch 15/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.3603 - accuracy: 0.7962\n",
      "Epoch 16/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.2795 - accuracy: 0.8135\n",
      "Epoch 17/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.2286 - accuracy: 0.8173\n",
      "Epoch 18/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.1736 - accuracy: 0.8275\n",
      "Epoch 19/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1266 - accuracy: 0.8325\n",
      "Epoch 20/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0773 - accuracy: 0.8394\n",
      "Epoch 21/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0377 - accuracy: 0.8457\n",
      "Epoch 22/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9961 - accuracy: 0.8536\n",
      "Epoch 23/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9612 - accuracy: 0.8605\n",
      "Epoch 24/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9240 - accuracy: 0.8681\n",
      "Epoch 25/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9060 - accuracy: 0.8664\n",
      "Epoch 26/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.8789 - accuracy: 0.8713\n",
      "Epoch 27/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8333 - accuracy: 0.8852\n",
      "Epoch 28/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.8328 - accuracy: 0.8795\n",
      "Epoch 29/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8065 - accuracy: 0.8864\n",
      "Epoch 30/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7638 - accuracy: 0.8996\n",
      "Epoch 31/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.7648 - accuracy: 0.8945\n",
      "Epoch 32/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7520 - accuracy: 0.8958\n",
      "Epoch 33/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7198 - accuracy: 0.9052\n",
      "Epoch 34/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.7024 - accuracy: 0.9102\n",
      "Epoch 35/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6877 - accuracy: 0.9121\n",
      "Epoch 36/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6759 - accuracy: 0.9139\n",
      "Epoch 37/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.6534 - accuracy: 0.9199\n",
      "Epoch 38/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6542 - accuracy: 0.9172\n",
      "Epoch 39/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6381 - accuracy: 0.9214\n",
      "Epoch 40/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6164 - accuracy: 0.9275\n",
      "Epoch 41/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6061 - accuracy: 0.9298\n",
      "Epoch 42/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5965 - accuracy: 0.9313\n",
      "Epoch 43/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5872 - accuracy: 0.9325\n",
      "Epoch 44/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5692 - accuracy: 0.9375\n",
      "Epoch 45/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5688 - accuracy: 0.9355\n",
      "Epoch 46/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5530 - accuracy: 0.9380\n",
      "Epoch 47/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5459 - accuracy: 0.9386\n",
      "Epoch 48/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5204 - accuracy: 0.9474\n",
      "Epoch 49/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5248 - accuracy: 0.9441\n",
      "Epoch 50/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5044 - accuracy: 0.9496\n",
      "Epoch 51/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5054 - accuracy: 0.9484\n",
      "Epoch 52/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4876 - accuracy: 0.9522\n",
      "Epoch 53/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4904 - accuracy: 0.9502\n",
      "Epoch 54/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4746 - accuracy: 0.9534\n",
      "Epoch 55/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4623 - accuracy: 0.9571\n",
      "Epoch 56/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4596 - accuracy: 0.9569\n",
      "Epoch 57/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4611 - accuracy: 0.9533\n",
      "Epoch 58/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4360 - accuracy: 0.9614\n",
      "Epoch 59/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4415 - accuracy: 0.9592\n",
      "Epoch 60/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4276 - accuracy: 0.9613\n",
      "Epoch 61/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4173 - accuracy: 0.9638\n",
      "Epoch 62/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4181 - accuracy: 0.9616\n",
      "Epoch 63/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4134 - accuracy: 0.9621\n",
      "Epoch 64/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3961 - accuracy: 0.9671\n",
      "Epoch 65/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3952 - accuracy: 0.9658\n",
      "Epoch 66/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4022 - accuracy: 0.9633\n",
      "Epoch 67/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3907 - accuracy: 0.9656\n",
      "Epoch 68/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3644 - accuracy: 0.9732\n",
      "Epoch 69/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3686 - accuracy: 0.9712\n",
      "Epoch 70/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3790 - accuracy: 0.9660\n",
      "Epoch 71/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3640 - accuracy: 0.9699\n",
      "Epoch 72/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3456 - accuracy: 0.9752\n",
      "Epoch 73/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3722 - accuracy: 0.9659\n",
      "Epoch 74/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3336 - accuracy: 0.9776\n",
      "Epoch 75/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3507 - accuracy: 0.9707\n",
      "Epoch 76/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3331 - accuracy: 0.9759\n",
      "Epoch 77/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3413 - accuracy: 0.9731\n",
      "Epoch 78/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3152 - accuracy: 0.9796\n",
      "Epoch 79/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3387 - accuracy: 0.9722\n",
      "Epoch 80/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3121 - accuracy: 0.9793\n",
      "Epoch 81/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3272 - accuracy: 0.9734\n",
      "Epoch 82/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3017 - accuracy: 0.9806\n",
      "Epoch 83/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3147 - accuracy: 0.9755\n",
      "Epoch 84/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2986 - accuracy: 0.9814\n",
      "Epoch 85/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3039 - accuracy: 0.9775\n",
      "Epoch 86/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2759 - accuracy: 0.9861\n",
      "Epoch 87/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3168 - accuracy: 0.9710\n",
      "Epoch 88/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2822 - accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2807 - accuracy: 0.9823\n",
      "Epoch 90/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2909 - accuracy: 0.9785\n",
      "Epoch 91/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2669 - accuracy: 0.9857\n",
      "Epoch 92/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2799 - accuracy: 0.9802\n",
      "Epoch 93/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2767 - accuracy: 0.9816\n",
      "Epoch 94/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2640 - accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2707 - accuracy: 0.9817\n",
      "Epoch 96/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2501 - accuracy: 0.9871\n",
      "Epoch 97/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2602 - accuracy: 0.9843\n",
      "Epoch 98/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2710 - accuracy: 0.9795\n",
      "Epoch 99/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2318 - accuracy: 0.9906\n",
      "Epoch 100/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2471 - accuracy: 0.9854\n",
      "14000/14000 [==============================] - 0s 11us/step\n",
      "Epoch 1/100\n",
      "28000/28000 [==============================] - 1s 31us/step - loss: 4.1066 - accuracy: 0.2475\n",
      "Epoch 2/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 3.4128 - accuracy: 0.4735\n",
      "Epoch 3/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.0543 - accuracy: 0.5705\n",
      "Epoch 4/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.7943 - accuracy: 0.6217\n",
      "Epoch 5/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 2.5681 - accuracy: 0.6575\n",
      "Epoch 6/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.3820 - accuracy: 0.6809\n",
      "Epoch 7/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.2186 - accuracy: 0.6977\n",
      "Epoch 8/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.0498 - accuracy: 0.7250\n",
      "Epoch 9/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.9418 - accuracy: 0.7250\n",
      "Epoch 10/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.8032 - accuracy: 0.7462\n",
      "Epoch 11/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6712 - accuracy: 0.7698\n",
      "Epoch 12/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5927 - accuracy: 0.7660\n",
      "Epoch 13/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4911 - accuracy: 0.7838\n",
      "Epoch 14/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.4102 - accuracy: 0.7919\n",
      "Epoch 15/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3260 - accuracy: 0.8061\n",
      "Epoch 16/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.2653 - accuracy: 0.8106\n",
      "Epoch 17/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.2132 - accuracy: 0.8124\n",
      "Epoch 18/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1572 - accuracy: 0.8220\n",
      "Epoch 19/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1051 - accuracy: 0.8308\n",
      "Epoch 20/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0587 - accuracy: 0.8393\n",
      "Epoch 21/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0389 - accuracy: 0.8357\n",
      "Epoch 22/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9825 - accuracy: 0.8503\n",
      "Epoch 23/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9552 - accuracy: 0.8560\n",
      "Epoch 24/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9251 - accuracy: 0.8594\n",
      "Epoch 25/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8965 - accuracy: 0.8659\n",
      "Epoch 26/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8705 - accuracy: 0.8709\n",
      "Epoch 27/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8420 - accuracy: 0.8784\n",
      "Epoch 28/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8331 - accuracy: 0.8771\n",
      "Epoch 29/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7955 - accuracy: 0.8891\n",
      "Epoch 30/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7769 - accuracy: 0.8931\n",
      "Epoch 31/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7664 - accuracy: 0.8933\n",
      "Epoch 32/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.7496 - accuracy: 0.8957\n",
      "Epoch 33/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7369 - accuracy: 0.8985\n",
      "Epoch 34/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7103 - accuracy: 0.9054\n",
      "Epoch 35/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7011 - accuracy: 0.9073\n",
      "Epoch 36/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6850 - accuracy: 0.9110\n",
      "Epoch 37/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6742 - accuracy: 0.9112\n",
      "Epoch 38/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6391 - accuracy: 0.9245\n",
      "Epoch 39/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6407 - accuracy: 0.9218\n",
      "Epoch 40/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6266 - accuracy: 0.9244\n",
      "Epoch 41/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6092 - accuracy: 0.9283\n",
      "Epoch 42/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5911 - accuracy: 0.9321\n",
      "Epoch 43/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5971 - accuracy: 0.9275\n",
      "Epoch 44/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5727 - accuracy: 0.9338\n",
      "Epoch 45/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5651 - accuracy: 0.9354\n",
      "Epoch 46/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5577 - accuracy: 0.9374\n",
      "Epoch 47/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5589 - accuracy: 0.9347\n",
      "Epoch 48/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5269 - accuracy: 0.9449\n",
      "Epoch 49/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5188 - accuracy: 0.9454\n",
      "Epoch 50/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5242 - accuracy: 0.9420\n",
      "Epoch 51/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4818 - accuracy: 0.9553\n",
      "Epoch 52/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5138 - accuracy: 0.9423\n",
      "Epoch 53/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4864 - accuracy: 0.9517\n",
      "Epoch 54/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4763 - accuracy: 0.9529\n",
      "Epoch 55/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4639 - accuracy: 0.9553\n",
      "Epoch 56/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4771 - accuracy: 0.9474\n",
      "Epoch 57/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4326 - accuracy: 0.9638\n",
      "Epoch 58/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4539 - accuracy: 0.9553\n",
      "Epoch 59/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4429 - accuracy: 0.9573\n",
      "Epoch 60/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4231 - accuracy: 0.9622\n",
      "Epoch 61/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4274 - accuracy: 0.9596\n",
      "Epoch 62/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4270 - accuracy: 0.9574\n",
      "Epoch 63/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4037 - accuracy: 0.9644\n",
      "Epoch 64/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4152 - accuracy: 0.9589\n",
      "Epoch 65/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3989 - accuracy: 0.9635\n",
      "Epoch 66/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3821 - accuracy: 0.9682\n",
      "Epoch 67/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3868 - accuracy: 0.9660\n",
      "Epoch 68/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3785 - accuracy: 0.9682\n",
      "Epoch 69/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3835 - accuracy: 0.9651\n",
      "Epoch 70/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3603 - accuracy: 0.9718\n",
      "Epoch 71/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3771 - accuracy: 0.9659\n",
      "Epoch 72/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3484 - accuracy: 0.9736\n",
      "Epoch 73/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3529 - accuracy: 0.9710\n",
      "Epoch 74/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3513 - accuracy: 0.9716\n",
      "Epoch 75/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3447 - accuracy: 0.9717\n",
      "Epoch 76/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3407 - accuracy: 0.9725\n",
      "Epoch 77/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3395 - accuracy: 0.9715\n",
      "Epoch 78/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3170 - accuracy: 0.9788\n",
      "Epoch 79/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3293 - accuracy: 0.9739\n",
      "Epoch 80/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3326 - accuracy: 0.9718\n",
      "Epoch 81/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3063 - accuracy: 0.9787\n",
      "Epoch 82/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3104 - accuracy: 0.9772\n",
      "Epoch 83/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3210 - accuracy: 0.9734\n",
      "Epoch 84/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2886 - accuracy: 0.9825\n",
      "Epoch 85/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3162 - accuracy: 0.9734\n",
      "Epoch 86/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3133 - accuracy: 0.9714\n",
      "Epoch 87/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2722 - accuracy: 0.9859\n",
      "Epoch 88/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2876 - accuracy: 0.9803\n",
      "Epoch 89/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2896 - accuracy: 0.9785\n",
      "Epoch 90/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2885 - accuracy: 0.9785\n",
      "Epoch 91/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2791 - accuracy: 0.9811\n",
      "Epoch 92/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2704 - accuracy: 0.9827\n",
      "Epoch 93/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2808 - accuracy: 0.9790\n",
      "Epoch 94/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2732 - accuracy: 0.9796\n",
      "Epoch 95/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2641 - accuracy: 0.9831\n",
      "Epoch 96/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2832 - accuracy: 0.9766\n",
      "Epoch 97/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2308 - accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2654 - accuracy: 0.9807\n",
      "Epoch 99/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2629 - accuracy: 0.9811\n",
      "Epoch 100/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2559 - accuracy: 0.9819\n",
      "14000/14000 [==============================] - 0s 13us/step\n",
      "Epoch 1/100\n",
      "28000/28000 [==============================] - 1s 30us/step - loss: 4.2436 - accuracy: 0.2316\n",
      "Epoch 2/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.5058 - accuracy: 0.4666\n",
      "Epoch 3/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.0962 - accuracy: 0.5794\n",
      "Epoch 4/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.8130 - accuracy: 0.6317\n",
      "Epoch 5/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.5830 - accuracy: 0.6672\n",
      "Epoch 6/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.3740 - accuracy: 0.6956\n",
      "Epoch 7/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 2.1943 - accuracy: 0.7164\n",
      "Epoch 8/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.0434 - accuracy: 0.7277\n",
      "Epoch 9/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.9035 - accuracy: 0.7429\n",
      "Epoch 10/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.7762 - accuracy: 0.7575\n",
      "Epoch 11/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6827 - accuracy: 0.7619\n",
      "Epoch 12/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5612 - accuracy: 0.7823\n",
      "Epoch 13/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4853 - accuracy: 0.7856\n",
      "Epoch 14/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3982 - accuracy: 0.7963\n",
      "Epoch 15/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3338 - accuracy: 0.8018\n",
      "Epoch 16/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.2555 - accuracy: 0.8161\n",
      "Epoch 17/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2120 - accuracy: 0.8159\n",
      "Epoch 18/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1448 - accuracy: 0.8302\n",
      "Epoch 19/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0975 - accuracy: 0.8348\n",
      "Epoch 20/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0668 - accuracy: 0.8362\n",
      "Epoch 21/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0146 - accuracy: 0.8482\n",
      "Epoch 22/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9982 - accuracy: 0.8479\n",
      "Epoch 23/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9428 - accuracy: 0.8646\n",
      "Epoch 24/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9221 - accuracy: 0.8648\n",
      "Epoch 25/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8928 - accuracy: 0.8705\n",
      "Epoch 26/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8700 - accuracy: 0.8735\n",
      "Epoch 27/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8346 - accuracy: 0.8846\n",
      "Epoch 28/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8180 - accuracy: 0.8868\n",
      "Epoch 29/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7992 - accuracy: 0.8907\n",
      "Epoch 30/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7876 - accuracy: 0.8900\n",
      "Epoch 31/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7511 - accuracy: 0.9022\n",
      "Epoch 32/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7492 - accuracy: 0.8986\n",
      "Epoch 33/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7147 - accuracy: 0.9106\n",
      "Epoch 34/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7140 - accuracy: 0.9071\n",
      "Epoch 35/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6913 - accuracy: 0.9112\n",
      "Epoch 36/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6882 - accuracy: 0.9115\n",
      "Epoch 37/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6566 - accuracy: 0.9202\n",
      "Epoch 38/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6501 - accuracy: 0.9195\n",
      "Epoch 39/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6342 - accuracy: 0.9250\n",
      "Epoch 40/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6289 - accuracy: 0.9242\n",
      "Epoch 41/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6089 - accuracy: 0.9300\n",
      "Epoch 42/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5942 - accuracy: 0.9323\n",
      "Epoch 43/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.5827 - accuracy: 0.9347\n",
      "Epoch 44/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5712 - accuracy: 0.9365\n",
      "Epoch 45/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5625 - accuracy: 0.9371\n",
      "Epoch 46/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5416 - accuracy: 0.9439\n",
      "Epoch 47/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5396 - accuracy: 0.9433\n",
      "Epoch 48/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5278 - accuracy: 0.9455\n",
      "Epoch 49/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5222 - accuracy: 0.9448\n",
      "Epoch 50/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5039 - accuracy: 0.9498\n",
      "Epoch 51/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4925 - accuracy: 0.9529\n",
      "Epoch 52/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4913 - accuracy: 0.9510\n",
      "Epoch 53/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4693 - accuracy: 0.9583\n",
      "Epoch 54/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4844 - accuracy: 0.9496\n",
      "Epoch 55/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4663 - accuracy: 0.9547\n",
      "Epoch 56/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4549 - accuracy: 0.9581\n",
      "Epoch 57/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4392 - accuracy: 0.9621\n",
      "Epoch 58/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4429 - accuracy: 0.9580\n",
      "Epoch 59/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4269 - accuracy: 0.9632\n",
      "Epoch 60/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4307 - accuracy: 0.9618\n",
      "Epoch 61/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4214 - accuracy: 0.9627\n",
      "Epoch 62/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4076 - accuracy: 0.9655\n",
      "Epoch 63/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4095 - accuracy: 0.9640\n",
      "Epoch 64/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4052 - accuracy: 0.9647\n",
      "Epoch 65/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3903 - accuracy: 0.9678\n",
      "Epoch 66/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3861 - accuracy: 0.9689\n",
      "Epoch 67/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3913 - accuracy: 0.9656\n",
      "Epoch 68/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3722 - accuracy: 0.9711\n",
      "Epoch 69/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3691 - accuracy: 0.9713\n",
      "Epoch 70/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3631 - accuracy: 0.9722\n",
      "Epoch 71/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3685 - accuracy: 0.9688\n",
      "Epoch 72/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3496 - accuracy: 0.9745\n",
      "Epoch 73/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3503 - accuracy: 0.9736\n",
      "Epoch 74/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3388 - accuracy: 0.9759\n",
      "Epoch 75/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3466 - accuracy: 0.9728\n",
      "Epoch 76/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3359 - accuracy: 0.9740\n",
      "Epoch 77/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3150 - accuracy: 0.9805\n",
      "Epoch 78/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3386 - accuracy: 0.9721\n",
      "Epoch 79/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3211 - accuracy: 0.9774\n",
      "Epoch 80/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3310 - accuracy: 0.9729\n",
      "Epoch 81/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3131 - accuracy: 0.9772\n",
      "Epoch 82/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2928 - accuracy: 0.9837\n",
      "Epoch 83/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3228 - accuracy: 0.9735\n",
      "Epoch 84/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2894 - accuracy: 0.9828\n",
      "Epoch 85/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2913 - accuracy: 0.9819\n",
      "Epoch 86/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3070 - accuracy: 0.9766\n",
      "Epoch 87/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2734 - accuracy: 0.9862\n",
      "Epoch 88/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2916 - accuracy: 0.9805\n",
      "Epoch 89/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2811 - accuracy: 0.9812\n",
      "Epoch 90/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2805 - accuracy: 0.9821\n",
      "Epoch 91/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2788 - accuracy: 0.9824\n",
      "Epoch 92/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2695 - accuracy: 0.9829\n",
      "Epoch 93/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2668 - accuracy: 0.9850\n",
      "Epoch 94/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2691 - accuracy: 0.9829\n",
      "Epoch 95/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2520 - accuracy: 0.9873\n",
      "Epoch 96/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2656 - accuracy: 0.9834\n",
      "Epoch 97/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2680 - accuracy: 0.9811\n",
      "Epoch 98/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2535 - accuracy: 0.9849\n",
      "Epoch 99/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2407 - accuracy: 0.9888\n",
      "Epoch 100/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2406 - accuracy: 0.9885\n",
      "14000/14000 [==============================] - 0s 11us/step\n",
      "Epoch 1/100\n",
      "28000/28000 [==============================] - 1s 35us/step - loss: 4.0231 - accuracy: 0.2315\n",
      "Epoch 2/100\n",
      "28000/28000 [==============================] - 0s 10us/step - loss: 3.3891 - accuracy: 0.4413\n",
      "Epoch 3/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.0448 - accuracy: 0.5478\n",
      "Epoch 4/100\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 2.7698 - accuracy: 0.6058\n",
      "Epoch 5/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.5362 - accuracy: 0.6481\n",
      "Epoch 6/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.3352 - accuracy: 0.6746\n",
      "Epoch 7/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.1628 - accuracy: 0.6950\n",
      "Epoch 8/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.9963 - accuracy: 0.7151\n",
      "Epoch 9/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.8593 - accuracy: 0.7319\n",
      "Epoch 10/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.7467 - accuracy: 0.7418\n",
      "Epoch 11/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6308 - accuracy: 0.7575\n",
      "Epoch 12/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5339 - accuracy: 0.7675\n",
      "Epoch 13/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4431 - accuracy: 0.7828\n",
      "Epoch 14/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3754 - accuracy: 0.7847\n",
      "Epoch 15/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2995 - accuracy: 0.7981\n",
      "Epoch 16/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2411 - accuracy: 0.8080\n",
      "Epoch 17/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1907 - accuracy: 0.8119\n",
      "Epoch 18/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1451 - accuracy: 0.8174\n",
      "Epoch 19/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0925 - accuracy: 0.8294\n",
      "Epoch 20/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0632 - accuracy: 0.8325\n",
      "Epoch 21/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0243 - accuracy: 0.8391\n",
      "Epoch 22/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9796 - accuracy: 0.8500\n",
      "Epoch 23/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9661 - accuracy: 0.8496\n",
      "Epoch 24/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9263 - accuracy: 0.8595\n",
      "Epoch 25/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.9123 - accuracy: 0.8596\n",
      "Epoch 26/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8787 - accuracy: 0.8696\n",
      "Epoch 27/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8611 - accuracy: 0.8724\n",
      "Epoch 28/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8358 - accuracy: 0.8778\n",
      "Epoch 29/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8196 - accuracy: 0.8803\n",
      "Epoch 30/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7929 - accuracy: 0.8877\n",
      "Epoch 31/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7777 - accuracy: 0.8905\n",
      "Epoch 32/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7546 - accuracy: 0.8964\n",
      "Epoch 33/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7415 - accuracy: 0.8981\n",
      "Epoch 34/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7251 - accuracy: 0.9017\n",
      "Epoch 35/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7068 - accuracy: 0.9076\n",
      "Epoch 36/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6935 - accuracy: 0.9100\n",
      "Epoch 37/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6708 - accuracy: 0.9154\n",
      "Epoch 38/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6622 - accuracy: 0.9147\n",
      "Epoch 39/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6498 - accuracy: 0.9183\n",
      "Epoch 40/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6389 - accuracy: 0.9193\n",
      "Epoch 41/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6165 - accuracy: 0.9247\n",
      "Epoch 42/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6131 - accuracy: 0.9252\n",
      "Epoch 43/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5969 - accuracy: 0.9286\n",
      "Epoch 44/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5865 - accuracy: 0.9294\n",
      "Epoch 45/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5767 - accuracy: 0.9318\n",
      "Epoch 46/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5467 - accuracy: 0.9409\n",
      "Epoch 47/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5588 - accuracy: 0.9336\n",
      "Epoch 48/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5358 - accuracy: 0.9405\n",
      "Epoch 49/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5246 - accuracy: 0.9431\n",
      "Epoch 50/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5241 - accuracy: 0.9404\n",
      "Epoch 51/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5138 - accuracy: 0.9448\n",
      "Epoch 52/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4988 - accuracy: 0.9464\n",
      "Epoch 53/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4928 - accuracy: 0.9471\n",
      "Epoch 54/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4766 - accuracy: 0.9520\n",
      "Epoch 55/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4707 - accuracy: 0.9529\n",
      "Epoch 56/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4725 - accuracy: 0.9496\n",
      "Epoch 57/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4561 - accuracy: 0.9552\n",
      "Epoch 58/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4435 - accuracy: 0.9582\n",
      "Epoch 59/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4455 - accuracy: 0.9566\n",
      "Epoch 60/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4310 - accuracy: 0.9581\n",
      "Epoch 61/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4335 - accuracy: 0.9560\n",
      "Epoch 62/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4076 - accuracy: 0.9643\n",
      "Epoch 63/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4248 - accuracy: 0.9564\n",
      "Epoch 64/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4029 - accuracy: 0.9638\n",
      "Epoch 65/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3997 - accuracy: 0.9649\n",
      "Epoch 66/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4000 - accuracy: 0.9620\n",
      "Epoch 67/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3855 - accuracy: 0.9668\n",
      "Epoch 68/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3875 - accuracy: 0.9648\n",
      "Epoch 69/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3695 - accuracy: 0.9697\n",
      "Epoch 70/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3670 - accuracy: 0.9702\n",
      "Epoch 71/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3799 - accuracy: 0.9647\n",
      "Epoch 72/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3576 - accuracy: 0.9711\n",
      "Epoch 73/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3482 - accuracy: 0.9721\n",
      "Epoch 74/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3450 - accuracy: 0.9743\n",
      "Epoch 75/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3448 - accuracy: 0.9724\n",
      "Epoch 76/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3418 - accuracy: 0.9719\n",
      "Epoch 77/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3269 - accuracy: 0.9754\n",
      "Epoch 78/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3486 - accuracy: 0.9686\n",
      "Epoch 79/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3260 - accuracy: 0.9747\n",
      "Epoch 80/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3208 - accuracy: 0.9757\n",
      "Epoch 81/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3170 - accuracy: 0.9758\n",
      "Epoch 82/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3002 - accuracy: 0.9805\n",
      "Epoch 83/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3162 - accuracy: 0.9737\n",
      "Epoch 84/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2952 - accuracy: 0.9804\n",
      "Epoch 85/100\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3104 - accuracy: 0.9756\n",
      "Epoch 86/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2925 - accuracy: 0.9799\n",
      "Epoch 87/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3055 - accuracy: 0.9747\n",
      "Epoch 88/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2885 - accuracy: 0.9789\n",
      "Epoch 89/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2656 - accuracy: 0.9859\n",
      "Epoch 90/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2950 - accuracy: 0.9755\n",
      "Epoch 91/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2839 - accuracy: 0.9784\n",
      "Epoch 92/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2561 - accuracy: 0.9875\n",
      "Epoch 93/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2877 - accuracy: 0.9772\n",
      "Epoch 94/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2676 - accuracy: 0.9818\n",
      "Epoch 95/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2534 - accuracy: 0.9859\n",
      "Epoch 96/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2865 - accuracy: 0.9743\n",
      "Epoch 97/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2381 - accuracy: 0.9893\n",
      "Epoch 98/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2637 - accuracy: 0.9810\n",
      "Epoch 99/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2456 - accuracy: 0.9859\n",
      "Epoch 100/100\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2759 - accuracy: 0.9756\n",
      "14000/14000 [==============================] - 0s 12us/step\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 1s 35us/step - loss: 4.0325 - accuracy: 0.2556\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.3464 - accuracy: 0.4672\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.9919 - accuracy: 0.5663\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.7097 - accuracy: 0.6336\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.4945 - accuracy: 0.6641\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.3241 - accuracy: 0.6814\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.1417 - accuracy: 0.7100\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.0101 - accuracy: 0.7208\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.8753 - accuracy: 0.7376\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.7685 - accuracy: 0.7450\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6533 - accuracy: 0.7637\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5472 - accuracy: 0.7794\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4731 - accuracy: 0.7817\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4104 - accuracy: 0.7863\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3194 - accuracy: 0.8049\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.2665 - accuracy: 0.8076\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2041 - accuracy: 0.8217\n",
      "Epoch 18/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1649 - accuracy: 0.8244\n",
      "Epoch 19/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.1206 - accuracy: 0.8305\n",
      "Epoch 20/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.0598 - accuracy: 0.8421\n",
      "Epoch 21/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0308 - accuracy: 0.8458\n",
      "Epoch 22/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0066 - accuracy: 0.8453\n",
      "Epoch 23/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9531 - accuracy: 0.8625\n",
      "Epoch 24/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9287 - accuracy: 0.8622\n",
      "Epoch 25/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9143 - accuracy: 0.8650\n",
      "Epoch 26/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8737 - accuracy: 0.8725\n",
      "Epoch 27/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8478 - accuracy: 0.8795\n",
      "Epoch 28/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8283 - accuracy: 0.8813\n",
      "Epoch 29/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8120 - accuracy: 0.8832\n",
      "Epoch 30/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7811 - accuracy: 0.8907\n",
      "Epoch 31/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.7587 - accuracy: 0.8979\n",
      "Epoch 32/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7499 - accuracy: 0.8964\n",
      "Epoch 33/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7262 - accuracy: 0.9030\n",
      "Epoch 34/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7157 - accuracy: 0.9032\n",
      "Epoch 35/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6935 - accuracy: 0.9078\n",
      "Epoch 36/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6736 - accuracy: 0.9151\n",
      "Epoch 37/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6681 - accuracy: 0.9134\n",
      "Epoch 38/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6566 - accuracy: 0.9171\n",
      "Epoch 39/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6309 - accuracy: 0.9223\n",
      "Epoch 40/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6300 - accuracy: 0.9209\n",
      "Epoch 41/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6205 - accuracy: 0.9220\n",
      "Epoch 42/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5948 - accuracy: 0.9304\n",
      "Epoch 43/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5835 - accuracy: 0.9324\n",
      "Epoch 44/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5728 - accuracy: 0.9358\n",
      "Epoch 45/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5766 - accuracy: 0.9310\n",
      "Epoch 46/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5487 - accuracy: 0.9391\n",
      "Epoch 47/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5413 - accuracy: 0.9404\n",
      "Epoch 48/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5399 - accuracy: 0.9383\n",
      "Epoch 49/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5230 - accuracy: 0.9447\n",
      "Epoch 50/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5043 - accuracy: 0.9476\n",
      "Epoch 51/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5092 - accuracy: 0.9449\n",
      "Epoch 52/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4978 - accuracy: 0.9473\n",
      "Epoch 53/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4949 - accuracy: 0.9456\n",
      "Epoch 54/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4849 - accuracy: 0.9489\n",
      "Epoch 55/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4690 - accuracy: 0.9534\n",
      "Epoch 56/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4733 - accuracy: 0.9487\n",
      "Epoch 57/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4530 - accuracy: 0.9546\n",
      "Epoch 58/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4552 - accuracy: 0.9538\n",
      "Epoch 59/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4359 - accuracy: 0.9600\n",
      "Epoch 60/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4246 - accuracy: 0.9617\n",
      "Epoch 61/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4349 - accuracy: 0.9565\n",
      "Epoch 62/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4224 - accuracy: 0.9590\n",
      "Epoch 63/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4001 - accuracy: 0.9651\n",
      "Epoch 64/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4015 - accuracy: 0.9636\n",
      "Epoch 65/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4025 - accuracy: 0.9637\n",
      "Epoch 66/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4027 - accuracy: 0.9611\n",
      "Epoch 67/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3894 - accuracy: 0.9653\n",
      "Epoch 68/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3883 - accuracy: 0.9645\n",
      "Epoch 69/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3611 - accuracy: 0.9732\n",
      "Epoch 70/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3795 - accuracy: 0.9643\n",
      "Epoch 71/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3707 - accuracy: 0.9679\n",
      "Epoch 72/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3612 - accuracy: 0.9690\n",
      "Epoch 73/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3453 - accuracy: 0.9725\n",
      "Epoch 74/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3578 - accuracy: 0.9686\n",
      "Epoch 75/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3323 - accuracy: 0.9757\n",
      "Epoch 76/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3377 - accuracy: 0.9734\n",
      "Epoch 77/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3327 - accuracy: 0.9748\n",
      "Epoch 78/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3208 - accuracy: 0.9772\n",
      "Epoch 79/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3529 - accuracy: 0.9653\n",
      "Epoch 80/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3049 - accuracy: 0.9802\n",
      "Epoch 81/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3140 - accuracy: 0.9768\n",
      "Epoch 82/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3189 - accuracy: 0.9745\n",
      "Epoch 83/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3053 - accuracy: 0.9775\n",
      "Epoch 84/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3198 - accuracy: 0.9730\n",
      "Epoch 85/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2890 - accuracy: 0.9818\n",
      "Epoch 86/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3125 - accuracy: 0.9725\n",
      "Epoch 87/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2717 - accuracy: 0.9854\n",
      "Epoch 88/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3041 - accuracy: 0.9743\n",
      "Epoch 89/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2753 - accuracy: 0.9831\n",
      "Epoch 90/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2967 - accuracy: 0.9757\n",
      "Epoch 91/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2733 - accuracy: 0.9831\n",
      "Epoch 92/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2797 - accuracy: 0.9804\n",
      "Epoch 93/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2834 - accuracy: 0.9779\n",
      "Epoch 94/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2572 - accuracy: 0.9851\n",
      "Epoch 95/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2776 - accuracy: 0.9779\n",
      "Epoch 96/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2616 - accuracy: 0.9830\n",
      "Epoch 97/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2671 - accuracy: 0.9808\n",
      "Epoch 98/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2473 - accuracy: 0.9866\n",
      "Epoch 99/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2623 - accuracy: 0.9815\n",
      "Epoch 100/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2542 - accuracy: 0.9829\n",
      "Epoch 101/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2658 - accuracy: 0.9782\n",
      "Epoch 102/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2161 - accuracy: 0.9935\n",
      "Epoch 103/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2770 - accuracy: 0.9744\n",
      "Epoch 104/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2300 - accuracy: 0.9871\n",
      "Epoch 105/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2367 - accuracy: 0.9854\n",
      "Epoch 106/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2483 - accuracy: 0.9815\n",
      "Epoch 107/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2227 - accuracy: 0.9892\n",
      "Epoch 108/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2510 - accuracy: 0.9787\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1966 - accuracy: 0.9957\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2627 - accuracy: 0.9750\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2019 - accuracy: 0.9926\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2364 - accuracy: 0.9831\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2335 - accuracy: 0.9818\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1996 - accuracy: 0.9927\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2369 - accuracy: 0.9804\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2039 - accuracy: 0.9900\n",
      "Epoch 117/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2174 - accuracy: 0.9862\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2102 - accuracy: 0.9873\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1997 - accuracy: 0.9912\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2230 - accuracy: 0.9836\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2067 - accuracy: 0.9860\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1925 - accuracy: 0.9917\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2107 - accuracy: 0.9858\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2033 - accuracy: 0.9865\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1863 - accuracy: 0.9920\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2101 - accuracy: 0.9847\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1890 - accuracy: 0.9906\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2161 - accuracy: 0.9820\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1665 - accuracy: 0.9960\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2043 - accuracy: 0.9850\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1787 - accuracy: 0.9922\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1919 - accuracy: 0.9885\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1813 - accuracy: 0.9912\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1897 - accuracy: 0.9884\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1810 - accuracy: 0.9896\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1725 - accuracy: 0.9929\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1938 - accuracy: 0.9860\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1624 - accuracy: 0.9945\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1858 - accuracy: 0.9871\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1756 - accuracy: 0.9906\n",
      "Epoch 141/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1691 - accuracy: 0.9919\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1942 - accuracy: 0.9836\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1444 - accuracy: 0.9984\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1991 - accuracy: 0.9815\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1473 - accuracy: 0.9969\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1891 - accuracy: 0.9834\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1474 - accuracy: 0.9965\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1872 - accuracy: 0.9839\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1468 - accuracy: 0.9962\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1907 - accuracy: 0.9820\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1348 - accuracy: 0.9985\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1918 - accuracy: 0.9823\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1329 - accuracy: 0.9986\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1767 - accuracy: 0.9850\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1336 - accuracy: 0.9980\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1855 - accuracy: 0.9828\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1317 - accuracy: 0.9979\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1829 - accuracy: 0.9836\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1551 - accuracy: 0.9899\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1439 - accuracy: 0.9939\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1656 - accuracy: 0.9868\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1405 - accuracy: 0.9949\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1521 - accuracy: 0.9899\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1519 - accuracy: 0.9909\n",
      "Epoch 165/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1491 - accuracy: 0.9909\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1610 - accuracy: 0.9882\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1286 - accuracy: 0.9967\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1574 - accuracy: 0.9887\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1248 - accuracy: 0.9973\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1551 - accuracy: 0.9887\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1548 - accuracy: 0.9882\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1359 - accuracy: 0.9933\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1440 - accuracy: 0.9911\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1540 - accuracy: 0.9877\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1312 - accuracy: 0.9946\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1354 - accuracy: 0.9935\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1615 - accuracy: 0.9847\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1162 - accuracy: 0.9988\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1625 - accuracy: 0.9850\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1122 - accuracy: 0.9989\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1453 - accuracy: 0.9892\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1210 - accuracy: 0.9965\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1436 - accuracy: 0.9896\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1134 - accuracy: 0.9981\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1646 - accuracy: 0.9828\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1109 - accuracy: 0.9985\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1391 - accuracy: 0.9900\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1116 - accuracy: 0.9975\n",
      "Epoch 189/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1411 - accuracy: 0.9888\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1041 - accuracy: 0.9991\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1638 - accuracy: 0.9816\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1148 - accuracy: 0.9954\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1221 - accuracy: 0.9943\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1514 - accuracy: 0.9852\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1091 - accuracy: 0.9972\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1387 - accuracy: 0.9884\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1087 - accuracy: 0.9976\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1399 - accuracy: 0.9877\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1055 - accuracy: 0.9977\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1422 - accuracy: 0.9866\n",
      "14000/14000 [==============================] - 0s 12us/step\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 1s 30us/step - loss: 4.1300 - accuracy: 0.2541\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.4518 - accuracy: 0.4828\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.0978 - accuracy: 0.5765\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 2.8264 - accuracy: 0.6280\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.5961 - accuracy: 0.6649\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 2.4151 - accuracy: 0.6823\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.2295 - accuracy: 0.7067\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.0860 - accuracy: 0.7185\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.9437 - accuracy: 0.7395\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.8126 - accuracy: 0.7560\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.7122 - accuracy: 0.7628\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6190 - accuracy: 0.7710\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5225 - accuracy: 0.7839\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4454 - accuracy: 0.7909\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3606 - accuracy: 0.8060\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3125 - accuracy: 0.8038\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.2456 - accuracy: 0.8152\n",
      "Epoch 18/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1946 - accuracy: 0.8237\n",
      "Epoch 19/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1464 - accuracy: 0.8279\n",
      "Epoch 20/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0939 - accuracy: 0.8382\n",
      "Epoch 21/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0557 - accuracy: 0.8419\n",
      "Epoch 22/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.0166 - accuracy: 0.8492\n",
      "Epoch 23/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9782 - accuracy: 0.8554\n",
      "Epoch 24/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9414 - accuracy: 0.8643\n",
      "Epoch 25/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9112 - accuracy: 0.8703\n",
      "Epoch 26/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.9036 - accuracy: 0.8633\n",
      "Epoch 27/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8607 - accuracy: 0.8749\n",
      "Epoch 28/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8355 - accuracy: 0.8809\n",
      "Epoch 29/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8142 - accuracy: 0.8834\n",
      "Epoch 30/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7946 - accuracy: 0.8888\n",
      "Epoch 31/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.7743 - accuracy: 0.8932\n",
      "Epoch 32/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.7594 - accuracy: 0.8946\n",
      "Epoch 33/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.7215 - accuracy: 0.9059\n",
      "Epoch 34/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7218 - accuracy: 0.9016\n",
      "Epoch 35/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7087 - accuracy: 0.9041\n",
      "Epoch 36/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6907 - accuracy: 0.9101\n",
      "Epoch 37/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6829 - accuracy: 0.9084\n",
      "Epoch 38/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6617 - accuracy: 0.9151\n",
      "Epoch 39/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.6373 - accuracy: 0.9225\n",
      "Epoch 40/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6406 - accuracy: 0.9177\n",
      "Epoch 41/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6194 - accuracy: 0.9249\n",
      "Epoch 42/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6095 - accuracy: 0.9266\n",
      "Epoch 43/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.6065 - accuracy: 0.9253\n",
      "Epoch 44/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.5810 - accuracy: 0.9338\n",
      "Epoch 45/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5711 - accuracy: 0.9345\n",
      "Epoch 46/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5604 - accuracy: 0.9377\n",
      "Epoch 47/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5595 - accuracy: 0.9345\n",
      "Epoch 48/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5517 - accuracy: 0.9350\n",
      "Epoch 49/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.5217 - accuracy: 0.9445\n",
      "Epoch 50/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5172 - accuracy: 0.9446\n",
      "Epoch 51/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5157 - accuracy: 0.9439\n",
      "Epoch 52/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5128 - accuracy: 0.9432\n",
      "Epoch 53/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4879 - accuracy: 0.9511\n",
      "Epoch 54/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4889 - accuracy: 0.9495\n",
      "Epoch 55/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4857 - accuracy: 0.9478\n",
      "Epoch 56/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4670 - accuracy: 0.9539\n",
      "Epoch 57/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4556 - accuracy: 0.9556\n",
      "Epoch 58/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4651 - accuracy: 0.9506\n",
      "Epoch 59/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4362 - accuracy: 0.9601\n",
      "Epoch 60/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4504 - accuracy: 0.9538\n",
      "Epoch 61/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4270 - accuracy: 0.9603\n",
      "Epoch 62/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4283 - accuracy: 0.9587\n",
      "Epoch 63/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4163 - accuracy: 0.9608\n",
      "Epoch 64/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4128 - accuracy: 0.9610\n",
      "Epoch 65/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4078 - accuracy: 0.9624\n",
      "Epoch 66/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3942 - accuracy: 0.9659\n",
      "Epoch 67/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3813 - accuracy: 0.9687\n",
      "Epoch 68/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3935 - accuracy: 0.9634\n",
      "Epoch 69/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3839 - accuracy: 0.9660\n",
      "Epoch 70/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3763 - accuracy: 0.9673\n",
      "Epoch 71/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3734 - accuracy: 0.9673\n",
      "Epoch 72/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3593 - accuracy: 0.9713\n",
      "Epoch 73/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3593 - accuracy: 0.9703\n",
      "Epoch 74/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3517 - accuracy: 0.9713\n",
      "Epoch 75/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3587 - accuracy: 0.9687\n",
      "Epoch 76/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3409 - accuracy: 0.9742\n",
      "Epoch 77/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3361 - accuracy: 0.9738\n",
      "Epoch 78/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3443 - accuracy: 0.9702\n",
      "Epoch 79/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3194 - accuracy: 0.9779\n",
      "Epoch 80/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3289 - accuracy: 0.9738\n",
      "Epoch 81/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3149 - accuracy: 0.9785\n",
      "Epoch 82/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3092 - accuracy: 0.9797\n",
      "Epoch 83/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3328 - accuracy: 0.9695\n",
      "Epoch 84/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3000 - accuracy: 0.9800\n",
      "Epoch 85/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3054 - accuracy: 0.9779\n",
      "Epoch 86/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2986 - accuracy: 0.9791\n",
      "Epoch 87/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2982 - accuracy: 0.9789\n",
      "Epoch 88/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2928 - accuracy: 0.9789\n",
      "Epoch 89/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2820 - accuracy: 0.9820\n",
      "Epoch 90/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2829 - accuracy: 0.9808\n",
      "Epoch 91/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3015 - accuracy: 0.9742\n",
      "Epoch 92/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2575 - accuracy: 0.9880\n",
      "Epoch 93/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2864 - accuracy: 0.9780\n",
      "Epoch 94/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2649 - accuracy: 0.9834\n",
      "Epoch 95/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2785 - accuracy: 0.9793\n",
      "Epoch 96/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2528 - accuracy: 0.9866\n",
      "Epoch 97/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2902 - accuracy: 0.9738\n",
      "Epoch 98/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2486 - accuracy: 0.9860\n",
      "Epoch 99/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2730 - accuracy: 0.9781\n",
      "Epoch 100/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2512 - accuracy: 0.9846\n",
      "Epoch 101/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2278 - accuracy: 0.9915\n",
      "Epoch 102/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2820 - accuracy: 0.9737\n",
      "Epoch 103/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2296 - accuracy: 0.9897\n",
      "Epoch 104/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2551 - accuracy: 0.9811\n",
      "Epoch 105/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2499 - accuracy: 0.9814\n",
      "Epoch 106/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2218 - accuracy: 0.9908\n",
      "Epoch 107/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2347 - accuracy: 0.9861\n",
      "Epoch 108/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2300 - accuracy: 0.9876\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2470 - accuracy: 0.9809\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2288 - accuracy: 0.9861\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2265 - accuracy: 0.9863\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2297 - accuracy: 0.9852\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2180 - accuracy: 0.9889\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2227 - accuracy: 0.9868\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2017 - accuracy: 0.9924\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2364 - accuracy: 0.9817\n",
      "Epoch 117/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1972 - accuracy: 0.9927\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2285 - accuracy: 0.9827\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2062 - accuracy: 0.9880\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2061 - accuracy: 0.9887\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2333 - accuracy: 0.9797\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1769 - accuracy: 0.9964\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2248 - accuracy: 0.9828\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1869 - accuracy: 0.9925\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2124 - accuracy: 0.9844\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1913 - accuracy: 0.9896\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1911 - accuracy: 0.9904\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1948 - accuracy: 0.9901\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2101 - accuracy: 0.9833\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1777 - accuracy: 0.9929\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1920 - accuracy: 0.9881\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1984 - accuracy: 0.9866\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1731 - accuracy: 0.9937\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2001 - accuracy: 0.9850\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1666 - accuracy: 0.9948\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1978 - accuracy: 0.9859\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1705 - accuracy: 0.9923\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1815 - accuracy: 0.9895\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1945 - accuracy: 0.9852\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1483 - accuracy: 0.9982\n",
      "Epoch 141/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1893 - accuracy: 0.9864\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1637 - accuracy: 0.9927\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1795 - accuracy: 0.9884\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1875 - accuracy: 0.9860\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1441 - accuracy: 0.9979\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1843 - accuracy: 0.9861\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1484 - accuracy: 0.9958\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1895 - accuracy: 0.9840\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1482 - accuracy: 0.9959\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1750 - accuracy: 0.9882\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1786 - accuracy: 0.9865\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1388 - accuracy: 0.9977\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1761 - accuracy: 0.9869\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1651 - accuracy: 0.9887\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1492 - accuracy: 0.9950\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1707 - accuracy: 0.9865\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1363 - accuracy: 0.9975\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1754 - accuracy: 0.9851\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1283 - accuracy: 0.9991\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1855 - accuracy: 0.9808\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1271 - accuracy: 0.9992\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1787 - accuracy: 0.9819\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1306 - accuracy: 0.9979\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1287 - accuracy: 0.9972\n",
      "Epoch 165/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1737 - accuracy: 0.9842\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1619 - accuracy: 0.9868\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1300 - accuracy: 0.9970\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1482 - accuracy: 0.9918\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1377 - accuracy: 0.9938\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1445 - accuracy: 0.9915\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1569 - accuracy: 0.9877\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1177 - accuracy: 0.9991\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1710 - accuracy: 0.9841\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1192 - accuracy: 0.9985\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1643 - accuracy: 0.9852\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1152 - accuracy: 0.9990\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1544 - accuracy: 0.9877\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1210 - accuracy: 0.9967\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1533 - accuracy: 0.9875\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1091 - accuracy: 0.9996\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1759 - accuracy: 0.9799\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1092 - accuracy: 0.9996\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1560 - accuracy: 0.9845\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1233 - accuracy: 0.9954\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1177 - accuracy: 0.9962\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1483 - accuracy: 0.9871\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1177 - accuracy: 0.9959\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1353 - accuracy: 0.9910\n",
      "Epoch 189/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1363 - accuracy: 0.9900\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1169 - accuracy: 0.9965\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1386 - accuracy: 0.9891\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1075 - accuracy: 0.9988\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1414 - accuracy: 0.9873\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1155 - accuracy: 0.9961\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1229 - accuracy: 0.9933\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1249 - accuracy: 0.9936\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.0987 - accuracy: 0.9998\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1613 - accuracy: 0.9816\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1001 - accuracy: 0.9993\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1419 - accuracy: 0.9873\n",
      "14000/14000 [==============================] - 0s 11us/step\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 1s 30us/step - loss: 3.8377 - accuracy: 0.2504\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.1950 - accuracy: 0.4624\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.8649 - accuracy: 0.5592\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.6265 - accuracy: 0.6110\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.4313 - accuracy: 0.6499\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.2506 - accuracy: 0.6821\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.1079 - accuracy: 0.7025\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.9640 - accuracy: 0.7226\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.8386 - accuracy: 0.7372\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.7380 - accuracy: 0.7457\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6392 - accuracy: 0.7593\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5430 - accuracy: 0.7734\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4643 - accuracy: 0.7832\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3902 - accuracy: 0.7942\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3192 - accuracy: 0.8039\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2456 - accuracy: 0.8199\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2024 - accuracy: 0.8216\n",
      "Epoch 18/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.1543 - accuracy: 0.8282\n",
      "Epoch 19/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.1085 - accuracy: 0.8344\n",
      "Epoch 20/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0570 - accuracy: 0.8440\n",
      "Epoch 21/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0235 - accuracy: 0.8490\n",
      "Epoch 22/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9903 - accuracy: 0.8526\n",
      "Epoch 23/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.9556 - accuracy: 0.8603\n",
      "Epoch 24/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.9149 - accuracy: 0.8708\n",
      "Epoch 25/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8930 - accuracy: 0.8717\n",
      "Epoch 26/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8590 - accuracy: 0.8791\n",
      "Epoch 27/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8524 - accuracy: 0.8760\n",
      "Epoch 28/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8169 - accuracy: 0.8849\n",
      "Epoch 29/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7955 - accuracy: 0.8899\n",
      "Epoch 30/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7788 - accuracy: 0.8914\n",
      "Epoch 31/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7459 - accuracy: 0.9020\n",
      "Epoch 32/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7424 - accuracy: 0.9010\n",
      "Epoch 33/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7142 - accuracy: 0.9062\n",
      "Epoch 34/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7145 - accuracy: 0.9054\n",
      "Epoch 35/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6786 - accuracy: 0.9154\n",
      "Epoch 36/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6720 - accuracy: 0.9165\n",
      "Epoch 37/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6557 - accuracy: 0.9182\n",
      "Epoch 38/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6496 - accuracy: 0.9196\n",
      "Epoch 39/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6281 - accuracy: 0.9237\n",
      "Epoch 40/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6295 - accuracy: 0.9217\n",
      "Epoch 41/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6081 - accuracy: 0.9279\n",
      "Epoch 42/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5834 - accuracy: 0.9351\n",
      "Epoch 43/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5795 - accuracy: 0.9341\n",
      "Epoch 44/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5642 - accuracy: 0.9379\n",
      "Epoch 45/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5660 - accuracy: 0.9348\n",
      "Epoch 46/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5422 - accuracy: 0.9419\n",
      "Epoch 47/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5375 - accuracy: 0.9417\n",
      "Epoch 48/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5303 - accuracy: 0.9418\n",
      "Epoch 49/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5098 - accuracy: 0.9485\n",
      "Epoch 50/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5295 - accuracy: 0.9387\n",
      "Epoch 51/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4907 - accuracy: 0.9509\n",
      "Epoch 52/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4819 - accuracy: 0.9525\n",
      "Epoch 53/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4727 - accuracy: 0.9544\n",
      "Epoch 54/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4704 - accuracy: 0.9536\n",
      "Epoch 55/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4607 - accuracy: 0.9573\n",
      "Epoch 56/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4561 - accuracy: 0.9570\n",
      "Epoch 57/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4432 - accuracy: 0.9587\n",
      "Epoch 58/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4386 - accuracy: 0.9585\n",
      "Epoch 59/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4374 - accuracy: 0.9580\n",
      "Epoch 60/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4287 - accuracy: 0.9606\n",
      "Epoch 61/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4247 - accuracy: 0.9609\n",
      "Epoch 62/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4046 - accuracy: 0.9658\n",
      "Epoch 63/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4091 - accuracy: 0.9634\n",
      "Epoch 64/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4057 - accuracy: 0.9626\n",
      "Epoch 65/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3900 - accuracy: 0.9674\n",
      "Epoch 66/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3915 - accuracy: 0.9656\n",
      "Epoch 67/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3815 - accuracy: 0.9676\n",
      "Epoch 68/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3755 - accuracy: 0.9692\n",
      "Epoch 69/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3730 - accuracy: 0.9684\n",
      "Epoch 70/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3702 - accuracy: 0.9689\n",
      "Epoch 71/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3549 - accuracy: 0.9724\n",
      "Epoch 72/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3596 - accuracy: 0.9712\n",
      "Epoch 73/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3377 - accuracy: 0.9759\n",
      "Epoch 74/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3613 - accuracy: 0.9671\n",
      "Epoch 75/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3284 - accuracy: 0.9769\n",
      "Epoch 76/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3637 - accuracy: 0.9641\n",
      "Epoch 77/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3115 - accuracy: 0.9812\n",
      "Epoch 78/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3214 - accuracy: 0.9774\n",
      "Epoch 79/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3330 - accuracy: 0.9724\n",
      "Epoch 80/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3227 - accuracy: 0.9750\n",
      "Epoch 81/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2994 - accuracy: 0.9813\n",
      "Epoch 82/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3215 - accuracy: 0.9740\n",
      "Epoch 83/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3122 - accuracy: 0.9758\n",
      "Epoch 84/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2935 - accuracy: 0.9812\n",
      "Epoch 85/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2997 - accuracy: 0.9784\n",
      "Epoch 86/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2813 - accuracy: 0.9837\n",
      "Epoch 87/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2981 - accuracy: 0.9783\n",
      "Epoch 88/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2847 - accuracy: 0.9814\n",
      "Epoch 89/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2939 - accuracy: 0.9767\n",
      "Epoch 90/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2820 - accuracy: 0.9805\n",
      "Epoch 91/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2758 - accuracy: 0.9821\n",
      "Epoch 92/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2709 - accuracy: 0.9835\n",
      "Epoch 93/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2658 - accuracy: 0.9834\n",
      "Epoch 94/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2607 - accuracy: 0.9856\n",
      "Epoch 95/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2824 - accuracy: 0.9775\n",
      "Epoch 96/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2414 - accuracy: 0.9892\n",
      "Epoch 97/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2704 - accuracy: 0.9805\n",
      "Epoch 98/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2645 - accuracy: 0.9812\n",
      "Epoch 99/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2450 - accuracy: 0.9868\n",
      "Epoch 100/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2448 - accuracy: 0.9863\n",
      "Epoch 101/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2680 - accuracy: 0.9780\n",
      "Epoch 102/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2152 - accuracy: 0.9935\n",
      "Epoch 103/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2570 - accuracy: 0.9806\n",
      "Epoch 104/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2561 - accuracy: 0.9799\n",
      "Epoch 105/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2153 - accuracy: 0.9914\n",
      "Epoch 106/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2615 - accuracy: 0.9782\n",
      "Epoch 107/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2278 - accuracy: 0.9862\n",
      "Epoch 108/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2236 - accuracy: 0.9881\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2477 - accuracy: 0.9795\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2107 - accuracy: 0.9910\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2313 - accuracy: 0.9849\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2319 - accuracy: 0.9834\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2110 - accuracy: 0.9898\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2231 - accuracy: 0.9859\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2295 - accuracy: 0.9834\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2101 - accuracy: 0.9883\n",
      "Epoch 117/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1967 - accuracy: 0.9921\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2275 - accuracy: 0.9824\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1852 - accuracy: 0.9944\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2183 - accuracy: 0.9846\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2163 - accuracy: 0.9847\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1738 - accuracy: 0.9965\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2335 - accuracy: 0.9789\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2015 - accuracy: 0.9881\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1820 - accuracy: 0.9931\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2200 - accuracy: 0.9812\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1995 - accuracy: 0.9865\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1897 - accuracy: 0.9904\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1899 - accuracy: 0.9895\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2066 - accuracy: 0.9835\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1575 - accuracy: 0.9979\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2265 - accuracy: 0.9771\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1879 - accuracy: 0.9886\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1653 - accuracy: 0.9951\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2070 - accuracy: 0.9833\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1748 - accuracy: 0.9916\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1697 - accuracy: 0.9931\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1839 - accuracy: 0.9886\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1940 - accuracy: 0.9843\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1563 - accuracy: 0.9964\n",
      "Epoch 141/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1990 - accuracy: 0.9826\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1515 - accuracy: 0.9969\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1969 - accuracy: 0.9832\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1721 - accuracy: 0.9893\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1536 - accuracy: 0.9956\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1856 - accuracy: 0.9855\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1568 - accuracy: 0.9932\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1674 - accuracy: 0.9906\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1859 - accuracy: 0.9840\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1468 - accuracy: 0.9962\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1730 - accuracy: 0.9880\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1519 - accuracy: 0.9944\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1571 - accuracy: 0.9924\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1812 - accuracy: 0.9840\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1373 - accuracy: 0.9974\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1664 - accuracy: 0.9888\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1623 - accuracy: 0.9891\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1441 - accuracy: 0.9951\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1724 - accuracy: 0.9869\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1449 - accuracy: 0.9939\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1507 - accuracy: 0.9918\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1247 - accuracy: 0.9987\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1818 - accuracy: 0.9824\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1548 - accuracy: 0.9898\n",
      "Epoch 165/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1338 - accuracy: 0.9959\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1668 - accuracy: 0.9850\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1291 - accuracy: 0.9971\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1502 - accuracy: 0.9905\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1372 - accuracy: 0.9946\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1616 - accuracy: 0.9862\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1287 - accuracy: 0.9965\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1673 - accuracy: 0.9846\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1212 - accuracy: 0.9979\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1562 - accuracy: 0.9870\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1193 - accuracy: 0.9982\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1551 - accuracy: 0.9869\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1247 - accuracy: 0.9964\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1547 - accuracy: 0.9869\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1196 - accuracy: 0.9975\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1483 - accuracy: 0.9876\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1249 - accuracy: 0.9955\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1665 - accuracy: 0.9824\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1121 - accuracy: 0.9989\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1410 - accuracy: 0.9889\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1181 - accuracy: 0.9967\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1459 - accuracy: 0.9876\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1210 - accuracy: 0.9958\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1396 - accuracy: 0.9896\n",
      "Epoch 189/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1329 - accuracy: 0.9910\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1116 - accuracy: 0.9980\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1451 - accuracy: 0.9880\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1049 - accuracy: 0.9989\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1603 - accuracy: 0.9828\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1036 - accuracy: 0.9990\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1322 - accuracy: 0.9908\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1121 - accuracy: 0.9970\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1406 - accuracy: 0.9875\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1082 - accuracy: 0.9978\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1294 - accuracy: 0.9910\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1136 - accuracy: 0.9959\n",
      "14000/14000 [==============================] - 0s 11us/step\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 1s 34us/step - loss: 3.8619 - accuracy: 0.2486\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 0s 10us/step - loss: 3.1992 - accuracy: 0.4813\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.8259 - accuracy: 0.5943\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.5813 - accuracy: 0.6322\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 2.3535 - accuracy: 0.6679\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.1766 - accuracy: 0.6880\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.0157 - accuracy: 0.7085\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.8689 - accuracy: 0.7294\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.7530 - accuracy: 0.7390\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6395 - accuracy: 0.7537\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5419 - accuracy: 0.7674\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4519 - accuracy: 0.7792\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3774 - accuracy: 0.7853\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3110 - accuracy: 0.7962\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2423 - accuracy: 0.8065\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1991 - accuracy: 0.8074\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1225 - accuracy: 0.8299\n",
      "Epoch 18/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0890 - accuracy: 0.8301\n",
      "Epoch 19/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.0635 - accuracy: 0.8305\n",
      "Epoch 20/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0218 - accuracy: 0.8399\n",
      "Epoch 21/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9777 - accuracy: 0.8505\n",
      "Epoch 22/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9499 - accuracy: 0.8518\n",
      "Epoch 23/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9197 - accuracy: 0.8597\n",
      "Epoch 24/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8987 - accuracy: 0.8636\n",
      "Epoch 25/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8747 - accuracy: 0.8668\n",
      "Epoch 26/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8522 - accuracy: 0.8726\n",
      "Epoch 27/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8235 - accuracy: 0.8818\n",
      "Epoch 28/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8065 - accuracy: 0.8831\n",
      "Epoch 29/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7857 - accuracy: 0.8875\n",
      "Epoch 30/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7699 - accuracy: 0.8917\n",
      "Epoch 31/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.7591 - accuracy: 0.8916\n",
      "Epoch 32/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7342 - accuracy: 0.8982\n",
      "Epoch 33/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7159 - accuracy: 0.9029\n",
      "Epoch 34/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6898 - accuracy: 0.9099\n",
      "Epoch 35/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6932 - accuracy: 0.9062\n",
      "Epoch 36/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6556 - accuracy: 0.9184\n",
      "Epoch 37/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6659 - accuracy: 0.9114\n",
      "Epoch 38/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6320 - accuracy: 0.9226\n",
      "Epoch 39/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6372 - accuracy: 0.9154\n",
      "Epoch 40/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6049 - accuracy: 0.9290\n",
      "Epoch 41/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.6050 - accuracy: 0.9257\n",
      "Epoch 42/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5928 - accuracy: 0.9277\n",
      "Epoch 43/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5781 - accuracy: 0.9322\n",
      "Epoch 44/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5692 - accuracy: 0.9333\n",
      "Epoch 45/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5609 - accuracy: 0.9347\n",
      "Epoch 46/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.5490 - accuracy: 0.9367\n",
      "Epoch 47/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5319 - accuracy: 0.9414\n",
      "Epoch 48/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5096 - accuracy: 0.9484\n",
      "Epoch 49/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5238 - accuracy: 0.9420\n",
      "Epoch 50/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5099 - accuracy: 0.9445\n",
      "Epoch 51/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5022 - accuracy: 0.9453\n",
      "Epoch 52/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4872 - accuracy: 0.9502\n",
      "Epoch 53/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4855 - accuracy: 0.9490\n",
      "Epoch 54/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4748 - accuracy: 0.9500\n",
      "Epoch 55/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4622 - accuracy: 0.9540\n",
      "Epoch 56/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4615 - accuracy: 0.9533\n",
      "Epoch 57/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4617 - accuracy: 0.9510\n",
      "Epoch 58/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4398 - accuracy: 0.9580\n",
      "Epoch 59/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4393 - accuracy: 0.9558\n",
      "Epoch 60/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4106 - accuracy: 0.9653\n",
      "Epoch 61/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4395 - accuracy: 0.9542\n",
      "Epoch 62/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4074 - accuracy: 0.9637\n",
      "Epoch 63/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4048 - accuracy: 0.9634\n",
      "Epoch 64/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4118 - accuracy: 0.9598\n",
      "Epoch 65/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3828 - accuracy: 0.9689\n",
      "Epoch 66/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3918 - accuracy: 0.9660\n",
      "Epoch 67/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3941 - accuracy: 0.9630\n",
      "Epoch 68/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3705 - accuracy: 0.9694\n",
      "Epoch 69/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3761 - accuracy: 0.9667\n",
      "Epoch 70/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3555 - accuracy: 0.9730\n",
      "Epoch 71/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3693 - accuracy: 0.9674\n",
      "Epoch 72/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3538 - accuracy: 0.9714\n",
      "Epoch 73/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3550 - accuracy: 0.9700\n",
      "Epoch 74/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3528 - accuracy: 0.9702\n",
      "Epoch 75/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3409 - accuracy: 0.9730\n",
      "Epoch 76/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3468 - accuracy: 0.9704\n",
      "Epoch 77/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3265 - accuracy: 0.9748\n",
      "Epoch 78/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3285 - accuracy: 0.9745\n",
      "Epoch 79/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3331 - accuracy: 0.9718\n",
      "Epoch 80/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3103 - accuracy: 0.9790\n",
      "Epoch 81/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3182 - accuracy: 0.9743\n",
      "Epoch 82/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3184 - accuracy: 0.9748\n",
      "Epoch 83/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3063 - accuracy: 0.9769\n",
      "Epoch 84/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3018 - accuracy: 0.9779\n",
      "Epoch 85/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3009 - accuracy: 0.9787\n",
      "Epoch 86/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2948 - accuracy: 0.9798\n",
      "Epoch 87/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2993 - accuracy: 0.9774\n",
      "Epoch 88/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2924 - accuracy: 0.9776\n",
      "Epoch 89/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2754 - accuracy: 0.9835\n",
      "Epoch 90/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2985 - accuracy: 0.9757\n",
      "Epoch 91/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2586 - accuracy: 0.9866\n",
      "Epoch 92/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2837 - accuracy: 0.9783\n",
      "Epoch 93/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2782 - accuracy: 0.9794\n",
      "Epoch 94/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2647 - accuracy: 0.9836\n",
      "Epoch 95/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2728 - accuracy: 0.9803\n",
      "Epoch 96/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2658 - accuracy: 0.9810\n",
      "Epoch 97/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2461 - accuracy: 0.9876\n",
      "Epoch 98/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2760 - accuracy: 0.9772\n",
      "Epoch 99/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2426 - accuracy: 0.9866\n",
      "Epoch 100/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2614 - accuracy: 0.9817\n",
      "Epoch 101/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2409 - accuracy: 0.9866\n",
      "Epoch 102/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2455 - accuracy: 0.9850\n",
      "Epoch 103/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2587 - accuracy: 0.9794\n",
      "Epoch 104/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2470 - accuracy: 0.9817\n",
      "Epoch 105/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2207 - accuracy: 0.9909\n",
      "Epoch 106/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2504 - accuracy: 0.9818\n",
      "Epoch 107/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2193 - accuracy: 0.9906\n",
      "Epoch 108/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2536 - accuracy: 0.9789\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2035 - accuracy: 0.9933\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2425 - accuracy: 0.9828\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2160 - accuracy: 0.9894\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2522 - accuracy: 0.9774\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1940 - accuracy: 0.9947\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2331 - accuracy: 0.9827\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1994 - accuracy: 0.9925\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2320 - accuracy: 0.9824\n",
      "Epoch 117/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2062 - accuracy: 0.9895\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2043 - accuracy: 0.9895\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2215 - accuracy: 0.9839\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1965 - accuracy: 0.9907\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2059 - accuracy: 0.9883\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2171 - accuracy: 0.9843\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1841 - accuracy: 0.9934\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2267 - accuracy: 0.9799\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1709 - accuracy: 0.9964\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2328 - accuracy: 0.9771\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1616 - accuracy: 0.9980\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2248 - accuracy: 0.9783\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1614 - accuracy: 0.9975\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2294 - accuracy: 0.9774\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1685 - accuracy: 0.9951\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2068 - accuracy: 0.9826\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2025 - accuracy: 0.9836\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1593 - accuracy: 0.9971\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2031 - accuracy: 0.9831\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1637 - accuracy: 0.9950\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1844 - accuracy: 0.9890\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1948 - accuracy: 0.9858\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1580 - accuracy: 0.9955\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1898 - accuracy: 0.9863\n",
      "Epoch 141/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1855 - accuracy: 0.9866\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1616 - accuracy: 0.9942\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1912 - accuracy: 0.9848\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1532 - accuracy: 0.9958\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1805 - accuracy: 0.9870\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1663 - accuracy: 0.9914\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1759 - accuracy: 0.9886\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1445 - accuracy: 0.9969\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1754 - accuracy: 0.9880\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1749 - accuracy: 0.9876\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1591 - accuracy: 0.9922\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1630 - accuracy: 0.9910\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1464 - accuracy: 0.9952\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1858 - accuracy: 0.9827\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1363 - accuracy: 0.9976\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1784 - accuracy: 0.9844\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1335 - accuracy: 0.9981\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1734 - accuracy: 0.9862\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1356 - accuracy: 0.9964\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1696 - accuracy: 0.9862\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1588 - accuracy: 0.9887\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1522 - accuracy: 0.9916\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1450 - accuracy: 0.9927\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1464 - accuracy: 0.9927\n",
      "Epoch 165/200\n",
      "28000/28000 [==============================] - 0s 10us/step - loss: 0.1596 - accuracy: 0.9890\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1515 - accuracy: 0.9900\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1453 - accuracy: 0.9923\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1424 - accuracy: 0.9932\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1295 - accuracy: 0.9962\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1508 - accuracy: 0.9901\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1529 - accuracy: 0.9891\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1258 - accuracy: 0.9971\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1526 - accuracy: 0.9889\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1156 - accuracy: 0.9991\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1660 - accuracy: 0.9850\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1335 - accuracy: 0.9932\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1393 - accuracy: 0.9914\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1135 - accuracy: 0.9987\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1621 - accuracy: 0.9846\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1397 - accuracy: 0.9900\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1318 - accuracy: 0.9934\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1388 - accuracy: 0.9903\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1209 - accuracy: 0.9964\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1357 - accuracy: 0.9906\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1301 - accuracy: 0.9927\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1131 - accuracy: 0.9977\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1432 - accuracy: 0.9890\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1038 - accuracy: 0.9995\n",
      "Epoch 189/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1601 - accuracy: 0.9836\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1189 - accuracy: 0.9953\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1308 - accuracy: 0.9920\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1055 - accuracy: 0.9986\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1502 - accuracy: 0.9856\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1284 - accuracy: 0.9912\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1035 - accuracy: 0.9990\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1511 - accuracy: 0.9850\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1037 - accuracy: 0.9985\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1255 - accuracy: 0.9914\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1220 - accuracy: 0.9928\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1261 - accuracy: 0.9916\n",
      "14000/14000 [==============================] - 0s 13us/step\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 1s 34us/step - loss: 4.0785 - accuracy: 0.2705\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.3974 - accuracy: 0.4772\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 3.0316 - accuracy: 0.5744\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.7665 - accuracy: 0.6301\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.5425 - accuracy: 0.6639\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.3483 - accuracy: 0.6870\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 2.1674 - accuracy: 0.7094\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.0109 - accuracy: 0.7296\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.8891 - accuracy: 0.7356\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 1.7463 - accuracy: 0.7540\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.6442 - accuracy: 0.7620\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 1.5513 - accuracy: 0.7706\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4619 - accuracy: 0.7820\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3734 - accuracy: 0.7954\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3157 - accuracy: 0.7976\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2527 - accuracy: 0.8070\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1777 - accuracy: 0.8236\n",
      "Epoch 18/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1433 - accuracy: 0.8234\n",
      "Epoch 19/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1057 - accuracy: 0.8252\n",
      "Epoch 20/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0610 - accuracy: 0.8355\n",
      "Epoch 21/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0245 - accuracy: 0.8413\n",
      "Epoch 22/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9875 - accuracy: 0.8500\n",
      "Epoch 23/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9627 - accuracy: 0.8529\n",
      "Epoch 24/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9399 - accuracy: 0.8545\n",
      "Epoch 25/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9001 - accuracy: 0.8650\n",
      "Epoch 26/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.8899 - accuracy: 0.8646\n",
      "Epoch 27/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8600 - accuracy: 0.8721\n",
      "Epoch 28/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8381 - accuracy: 0.8781\n",
      "Epoch 29/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8137 - accuracy: 0.8836\n",
      "Epoch 30/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.8099 - accuracy: 0.8797\n",
      "Epoch 31/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7714 - accuracy: 0.8932\n",
      "Epoch 32/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7638 - accuracy: 0.8913\n",
      "Epoch 33/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7372 - accuracy: 0.9014\n",
      "Epoch 34/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.7314 - accuracy: 0.8997\n",
      "Epoch 35/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6921 - accuracy: 0.9121\n",
      "Epoch 36/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7061 - accuracy: 0.9040\n",
      "Epoch 37/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6699 - accuracy: 0.9139\n",
      "Epoch 38/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.6667 - accuracy: 0.9149\n",
      "Epoch 39/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6473 - accuracy: 0.9180\n",
      "Epoch 40/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6318 - accuracy: 0.9216\n",
      "Epoch 41/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6166 - accuracy: 0.9250\n",
      "Epoch 42/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6064 - accuracy: 0.9270\n",
      "Epoch 43/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.5863 - accuracy: 0.9320\n",
      "Epoch 44/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5905 - accuracy: 0.9315\n",
      "Epoch 45/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5722 - accuracy: 0.9330\n",
      "Epoch 46/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.5518 - accuracy: 0.9396\n",
      "Epoch 47/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5452 - accuracy: 0.9398\n",
      "Epoch 48/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5581 - accuracy: 0.9315\n",
      "Epoch 49/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5253 - accuracy: 0.9439\n",
      "Epoch 50/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5154 - accuracy: 0.9462\n",
      "Epoch 51/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5131 - accuracy: 0.9435\n",
      "Epoch 52/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5009 - accuracy: 0.9470\n",
      "Epoch 53/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4859 - accuracy: 0.9506\n",
      "Epoch 54/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4799 - accuracy: 0.9514\n",
      "Epoch 55/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4790 - accuracy: 0.9499\n",
      "Epoch 56/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4632 - accuracy: 0.9548\n",
      "Epoch 57/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4654 - accuracy: 0.9529\n",
      "Epoch 58/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4449 - accuracy: 0.9564\n",
      "Epoch 59/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4422 - accuracy: 0.9574\n",
      "Epoch 60/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4480 - accuracy: 0.9536\n",
      "Epoch 61/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4204 - accuracy: 0.9624\n",
      "Epoch 62/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4356 - accuracy: 0.9562\n",
      "Epoch 63/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4076 - accuracy: 0.9638\n",
      "Epoch 64/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4123 - accuracy: 0.9612\n",
      "Epoch 65/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3933 - accuracy: 0.9670\n",
      "Epoch 66/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3935 - accuracy: 0.9666\n",
      "Epoch 67/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3982 - accuracy: 0.9624\n",
      "Epoch 68/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3777 - accuracy: 0.9689\n",
      "Epoch 69/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3821 - accuracy: 0.9668\n",
      "Epoch 70/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3678 - accuracy: 0.9703\n",
      "Epoch 71/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3707 - accuracy: 0.9674\n",
      "Epoch 72/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3781 - accuracy: 0.9628\n",
      "Epoch 73/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3477 - accuracy: 0.9728\n",
      "Epoch 74/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3539 - accuracy: 0.9715\n",
      "Epoch 75/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3510 - accuracy: 0.9707\n",
      "Epoch 76/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.3315 - accuracy: 0.9759\n",
      "Epoch 77/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3459 - accuracy: 0.9716\n",
      "Epoch 78/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3277 - accuracy: 0.9756\n",
      "Epoch 79/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3385 - accuracy: 0.9709\n",
      "Epoch 80/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2993 - accuracy: 0.9835\n",
      "Epoch 81/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3442 - accuracy: 0.9674\n",
      "Epoch 82/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2948 - accuracy: 0.9833\n",
      "Epoch 83/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3348 - accuracy: 0.9689\n",
      "Epoch 84/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3015 - accuracy: 0.9786\n",
      "Epoch 85/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2907 - accuracy: 0.9811\n",
      "Epoch 86/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3069 - accuracy: 0.9761\n",
      "Epoch 87/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3014 - accuracy: 0.9770\n",
      "Epoch 88/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2817 - accuracy: 0.9825\n",
      "Epoch 89/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2994 - accuracy: 0.9755\n",
      "Epoch 90/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2641 - accuracy: 0.9866\n",
      "Epoch 91/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2854 - accuracy: 0.9792\n",
      "Epoch 92/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2839 - accuracy: 0.9794\n",
      "Epoch 93/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2509 - accuracy: 0.9887\n",
      "Epoch 94/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2777 - accuracy: 0.9798\n",
      "Epoch 95/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2650 - accuracy: 0.9829\n",
      "Epoch 96/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2496 - accuracy: 0.9868\n",
      "Epoch 97/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2666 - accuracy: 0.9810\n",
      "Epoch 98/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2545 - accuracy: 0.9843\n",
      "Epoch 99/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2663 - accuracy: 0.9796\n",
      "Epoch 100/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2248 - accuracy: 0.9916\n",
      "Epoch 101/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2738 - accuracy: 0.9758\n",
      "Epoch 102/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2375 - accuracy: 0.9871\n",
      "Epoch 103/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2401 - accuracy: 0.9865\n",
      "Epoch 104/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2570 - accuracy: 0.9802\n",
      "Epoch 105/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2164 - accuracy: 0.9918\n",
      "Epoch 106/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2482 - accuracy: 0.9819\n",
      "Epoch 107/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2328 - accuracy: 0.9859\n",
      "Epoch 108/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2182 - accuracy: 0.9902\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2461 - accuracy: 0.9806\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.2365 - accuracy: 0.9824\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2026 - accuracy: 0.9936\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2587 - accuracy: 0.9748\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1966 - accuracy: 0.9939\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2236 - accuracy: 0.9860\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2134 - accuracy: 0.9878\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2243 - accuracy: 0.9849\n",
      "Epoch 117/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1853 - accuracy: 0.9954\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2502 - accuracy: 0.9747\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1776 - accuracy: 0.9966\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2376 - accuracy: 0.9787\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1870 - accuracy: 0.9931\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2159 - accuracy: 0.9838\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2094 - accuracy: 0.9858\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2042 - accuracy: 0.9872\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2070 - accuracy: 0.9864\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1870 - accuracy: 0.9906\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1953 - accuracy: 0.9887\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2021 - accuracy: 0.9854\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1735 - accuracy: 0.9947\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2116 - accuracy: 0.9829\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1680 - accuracy: 0.9951\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1940 - accuracy: 0.9878\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1797 - accuracy: 0.9905\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1924 - accuracy: 0.9875\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1965 - accuracy: 0.9852\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1590 - accuracy: 0.9965\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2013 - accuracy: 0.9833\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1636 - accuracy: 0.9939\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1795 - accuracy: 0.9893\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1789 - accuracy: 0.9893\n",
      "Epoch 141/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1961 - accuracy: 0.9834\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1567 - accuracy: 0.9957\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1575 - accuracy: 0.9935\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1981 - accuracy: 0.9821\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1448 - accuracy: 0.9975\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1946 - accuracy: 0.9823\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1413 - accuracy: 0.9980\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1916 - accuracy: 0.9835\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1616 - accuracy: 0.9910\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1575 - accuracy: 0.9934\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1719 - accuracy: 0.9869\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1475 - accuracy: 0.9956\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1831 - accuracy: 0.9838\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1365 - accuracy: 0.9976\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1755 - accuracy: 0.9861\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1643 - accuracy: 0.9882\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1514 - accuracy: 0.9929\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1721 - accuracy: 0.9864\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1309 - accuracy: 0.9980\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1745 - accuracy: 0.9855\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1264 - accuracy: 0.9987\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1771 - accuracy: 0.9835\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1529 - accuracy: 0.9900\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1355 - accuracy: 0.9961\n",
      "Epoch 165/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1700 - accuracy: 0.9847\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1233 - accuracy: 0.9986\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1717 - accuracy: 0.9850\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1241 - accuracy: 0.9977\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1734 - accuracy: 0.9834\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1184 - accuracy: 0.9989\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1731 - accuracy: 0.9828\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1207 - accuracy: 0.9981\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1563 - accuracy: 0.9876\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1224 - accuracy: 0.9975\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1583 - accuracy: 0.9866\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1321 - accuracy: 0.9937\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1272 - accuracy: 0.9957\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1563 - accuracy: 0.9864\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1198 - accuracy: 0.9971\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1395 - accuracy: 0.9906\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1290 - accuracy: 0.9940\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1299 - accuracy: 0.9933\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1367 - accuracy: 0.9920\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1271 - accuracy: 0.9936\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1422 - accuracy: 0.9894\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1217 - accuracy: 0.9948\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1337 - accuracy: 0.9921\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1157 - accuracy: 0.9965\n",
      "Epoch 189/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1473 - accuracy: 0.9880\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1243 - accuracy: 0.9944\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1171 - accuracy: 0.9958\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1441 - accuracy: 0.9874\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1087 - accuracy: 0.9980\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1367 - accuracy: 0.9901\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1020 - accuracy: 0.9992\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1517 - accuracy: 0.9841\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1026 - accuracy: 0.9988\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1386 - accuracy: 0.9888\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1049 - accuracy: 0.9980\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1402 - accuracy: 0.9875\n",
      "14000/14000 [==============================] - 0s 12us/step\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 1s 31us/step - loss: 4.0531 - accuracy: 0.2624\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.3638 - accuracy: 0.4952\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 3.0062 - accuracy: 0.5889\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.7340 - accuracy: 0.6358\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.5209 - accuracy: 0.6572\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 2.3098 - accuracy: 0.6846\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 2.1539 - accuracy: 0.7042\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.9966 - accuracy: 0.7186\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.8599 - accuracy: 0.7370\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.7290 - accuracy: 0.7525\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.6183 - accuracy: 0.7649\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.5455 - accuracy: 0.7651\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.4495 - accuracy: 0.7782\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3711 - accuracy: 0.7896\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.3083 - accuracy: 0.7984\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.2474 - accuracy: 0.8039\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1951 - accuracy: 0.8100\n",
      "Epoch 18/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.1418 - accuracy: 0.8196\n",
      "Epoch 19/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0914 - accuracy: 0.8290\n",
      "Epoch 20/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0570 - accuracy: 0.8344\n",
      "Epoch 21/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 1.0141 - accuracy: 0.8438\n",
      "Epoch 22/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9950 - accuracy: 0.8414\n",
      "Epoch 23/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9497 - accuracy: 0.8543\n",
      "Epoch 24/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.9167 - accuracy: 0.8595\n",
      "Epoch 25/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8989 - accuracy: 0.8626\n",
      "Epoch 26/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8777 - accuracy: 0.8647\n",
      "Epoch 27/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8490 - accuracy: 0.8704\n",
      "Epoch 28/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8208 - accuracy: 0.8786\n",
      "Epoch 29/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.8144 - accuracy: 0.8790\n",
      "Epoch 30/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7866 - accuracy: 0.8868\n",
      "Epoch 31/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7672 - accuracy: 0.8920\n",
      "Epoch 32/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7458 - accuracy: 0.8961\n",
      "Epoch 33/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7376 - accuracy: 0.8973\n",
      "Epoch 34/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.7146 - accuracy: 0.9025\n",
      "Epoch 35/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.7243 - accuracy: 0.8986\n",
      "Epoch 36/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6802 - accuracy: 0.9111\n",
      "Epoch 37/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6601 - accuracy: 0.9175\n",
      "Epoch 38/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6554 - accuracy: 0.9162\n",
      "Epoch 39/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6470 - accuracy: 0.9173\n",
      "Epoch 40/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.6425 - accuracy: 0.9156\n",
      "Epoch 41/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.6147 - accuracy: 0.9238\n",
      "Epoch 42/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5979 - accuracy: 0.9284\n",
      "Epoch 43/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5927 - accuracy: 0.9286\n",
      "Epoch 44/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5877 - accuracy: 0.9287\n",
      "Epoch 45/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5666 - accuracy: 0.9350\n",
      "Epoch 46/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5712 - accuracy: 0.9323\n",
      "Epoch 47/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5323 - accuracy: 0.9422\n",
      "Epoch 48/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5441 - accuracy: 0.9389\n",
      "Epoch 49/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5246 - accuracy: 0.9430\n",
      "Epoch 50/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5242 - accuracy: 0.9398\n",
      "Epoch 51/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5062 - accuracy: 0.9461\n",
      "Epoch 52/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.5058 - accuracy: 0.9444\n",
      "Epoch 53/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4931 - accuracy: 0.9481\n",
      "Epoch 54/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4837 - accuracy: 0.9497\n",
      "Epoch 55/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4785 - accuracy: 0.9488\n",
      "Epoch 56/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4581 - accuracy: 0.9557\n",
      "Epoch 57/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4560 - accuracy: 0.9550\n",
      "Epoch 58/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4464 - accuracy: 0.9584\n",
      "Epoch 59/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4507 - accuracy: 0.9536\n",
      "Epoch 60/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4427 - accuracy: 0.9556\n",
      "Epoch 61/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.4344 - accuracy: 0.9574\n",
      "Epoch 62/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4066 - accuracy: 0.9662\n",
      "Epoch 63/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4330 - accuracy: 0.9549\n",
      "Epoch 64/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.4069 - accuracy: 0.9626\n",
      "Epoch 65/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4079 - accuracy: 0.9619\n",
      "Epoch 66/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3764 - accuracy: 0.9715\n",
      "Epoch 67/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.4001 - accuracy: 0.9611\n",
      "Epoch 68/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3812 - accuracy: 0.9682\n",
      "Epoch 69/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3639 - accuracy: 0.9727\n",
      "Epoch 70/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3814 - accuracy: 0.9651\n",
      "Epoch 71/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3546 - accuracy: 0.9731\n",
      "Epoch 72/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3620 - accuracy: 0.9693\n",
      "Epoch 73/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3708 - accuracy: 0.9652\n",
      "Epoch 74/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3525 - accuracy: 0.9707\n",
      "Epoch 75/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3304 - accuracy: 0.9770\n",
      "Epoch 76/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3478 - accuracy: 0.9704\n",
      "Epoch 77/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3369 - accuracy: 0.9734\n",
      "Epoch 78/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3410 - accuracy: 0.9720\n",
      "Epoch 79/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3374 - accuracy: 0.9706\n",
      "Epoch 80/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3171 - accuracy: 0.9770\n",
      "Epoch 81/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.3262 - accuracy: 0.9725\n",
      "Epoch 82/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2937 - accuracy: 0.9836\n",
      "Epoch 83/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3177 - accuracy: 0.9747\n",
      "Epoch 84/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3225 - accuracy: 0.9719\n",
      "Epoch 85/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2952 - accuracy: 0.9804\n",
      "Epoch 86/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2834 - accuracy: 0.9838\n",
      "Epoch 87/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.3015 - accuracy: 0.9769\n",
      "Epoch 88/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2946 - accuracy: 0.9782\n",
      "Epoch 89/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2765 - accuracy: 0.9835\n",
      "Epoch 90/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2895 - accuracy: 0.9785\n",
      "Epoch 91/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2796 - accuracy: 0.9806\n",
      "Epoch 92/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2591 - accuracy: 0.9868\n",
      "Epoch 93/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2841 - accuracy: 0.9778\n",
      "Epoch 94/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2796 - accuracy: 0.9787\n",
      "Epoch 95/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2570 - accuracy: 0.9852\n",
      "Epoch 96/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2579 - accuracy: 0.9844\n",
      "Epoch 97/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2827 - accuracy: 0.9759\n",
      "Epoch 98/200\n",
      "28000/28000 [==============================] - 0s 10us/step - loss: 0.2485 - accuracy: 0.9856\n",
      "Epoch 99/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2472 - accuracy: 0.9864\n",
      "Epoch 100/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2613 - accuracy: 0.9817\n",
      "Epoch 101/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2460 - accuracy: 0.9848\n",
      "Epoch 102/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2484 - accuracy: 0.9846\n",
      "Epoch 103/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2481 - accuracy: 0.9831\n",
      "Epoch 104/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2246 - accuracy: 0.9905\n",
      "Epoch 105/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2444 - accuracy: 0.9845\n",
      "Epoch 106/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2370 - accuracy: 0.9847\n",
      "Epoch 107/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2250 - accuracy: 0.9891\n",
      "Epoch 108/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2421 - accuracy: 0.9835\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2290 - accuracy: 0.9861\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2248 - accuracy: 0.9867\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2372 - accuracy: 0.9835\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2040 - accuracy: 0.9928\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2323 - accuracy: 0.9830\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2336 - accuracy: 0.9820\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1933 - accuracy: 0.9944\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2335 - accuracy: 0.9816\n",
      "Epoch 117/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1977 - accuracy: 0.9916\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2162 - accuracy: 0.9862\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2333 - accuracy: 0.9799\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1747 - accuracy: 0.9976\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2302 - accuracy: 0.9801\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1776 - accuracy: 0.9956\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2334 - accuracy: 0.9790\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1693 - accuracy: 0.9971\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2242 - accuracy: 0.9802\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1943 - accuracy: 0.9887\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1861 - accuracy: 0.9915\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2130 - accuracy: 0.9835\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1647 - accuracy: 0.9970\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2149 - accuracy: 0.9817\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1937 - accuracy: 0.9869\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1684 - accuracy: 0.9954\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2023 - accuracy: 0.9838\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1624 - accuracy: 0.9964\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.2045 - accuracy: 0.9829\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1642 - accuracy: 0.9948\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1978 - accuracy: 0.9849\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1490 - accuracy: 0.9984\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.2068 - accuracy: 0.9808\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1612 - accuracy: 0.9949\n",
      "Epoch 141/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1783 - accuracy: 0.9893\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1614 - accuracy: 0.9927\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1947 - accuracy: 0.9837\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1643 - accuracy: 0.9920\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1654 - accuracy: 0.9930\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1846 - accuracy: 0.9858\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1449 - accuracy: 0.9971\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1869 - accuracy: 0.9850\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1436 - accuracy: 0.9968\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1822 - accuracy: 0.9853\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1568 - accuracy: 0.9919\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1541 - accuracy: 0.9937\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1764 - accuracy: 0.9861\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1326 - accuracy: 0.9987\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1935 - accuracy: 0.9802\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1326 - accuracy: 0.9987\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1761 - accuracy: 0.9851\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1306 - accuracy: 0.9983\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1695 - accuracy: 0.9875\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1368 - accuracy: 0.9956\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1674 - accuracy: 0.9868\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1612 - accuracy: 0.9885\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1270 - accuracy: 0.9983\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1720 - accuracy: 0.9839\n",
      "Epoch 165/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1265 - accuracy: 0.9981\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1561 - accuracy: 0.9877\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1424 - accuracy: 0.9937\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1501 - accuracy: 0.9898\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1422 - accuracy: 0.9929\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1471 - accuracy: 0.9909\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1155 - accuracy: 0.9994\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1736 - accuracy: 0.9829\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1192 - accuracy: 0.9984\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1290 - accuracy: 0.9945\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1663 - accuracy: 0.9843\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1127 - accuracy: 0.9992\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 0s 9us/step - loss: 0.1684 - accuracy: 0.9833\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1222 - accuracy: 0.9965\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1441 - accuracy: 0.9902\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1494 - accuracy: 0.9882\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1223 - accuracy: 0.9966\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1169 - accuracy: 0.9968\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1579 - accuracy: 0.9858\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1072 - accuracy: 0.9994\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1584 - accuracy: 0.9843\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1095 - accuracy: 0.9990\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1522 - accuracy: 0.9855\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1093 - accuracy: 0.9986\n",
      "Epoch 189/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1550 - accuracy: 0.9841\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1094 - accuracy: 0.9981\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1316 - accuracy: 0.9914\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1038 - accuracy: 0.9989\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1522 - accuracy: 0.9854\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1289 - accuracy: 0.9906\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1131 - accuracy: 0.9966\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1374 - accuracy: 0.9896\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1086 - accuracy: 0.9974\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1371 - accuracy: 0.9891\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 0s 8us/step - loss: 0.1041 - accuracy: 0.9985\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 0s 7us/step - loss: 0.1420 - accuracy: 0.9872\n",
      "14000/14000 [==============================] - 0s 11us/step\n",
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 3.6698 - accuracy: 0.3553\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 2.7344 - accuracy: 0.6103\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 2.2096 - accuracy: 0.6841\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 1.8452 - accuracy: 0.7218\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 1.5792 - accuracy: 0.7502\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 1.3852 - accuracy: 0.7681\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 1.2379 - accuracy: 0.7863\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 1.1120 - accuracy: 0.8074\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 1.0207 - accuracy: 0.8203\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.9461 - accuracy: 0.8324\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.8828 - accuracy: 0.8465\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.8405 - accuracy: 0.8551\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.8005 - accuracy: 0.8620\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.7554 - accuracy: 0.8743\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.7234 - accuracy: 0.8815\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.6877 - accuracy: 0.8911\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.6586 - accuracy: 0.8973\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.6375 - accuracy: 0.8977\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.6030 - accuracy: 0.9075\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.5828 - accuracy: 0.9113\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.5552 - accuracy: 0.9182\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.5386 - accuracy: 0.9220\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.5130 - accuracy: 0.9269\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.4968 - accuracy: 0.9295\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.4781 - accuracy: 0.9344\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.4616 - accuracy: 0.9360\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.4461 - accuracy: 0.9395\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.4267 - accuracy: 0.9442\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.4202 - accuracy: 0.9435\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.4041 - accuracy: 0.9475\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.3899 - accuracy: 0.9510\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.3803 - accuracy: 0.9515\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.3603 - accuracy: 0.9563\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.3567 - accuracy: 0.9559\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.3407 - accuracy: 0.9601\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.3340 - accuracy: 0.9598\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.3242 - accuracy: 0.9615\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.3157 - accuracy: 0.9623\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.3056 - accuracy: 0.9642\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2987 - accuracy: 0.9655\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.2896 - accuracy: 0.9671\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.2812 - accuracy: 0.9682\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.2728 - accuracy: 0.9710\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2671 - accuracy: 0.9706\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.2579 - accuracy: 0.9723\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.2543 - accuracy: 0.9734\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.2490 - accuracy: 0.9728\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.2408 - accuracy: 0.9751\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.2379 - accuracy: 0.9751\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.2312 - accuracy: 0.9759\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.2250 - accuracy: 0.9779\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.2197 - accuracy: 0.9780\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.2147 - accuracy: 0.9781\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.2108 - accuracy: 0.9786\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.2056 - accuracy: 0.9803\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.2019 - accuracy: 0.9808\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.1982 - accuracy: 0.9800\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1918 - accuracy: 0.9824\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1892 - accuracy: 0.9820\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1859 - accuracy: 0.9822\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1831 - accuracy: 0.9825\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1798 - accuracy: 0.9824\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1773 - accuracy: 0.9829\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1748 - accuracy: 0.9832\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1701 - accuracy: 0.9843\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1657 - accuracy: 0.9850\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1597 - accuracy: 0.9862\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.1605 - accuracy: 0.9855\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.1614 - accuracy: 0.9846\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1576 - accuracy: 0.9855\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1528 - accuracy: 0.9861\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1490 - accuracy: 0.9870\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1525 - accuracy: 0.9846\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1445 - accuracy: 0.9870\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1425 - accuracy: 0.9873\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1403 - accuracy: 0.9874\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1416 - accuracy: 0.9863\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.1376 - accuracy: 0.9877\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1327 - accuracy: 0.9883\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.1345 - accuracy: 0.9876\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.1248 - accuracy: 0.9906\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1294 - accuracy: 0.9882\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1270 - accuracy: 0.9885\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1350 - accuracy: 0.9860\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1225 - accuracy: 0.9895\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.1202 - accuracy: 0.9897\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.1169 - accuracy: 0.9907\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1193 - accuracy: 0.9893\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1171 - accuracy: 0.9901\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.1186 - accuracy: 0.9890\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.1163 - accuracy: 0.9895\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1101 - accuracy: 0.9908\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1090 - accuracy: 0.9909\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1078 - accuracy: 0.9912\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1104 - accuracy: 0.9902\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.1055 - accuracy: 0.9918\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.1040 - accuracy: 0.9913\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.1050 - accuracy: 0.9913\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.1003 - accuracy: 0.9919\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.1007 - accuracy: 0.9914\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1026 - accuracy: 0.9911\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.1028 - accuracy: 0.9910\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0944 - accuracy: 0.9924\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0999 - accuracy: 0.9905\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0980 - accuracy: 0.9915\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0908 - accuracy: 0.9931\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0974 - accuracy: 0.9910\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0921 - accuracy: 0.9924\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0921 - accuracy: 0.9923\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0905 - accuracy: 0.9924\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0895 - accuracy: 0.9928\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0936 - accuracy: 0.9915\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.0902 - accuracy: 0.9918\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0847 - accuracy: 0.9937\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0842 - accuracy: 0.9932\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0877 - accuracy: 0.9923\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0803 - accuracy: 0.9946\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0874 - accuracy: 0.9916\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0828 - accuracy: 0.9932\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0812 - accuracy: 0.9935\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.0788 - accuracy: 0.9947\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0813 - accuracy: 0.9933\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.0812 - accuracy: 0.9929\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0791 - accuracy: 0.9930\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0769 - accuracy: 0.9941\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0766 - accuracy: 0.9940\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0799 - accuracy: 0.9929\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0730 - accuracy: 0.9943\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0746 - accuracy: 0.9939\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0769 - accuracy: 0.9936\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0760 - accuracy: 0.9926\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0716 - accuracy: 0.9944\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0737 - accuracy: 0.9940\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0689 - accuracy: 0.9949\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0734 - accuracy: 0.9935\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0701 - accuracy: 0.9940\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0736 - accuracy: 0.9931\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0695 - accuracy: 0.9943\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0696 - accuracy: 0.9943\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0684 - accuracy: 0.9945\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.0664 - accuracy: 0.9950\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0676 - accuracy: 0.9944\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0638 - accuracy: 0.9953\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0669 - accuracy: 0.9947\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0642 - accuracy: 0.9949\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0667 - accuracy: 0.9944\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0620 - accuracy: 0.9954\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0644 - accuracy: 0.9949\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0645 - accuracy: 0.9940\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0589 - accuracy: 0.9961\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0660 - accuracy: 0.9938\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0604 - accuracy: 0.9958\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.0582 - accuracy: 0.9959\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0648 - accuracy: 0.9940\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0577 - accuracy: 0.9959\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0632 - accuracy: 0.9939\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0565 - accuracy: 0.9963\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0608 - accuracy: 0.9948\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0563 - accuracy: 0.9960\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0574 - accuracy: 0.9957\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0560 - accuracy: 0.9957\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0563 - accuracy: 0.9956\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0563 - accuracy: 0.9956\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0582 - accuracy: 0.9950\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0556 - accuracy: 0.9957\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0569 - accuracy: 0.9953\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0523 - accuracy: 0.9965\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0582 - accuracy: 0.9950\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0538 - accuracy: 0.9956\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0545 - accuracy: 0.9960\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0518 - accuracy: 0.9965\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0555 - accuracy: 0.9954\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0498 - accuracy: 0.9969\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0598 - accuracy: 0.9939\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0515 - accuracy: 0.9963\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0501 - accuracy: 0.9965\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0508 - accuracy: 0.9963\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0509 - accuracy: 0.9961\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0495 - accuracy: 0.9964\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0490 - accuracy: 0.9965\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0569 - accuracy: 0.9942\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0489 - accuracy: 0.9963\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0512 - accuracy: 0.9956\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0457 - accuracy: 0.9970\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0532 - accuracy: 0.9950\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0456 - accuracy: 0.9972\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 0s 11us/step - loss: 0.0484 - accuracy: 0.9963\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0509 - accuracy: 0.9954\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 0s 12us/step - loss: 0.0475 - accuracy: 0.9966\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0468 - accuracy: 0.9962\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.0475 - accuracy: 0.9961\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.0461 - accuracy: 0.9964\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0457 - accuracy: 0.9967\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0470 - accuracy: 0.9961\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0443 - accuracy: 0.9967\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.0464 - accuracy: 0.9965\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0448 - accuracy: 0.9969\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 1s 12us/step - loss: 0.0467 - accuracy: 0.9961\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 1s 14us/step - loss: 0.0421 - accuracy: 0.9974\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 1s 13us/step - loss: 0.0473 - accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "model_init_batch_epoch_CV = KerasClassifier(build_fn=model_h, verbose=1)\n",
    "\n",
    "# we choose the initializers that came at the top in our previous cross-validation!!\n",
    "init_mode = ['he_normal', 'he_uniform'] \n",
    "batches = [1000, 2000]\n",
    "epochs = [100, 200]\n",
    "\n",
    "# grid search for initializer, batch size and number of epochs\n",
    "param_grid = dict(epochs=epochs, batch_size=batches, init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model_init_batch_epoch_CV, \n",
    "                    param_grid=param_grid,\n",
    "                    cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "OhaUc-DjwXii",
    "outputId": "ccf6c584-3770-41d3-e3fc-529cc2b24d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy for 0.7829 using {'batch_size': 2000, 'epochs': 200, 'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on the above outputs:\n",
    "1. By doing many Hyperparameter tuning the accuracy of the model on training is 78.29%.\n",
    "2. To have conclusion on the performance on the model evaluation of the model on the validation was carried out in the colab but it fetched a lot of time so it was not possible to recieve a conclusion on the model after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "1. Initially the given dataset was read.\n",
    "2. The read dataset was Reshaped, One-Hot encoded and Normalized.\n",
    "3. Various number of models and trials were done to achieve good results\n",
    "4. Few models were improved by hperparameter tuning.\n",
    "5. As per the above approach the model shown in the Step 11 can be used in the production. \n",
    "6. The ways the above approcah could have been improved which might have given us a different scenarios:\n",
    "\n",
    "        1. Few trials with exponential learning rate could have been tried.\n",
    "        2. By increasing or decriasing the number of layers in the model, but with careful handling on deeper networks because we hae the problem of vanishing gradients in the deeper networks.\n",
    "        3. By building the models with bias.\n",
    "        4. It was found that building models with Batch Normalization and Dropout did not work well so few models could have been built with dropout layers alone.\n",
    "        5. By performing more trials in the Model - 3 some more various activations in the intermediate layers.\n",
    "        6. By using different weight initialization methods.\n",
    "        7. By using different optimizers.\n",
    "7. There are many opportunities available to still achieve good resuts."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SVHN_V.L.Rithik_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
